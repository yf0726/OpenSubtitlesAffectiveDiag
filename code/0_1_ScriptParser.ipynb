{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested our segmentation method on Cornell movie dialogue data set. And in this notebook we validated our method on original movie scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Parse the scripts and segment dialogues\n",
    "\n",
    "The scripts are not well formatted: even though they are in html format, actually the lines are not well constructed in tags. We cannot parse them with tags. Fortunately, every characters and changes of scenes are bolded with tag 'b', and we have files containing characters information. So first we extract all bolded lines, and substract characters, then changes of scenes are left, and then we can know the boundaries of dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/datasets/scripts/code/opensubs-turns/'\n",
    "path = folder_path+'scripts'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if (file.endswith('.html')) & (~file.startswith('fd')) & (~file.startswith('tbbt')) & (~file.startswith('friends')):\n",
    "            test_path = folder_path+'sentences/'+file.split('.html')[0]+'-speakers.txt'\n",
    "            if os.path.exists(test_path):\n",
    "                files.append(file.split('.html')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser(files,j):\n",
    "    \"\"\"\n",
    "    This function is used to parse the scripts in .html.\n",
    "    Inputs:\n",
    "        files: List of scripts' directory.\n",
    "        j: index\n",
    "    \"\"\"\n",
    "    file_path = folder_path+'sentences/'+files[j]+'-speakers.txt' # read the file with speakers in that script\n",
    "\n",
    "    f = open(file_path)               \n",
    "    lines = f.readlines()               \n",
    "    tags_speakers = []\n",
    "    for line in lines: \n",
    "        tags_speakers.append(line.replace('continued','').upper().rstrip())\n",
    "    tags_speakers = set(tags_speakers) # characters in the scripts\n",
    "    \n",
    "    file_path = folder_path+'scripts/'+files[j]+'.html'\n",
    "    soup = BeautifulSoup(open(file_path, errors='ignore'))\n",
    "    \n",
    "    tags = []\n",
    "    for a in soup.find_all('b'):\n",
    "        tags.append(a.string.rstrip().lstrip())\n",
    "    tags = set(tags) # all bolded tags\n",
    "    tags_background = tags - tags_speakers # only changes of scenes are left\n",
    "\n",
    "    texts = [' '.join(x.rstrip().lstrip().split('\\n\\n')[0].split()) for x in soup.strings if str.strip(x) != '']\n",
    "\n",
    "    idxs = []\n",
    "    idxs_bg = []\n",
    "    speaker = []\n",
    "    lines = []\n",
    "    for i in range(len(texts)):\n",
    "        if texts[i] in tags_background:\n",
    "            idxs_bg.append(i)\n",
    "        if texts[i] not in tags_speakers:\n",
    "            continue\n",
    "        else:\n",
    "            speaker.append(texts[i])\n",
    "            line = re.sub(u\"\\\\(.*?\\\\)|\\\\{.*?}|\\\\[.*?]|\\\\♪.*?♪|\\\\#.*?#|\\\\=.*?=|\\\\¶.*?¶\", \"\", texts[i+1])\n",
    "            lines.append(line)\n",
    "            idxs.append(i)\n",
    "            \n",
    "    s = pd.Series(idxs)\n",
    "    boundaries = pd.cut(s,idxs_bg, labels=False, retbins=False, right=False).get_values()\n",
    "    boundaries = [1]+list((boundaries[1:] != boundaries[:-1])*1)\n",
    "    \n",
    "    MovieID = ['m%s'%(str(j))] * len(lines)\n",
    "    MovieName = [files[j]] * len(lines)\n",
    "\n",
    "    dialogue = pd.DataFrame([speaker,lines,boundaries,MovieID,MovieName]).T\n",
    "    dialogue.columns = ['Speaker','Line','Label','MovieID','MoveiName']\n",
    "    dialogue.to_csv(folder_path+'parsed/'+MovieID[0]+'.txt',sep=',', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Crow-Salvation,-The\n",
      "12 Star-Trek-First-Contact\n",
      "23 i-walked_with_a_zombie\n",
      "41 Who-Framed-Roger-Rabbit%3f\n",
      "42 Platoon\n",
      "43 the-x-files_production\n",
      "51 Pitch-Black\n",
      "56 pet-sematary\n",
      "62 thethinman\n",
      "93 Leaving-Las-Vegas\n",
      "134 Stepmom\n",
      "136 oneflewover\n",
      "142 Star-Trek-Generations\n",
      "147 Bones\n",
      "149 Minority-Report\n",
      "150 natural-born-killers_early\n",
      "170 Buffy-the-Vampire-Slayer\n",
      "177 Star-Trek-The-Motion-Picture\n",
      "179 fivefeetandrising\n",
      "181 Crying-Game\n",
      "193 Clueless\n",
      "197 natural-born-killers_shoot\n",
      "215 Tremors\n",
      "243 Sixth-Sense,-The\n",
      "256 John-Q\n",
      "273 Orgy-of-the-Dead\n",
      "284 Almost-Famous\n",
      "288 Blast-from-the-Past,-The\n",
      "293 Anastasia\n",
      "296 Memento\n",
      "298 Aladdin\n",
      "303 fabulous_baker_boys_final\n",
      "305 Blade-II\n",
      "308 hellraiser_ii\n",
      "313 mission-impossible-2_shoot\n",
      "315 English-Patient,-The\n",
      "322 Independence-Day\n",
      "340 halloween\n",
      "364 Apartment,-The\n",
      "368 kundun\n",
      "373 Shampoo\n",
      "374 True-Romance\n",
      "378 Star-Trek-II-The-Wrath-of-Khan\n",
      "390 Life-As-A-House\n",
      "413 Little-Mermaid,-The\n",
      "427 Red-Planet\n",
      "432 Withnail-and-I\n",
      "434 Heavy-Metal\n",
      "436 Pearl-Harbor\n",
      "442 thetimemachine_1959\n",
      "451 48-Hrs.\n",
      "455 X-Men\n",
      "459 Ace-Ventura-Pet-Detective\n",
      "463 Beach,-The\n",
      "480 12\n",
      "481 Sugar-and-Spice\n",
      "504 Mary-Poppins\n",
      "515 Highlander-Endgame\n",
      "520 Broadcast-News\n",
      "529 Ninth-Gate,-The\n",
      "540 happy_birthday_wanda_june\n",
      "563 Erik-the-Viking\n",
      "566 Resident-Evil\n",
      "568 Rambo-First-Blood-II-The-Mission\n",
      "579 Top-Gun\n",
      "582 vertigo\n",
      "587 They\n",
      "588 goodfellas\n",
      "591 Nightbreed\n",
      "600 Star-Wars-The-Phantom-Menace\n",
      "630 E.T.\n",
      "631 house-on-haunted-hill\n",
      "635 the-man-who-wasn't-there\n",
      "650 Planet-of-the-Apes,-The\n",
      "684 Nurse-Betty\n",
      "692 Punch-Drunk-Love\n",
      "702 Saint,-The\n",
      "716 Never-Been-Kissed\n",
      "719 At-First-Sight\n",
      "732 grosse_point_blank\n",
      "749 Blow\n",
      "759 avengers\n",
      "760 Rescuers-Down-Under,-The\n",
      "781 Bottle-Rocket\n",
      "786 True-Grit\n",
      "787 Cinema-Paradiso\n",
      "797 Battle-of-Algiers,-The\n",
      "802 Halloween-The-Curse-of-Michael-Myers\n",
      "816 Awakenings\n",
      "820 Enemy-of-the-State\n",
      "834 Usual-Suspects,-The\n",
      "845 millers_crossing\n",
      "846 Mission-Impossible\n",
      "853 spareme\n",
      "876 Swingers\n",
      "900 Mulan\n",
      "902 Cube\n",
      "919 Dawn-of-the-Dead\n",
      "920 the_day_the_clown_cried\n",
      "929 Brazil\n",
      "932 fabulous_baker_boys_april_1985\n",
      "934 unforgiven\n",
      "939 logans_run\n",
      "948 Labyrinth\n",
      "949 Burlesque\n",
      "957 Frequency\n",
      "976 Return-of-the-Apes\n",
      "977 Toy-Story\n",
      "985 all_the_presidents_men\n",
      "987 Jurassic-Park-III\n",
      "1000 Air-Force-One\n",
      "1003 Mystery-Men\n",
      "1025 Neverending-Story,-The\n",
      "1027 Real-Genius\n",
      "1031 Copycat\n",
      "1037 Four-Feathers\n",
      "1040 quantumproject\n",
      "1051 Sex,-Lies-and-Videotape\n",
      "1058 thebijou\n",
      "1063 fletch\n",
      "1064 White-Ribbon,-The\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(files)):\n",
    "    try:\n",
    "        Parser(files,j)\n",
    "    except:\n",
    "        print(j,files[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Test the similarity segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load('./word2vec/model_opst')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_clean(s):\n",
    "#     s = s.replace('\\'','')\n",
    "    s = tokenizer.tokenize(s.lower())\n",
    "#     s = ' '.join([ps.stem(x) for x in s])\n",
    "    s = ' '.join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1,v2):\n",
    "    return v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "def heuristic_max(s1,s2,flag=False,model=model.wv):\n",
    "    if len(s1)*len(s2) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    matrix = np.zeros((len(s1),len(s2)))\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] in model.vocab.keys():\n",
    "            s1_vec = model[s1[i]]\n",
    "        else:\n",
    "            continue # if the source target word is not in vocabulary list then corresponding similiarity row = 0\n",
    "        for j in range(len(s2)):            \n",
    "            if s2[j] in model.vocab.keys():\n",
    "                s2_vec = model[s2[j]]\n",
    "                matrix[i][j] = cos_sim(s1_vec,s2_vec)\n",
    "            else:\n",
    "                continue # for not-found words the similarity is 0\n",
    "    s1_sim =  np.sum(np.max(matrix,1))/len(s1)\n",
    "    s2_sim = np.sum(np.max(matrix,0))/len(s2)\n",
    "    return 1/2*(np.round(s1_sim,5)+np.round(s2_sim,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def calculate_p_k(p,r,s_size):\n",
    "    P = np.ones(s_size)\n",
    "    P[p:] = 2\n",
    "\n",
    "    R = np.ones(s_size)\n",
    "    R[r:] = 2\n",
    "    \n",
    "    k = int(s_size/2)\n",
    "\n",
    "    delta_R = np.array([int(R[i]==R[i+k]) for i in range(len(R)-k)])\n",
    "    delta_P = np.array([int(P[i]==P[i+k]) for i in range(len(P)-k)])\n",
    "\n",
    "    P_k = sum(~(delta_R==delta_P)*1)/(len(R)-k)\n",
    "    return P_k\n",
    "\n",
    "def calculate_MAE(x,s_size):\n",
    "    x[x<0] = s_size\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_pred(x,alpha):\n",
    "    x_ = x[x!=0]\n",
    "    if len(x_)==0:\n",
    "        th = 0\n",
    "        label = [0]\n",
    "    else:\n",
    "        th = np.mean(x_)-alpha*np.std(x_)\n",
    "        label = np.where(x<=th)[0]\n",
    "        label = label if len(label)>0 else [0] # if th is too low, then the predicted label is the whole session\n",
    "    return label[0]\n",
    "\n",
    "def deriv_pred(x):\n",
    "    tmp = np.where((x[1:]-x[:-1])>0)[0]\n",
    "    if len(tmp)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texttiling_embedding(labels,smooth_score):\n",
    "    s_dict = {}\n",
    "    start_idx = np.where(labels==1)[0]\n",
    "\n",
    "    s_size = 10\n",
    "\n",
    "    for i in start_idx:\n",
    "        s = smooth_score[i:i+s_size]\n",
    "        block_label = np.where(labels[i:i+s_size])[0]\n",
    "        if len(block_label) < 2:\n",
    "            continue\n",
    "        depth_score = [0]\n",
    "        lpeak = s[0]\n",
    "        for k in range(1,len(s)):\n",
    "    #         idx = max(0,k-block_size)\n",
    "            lpeak = max(s[0:k+1])\n",
    "            depth_score.append(s[k]-lpeak)\n",
    "        s_dict[i] = {}\n",
    "        s_dict[i]['depth score'] = np.round(np.array(depth_score),5)\n",
    "        s_dict[i]['smooth score'] = s\n",
    "        s_dict[i]['depth mean'] = np.mean(depth_score)\n",
    "        s_dict[i]['depth std'] = np.std(depth_score)\n",
    "        s_dict[i]['block label'] = block_label\n",
    "    s_df = pd.DataFrame.from_dict(s_dict).T  \n",
    "\n",
    "    # block_labels = s_df['block label'].apply(lambda x:x[1])\n",
    "#     length = s_df['length'].get_values()\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['alpha','ACC','MAE','P_k','Random ACC','Random MAE','Random P_k']\n",
    "\n",
    "    # nltk.texttiling: mean - std/2\n",
    "    alphas = [0.5]\n",
    "    for alpha in alphas:\n",
    "        block_labels = []\n",
    "        pred = s_df['depth score'].apply(lambda x: th_pred(x,alpha))\n",
    "        delta = s_df['depth score'].apply(lambda x: next(iter(np.where((x[1:]-x[:-1])>0)[0]), 0))\n",
    "        s_df['pred'] = np.max((pred.get_values(),delta.get_values()),axis=0) \n",
    "        s_df.pred.replace(0,s_size-1,inplace=True) # predict = 0 means not found and set label to len of session\n",
    "        for i in range(len(pred)): # find the nearest label to prediction\n",
    "            block_labels.append(min(s_df['block label'].iloc[i][1:], key=lambda x:abs(x-s_df['pred'].iloc[i])))\n",
    "        diff = block_labels - pred # diff>0 when the prediction before ground truth\n",
    "\n",
    "        random_pred = np.random.randint(low=1,high=s_size+1,size=len(block_labels))\n",
    "        random_diff = block_labels - random_pred\n",
    "\n",
    "        acc = sum(block_labels==pred)/len(pred)\n",
    "        random_acc = sum(block_labels==random_pred)/len(random_pred)\n",
    "        \n",
    "        p_k = np.mean([calculate_p_k(p,r,s_size) for (p,r) in zip(block_labels,pred)])\n",
    "        random_p_k = np.mean([calculate_p_k(p,r,s_size) for (p,r) in zip(block_labels,random_pred)])\n",
    "        \n",
    "        table.add_row([alpha,\n",
    "                       round(acc,3),\n",
    "                      round(abs(calculate_MAE(diff,s_size)).mean(),3), # MAE\n",
    "                       round(p_k,3),\n",
    "                       round(random_acc,3),\n",
    "                      round(abs(calculate_MAE(random_diff,s_size)).mean(),3), # random MAE\n",
    "                       round(random_p_k,3)]\n",
    "                     )\n",
    "#     print(table)\n",
    "    return round(acc,3),round(abs(calculate_MAE(diff,s_size)).mean(),3),round(p_k,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/datasets/scripts/code/opensubs-turns/parsed/'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(folder_path):\n",
    "    for file in f:\n",
    "        if file.endswith('.txt'):\n",
    "            files.append(folder_path+file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "MAEs = []\n",
    "p_ks = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 m604.txt 0.349 3.616 0.286\n",
      "500 m162.txt 0.291 4.649 0.305\n",
      "501 m176.txt 0.331 4.216 0.276\n",
      "502 m610.txt 0.405 4.071 0.184\n",
      "503 m823.txt 0.1 4.1 0.397\n",
      "504 m189.txt 0.263 5.0 0.358\n",
      "505 m837.txt 0.364 4.0 0.248\n",
      "506 m994.txt 0.267 4.32 0.331\n",
      "507 m758.txt 0.482 2.816 0.137\n",
      "508 m980.txt 0.286 2.786 0.357\n",
      "509 m770.txt 0.292 4.651 0.291\n",
      "510 m764.txt 0.387 3.247 0.215\n",
      "511 m943.txt 0.205 4.53 0.39\n",
      "512 m228.txt 0.083 5.525 0.413\n",
      "513 m214.txt 0.345 4.029 0.255\n",
      "514 m572.txt 0.291 4.013 0.291\n",
      "515 m200.txt 0.387 4.071 0.211\n",
      "516 m1004.txt 0.15 6.05 0.467\n",
      "517 m34.txt 0.495 3.37 0.162\n",
      "518 m599.txt 0.348 3.56 0.248\n",
      "519 m1010.txt 0.699 1.887 0.069\n",
      "520 m20.txt 0.366 3.269 0.248\n",
      "521 m1038.txt 0.256 4.966 0.266\n",
      "522 m1039.txt 0.893 0.143 0.029\n",
      "523 m21.txt 0.184 5.105 0.374\n",
      "524 m1011.txt 0.146 5.539 0.391\n",
      "525 m598.txt 0.357 4.786 0.314\n",
      "526 m35.txt 0.347 3.081 0.206\n",
      "527 m1005.txt 0.311 3.992 0.234\n",
      "528 m567.txt 0.198 4.296 0.309\n",
      "529 m201.txt 0.417 4.917 0.317\n",
      "530 m573.txt 0.248 4.497 0.291\n",
      "531 m229.txt 0.415 4.708 0.311\n",
      "532 m942.txt 0.271 4.514 0.283\n",
      "533 m956.txt 0.271 3.875 0.278\n",
      "534 m765.txt 0.531 2.429 0.2\n",
      "535 m771.txt 0.211 5.153 0.302\n",
      "536 m981.txt 0.475 3.313 0.198\n",
      "537 m995.txt 0.311 4.338 0.332\n",
      "538 m188.txt 0.183 5.333 0.357\n",
      "539 m836.txt 0.303 4.421 0.324\n",
      "540 m822.txt 0.281 4.813 0.227\n",
      "541 m611.txt 0.336 4.295 0.26\n",
      "542 m605.txt 0.319 4.185 0.321\n",
      "543 m163.txt 0.222 5.426 0.337\n",
      "544 m639.txt 0.276 4.241 0.275\n",
      "545 m375.txt 0.54 2.778 0.17\n",
      "546 m361.txt 0.26 5.305 0.308\n",
      "547 m407.txt 0.524 2.687 0.135\n",
      "548 m349.txt 0.461 2.966 0.157\n",
      "549 m439.txt 0.276 4.569 0.286\n",
      "550 m377.txt 0.27 4.539 0.277\n",
      "551 m411.txt 0.373 3.507 0.248\n",
      "552 m405.txt 0.209 5.0 0.335\n",
      "553 m363.txt 0.452 2.405 0.181\n",
      "554 m388.txt 0.423 3.911 0.174\n",
      "555 m613.txt 0.19 4.63 0.334\n",
      "556 m175.txt 0.318 4.752 0.257\n",
      "557 m161.txt 0.32 4.326 0.233\n",
      "558 m607.txt 0.443 3.615 0.201\n",
      "559 m808.txt 0.207 4.371 0.352\n",
      "560 m983.txt 0.488 2.888 0.154\n",
      "561 m997.txt 0.317 4.183 0.297\n",
      "562 m767.txt 0.231 4.628 0.31\n",
      "563 m773.txt 0.287 4.246 0.283\n",
      "564 m940.txt 0.246 5.362 0.359\n",
      "565 m798.txt 0.309 4.547 0.232\n",
      "566 m954.txt 0.202 5.787 0.364\n",
      "567 m8.txt 0.269 4.653 0.296\n",
      "568 m968.txt 0.191 5.118 0.35\n",
      "569 m559.txt 0.143 5.248 0.377\n",
      "570 m203.txt 0.357 3.107 0.201\n",
      "571 m565.txt 0.295 4.267 0.278\n",
      "572 m571.txt 0.271 5.096 0.3\n",
      "573 m217.txt 0.354 4.615 0.29\n",
      "574 m1013.txt 0.282 5.41 0.313\n",
      "575 m1007.txt 0.224 3.709 0.34\n",
      "576 m37.txt 0.489 3.522 0.274\n",
      "577 m36.txt 0.3 4.592 0.236\n",
      "578 m1006.txt 0.224 4.776 0.396\n",
      "579 m22.txt 0.147 5.176 0.353\n",
      "580 m1012.txt 0.26 4.646 0.352\n",
      "581 m570.txt 0.205 6.538 0.436\n",
      "582 m216.txt 0.411 4.295 0.275\n",
      "583 m202.txt 0.247 4.426 0.302\n",
      "584 m564.txt 0.222 4.244 0.362\n",
      "585 m558.txt 0.289 4.478 0.286\n",
      "586 m969.txt 0.357 3.9 0.221\n",
      "587 m955.txt 0.292 5.083 0.317\n",
      "588 m799.txt 0.322 4.391 0.297\n",
      "589 m941.txt 0.25 5.375 0.367\n",
      "590 m772.txt 0.179 5.366 0.352\n",
      "591 m766.txt 0.173 4.923 0.292\n",
      "592 m996.txt 0.23 4.986 0.35\n",
      "593 m982.txt 0.339 4.542 0.254\n",
      "594 m809.txt 0.392 3.004 0.234\n",
      "595 m821.txt 0.235 4.357 0.278\n",
      "596 m835.txt 0.376 4.407 0.277\n",
      "597 m160.txt 0.039 5.105 0.537\n",
      "598 m606.txt 0.151 4.726 0.317\n",
      "599 m612.txt 0.336 4.457 0.239\n",
      "600 m174.txt 0.315 4.574 0.245\n",
      "601 m148.txt 0.403 3.19 0.218\n",
      "602 m389.txt 0.33 3.973 0.227\n",
      "603 m404.txt 0.186 4.653 0.321\n",
      "604 m362.txt 0.279 4.315 0.31\n",
      "605 m376.txt 0.256 4.573 0.246\n",
      "606 m410.txt 0.253 4.57 0.309\n",
      "607 m438.txt 0.375 3.935 0.206\n",
      "608 m414.txt 0.276 4.885 0.283\n",
      "609 m372.txt 0.307 3.816 0.249\n",
      "610 m366.txt 0.469 3.704 0.235\n",
      "611 m400.txt 0.228 4.737 0.347\n",
      "612 m428.txt 0.318 4.327 0.275\n",
      "613 m399.txt 0.221 4.882 0.306\n",
      "614 m616.txt 0.278 4.368 0.294\n",
      "615 m602.txt 0.057 5.929 0.44\n",
      "616 m164.txt 0.197 5.0 0.397\n",
      "617 m158.txt 0.302 5.0 0.316\n",
      "618 m819.txt 0.357 3.759 0.277\n",
      "619 m831.txt 0.206 5.857 0.368\n",
      "620 m825.txt 0.22 4.976 0.325\n",
      "621 m762.txt 0.084 5.06 0.451\n",
      "622 m776.txt 0.321 4.244 0.27\n",
      "623 m986.txt 0.297 3.731 0.254\n",
      "624 m992.txt 0.279 4.507 0.294\n",
      "625 m979.txt 0.244 4.483 0.297\n",
      "626 m945.txt 0.182 6.818 0.364\n",
      "627 m951.txt 0.339 4.177 0.297\n",
      "628 m789.txt 0.221 4.246 0.349\n",
      "629 m560.txt 0.39 3.77 0.188\n",
      "630 m206.txt 0.267 4.489 0.379\n",
      "631 m212.txt 0.391 3.908 0.278\n",
      "632 m574.txt 0.322 4.085 0.305\n",
      "633 m548.txt 1.0 0.0 0.0\n",
      "634 m26.txt 0.388 4.075 0.205\n",
      "635 m1016.txt 0.375 3.571 0.238\n",
      "636 m32.txt 0.155 4.961 0.336\n",
      "637 m1002.txt 0.235 5.373 0.329\n",
      "638 m33.txt 0.319 3.837 0.281\n",
      "639 m1017.txt 0.229 4.477 0.316\n",
      "640 m27.txt 0.267 5.037 0.276\n",
      "641 m549.txt 0.373 3.696 0.288\n",
      "642 m213.txt 0.502 3.18 0.174\n",
      "643 m575.txt 0.297 4.881 0.279\n",
      "644 m561.txt 0.579 2.294 0.103\n",
      "645 m207.txt 0.367 3.978 0.222\n",
      "646 m788.txt 0.411 3.596 0.241\n",
      "647 m950.txt 0.288 4.339 0.305\n",
      "648 m944.txt 0.28 3.925 0.363\n",
      "649 m978.txt 0.179 4.896 0.364\n",
      "650 m993.txt 0.196 4.907 0.33\n",
      "651 m777.txt 0.25 3.5 0.286\n",
      "652 m763.txt 0.173 5.495 0.367\n",
      "653 m824.txt 0.433 3.753 0.178\n",
      "654 m830.txt 0.26 3.773 0.334\n",
      "655 m818.txt 0.37 3.43 0.229\n",
      "656 m159.txt 0.356 3.955 0.247\n",
      "657 m603.txt 0.115 4.323 0.425\n",
      "658 m165.txt 0.121 5.818 0.442\n",
      "659 m171.txt 0.384 3.856 0.218\n",
      "660 m617.txt 0.188 4.633 0.323\n",
      "661 m398.txt 0.176 4.902 0.42\n",
      "662 m429.txt 0.187 4.813 0.318\n",
      "663 m367.txt 0.431 3.487 0.19\n",
      "664 m401.txt 0.492 2.862 0.162\n",
      "665 m415.txt 0.281 3.956 0.26\n",
      "666 m403.txt 0.171 5.618 0.439\n",
      "667 m365.txt 0.236 4.429 0.353\n",
      "668 m371.txt 0.234 4.306 0.283\n",
      "669 m417.txt 0.061 4.97 0.406\n",
      "670 m359.txt 0.384 3.92 0.239\n",
      "671 m167.txt 0.25 6.417 0.5\n",
      "672 m601.txt 0.423 3.586 0.205\n",
      "673 m615.txt 0.145 5.873 0.382\n",
      "674 m173.txt 0.257 5.012 0.292\n",
      "675 m629.txt 0.44 3.269 0.195\n",
      "676 m198.txt 0.237 4.27 0.332\n",
      "677 m826.txt 0.454 3.437 0.169\n",
      "678 m832.txt 0.283 5.086 0.338\n",
      "679 m775.txt 0.352 3.876 0.275\n",
      "680 m761.txt 0.359 3.656 0.244\n",
      "681 m991.txt 0.198 4.294 0.348\n",
      "682 m952.txt 0.257 4.978 0.308\n",
      "683 m946.txt 0.314 4.336 0.289\n",
      "684 m577.txt 0.296 4.571 0.282\n",
      "685 m211.txt 0.503 2.758 0.143\n",
      "686 m205.txt 0.225 5.197 0.33\n",
      "687 m239.txt 0.316 3.135 0.239\n",
      "688 m19.txt 0.196 6.109 0.374\n",
      "689 m1029.txt 0.189 5.178 0.378\n",
      "690 m31.txt 0.422 3.493 0.148\n",
      "691 m1001.txt 0.156 5.2 0.484\n",
      "693 m1015.txt 0.511 3.098 0.158\n",
      "694 m1014.txt 0.368 4.482 0.249\n",
      "695 m24.txt 0.281 4.986 0.305\n",
      "696 m30.txt 0.235 6.784 0.31\n",
      "697 m589.txt 0.259 5.218 0.32\n",
      "698 m1028.txt 0.399 4.142 0.209\n",
      "699 m18.txt 0.31 4.262 0.255\n",
      "700 m238.txt 0.593 2.204 0.111\n",
      "701 m204.txt 0.345 3.357 0.213\n",
      "702 m562.txt 0.267 4.099 0.297\n",
      "703 m576.txt 0.358 3.767 0.305\n",
      "704 m210.txt 0.23 4.973 0.403\n",
      "705 m947.txt 0.301 4.154 0.214\n",
      "706 m953.txt 0.228 4.504 0.353\n",
      "707 m984.txt 0.29 4.454 0.293\n",
      "708 m990.txt 0.413 3.609 0.231\n",
      "709 m748.txt 0.282 4.746 0.324\n",
      "710 m774.txt 0.31 3.976 0.305\n",
      "711 m833.txt 0.304 3.552 0.234\n",
      "712 m199.txt 0.345 3.451 0.226\n",
      "713 m827.txt 0.283 4.23 0.312\n",
      "714 m628.txt 0.519 2.907 0.205\n",
      "715 m614.txt 0.519 2.198 0.142\n",
      "716 m172.txt 0.219 4.821 0.294\n",
      "717 m166.txt 0.3 4.5 0.318\n",
      "718 m358.txt 0.256 4.236 0.336\n",
      "719 m370.txt 0.459 3.347 0.156\n",
      "720 m416.txt 0.453 3.101 0.21\n",
      "721 m402.txt 0.418 3.967 0.266\n",
      "722 m465.txt 0.276 4.543 0.29\n",
      "723 m317.txt 0.327 4.149 0.271\n",
      "724 m471.txt 0.424 3.853 0.239\n",
      "725 m883.txt 0.178 4.548 0.385\n",
      "726 m897.txt 0.253 4.646 0.39\n",
      "727 m129.txt 0.413 3.549 0.221\n",
      "728 m101.txt 0.335 3.882 0.261\n",
      "729 m667.txt 0.165 5.194 0.353\n",
      "730 m673.txt 0.291 4.563 0.274\n",
      "731 m115.txt 0.272 3.994 0.242\n",
      "732 m698.txt 0.346 4.223 0.272\n",
      "733 m840.txt 0.362 2.174 0.258\n",
      "734 m854.txt 0.067 5.183 0.537\n",
      "735 m868.txt 0.251 4.082 0.276\n",
      "736 m713.txt 0.295 4.869 0.279\n",
      "737 m707.txt 0.219 3.812 0.322\n",
      "738 m908.txt 0.231 5.577 0.477\n",
      "739 m94.txt 0.123 4.951 0.323\n",
      "740 m80.txt 0.171 5.607 0.367\n",
      "741 m539.txt 0.083 4.292 0.4\n",
      "742 m511.txt 0.442 3.423 0.292\n",
      "743 m277.txt 0.541 3.068 0.238\n",
      "744 m263.txt 0.265 5.008 0.318\n",
      "745 m505.txt 0.446 3.072 0.172\n",
      "746 m57.txt 0.34 4.551 0.269\n",
      "747 m289.txt 0.214 6.071 0.343\n",
      "748 m262.txt 0.324 4.088 0.304\n",
      "749 m510.txt 0.151 4.882 0.385\n",
      "750 m276.txt 0.496 2.866 0.187\n",
      "751 m538.txt 0.447 3.294 0.18\n",
      "752 m81.txt 0.189 4.577 0.27\n",
      "753 m95.txt 0.191 6.702 0.404\n",
      "754 m909.txt 0.329 3.942 0.246\n",
      "755 m921.txt 0.1 6.043 0.434\n",
      "756 m935.txt 0.345 4.97 0.251\n",
      "757 m706.txt 0.118 5.235 0.518\n",
      "758 m712.txt 0.233 4.767 0.358\n",
      "759 m869.txt 0.204 5.175 0.285\n",
      "760 m855.txt 0.327 3.644 0.271\n",
      "761 m841.txt 0.389 3.419 0.24\n",
      "762 m699.txt 0.453 3.543 0.187\n",
      "763 m672.txt 0.398 3.714 0.211\n",
      "764 m114.txt 0.356 3.8 0.273\n",
      "765 m100.txt 0.231 5.365 0.423\n",
      "766 m666.txt 0.179 4.564 0.313\n",
      "767 m896.txt 0.372 4.116 0.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 m128.txt 0.323 3.581 0.229\n",
      "769 m882.txt 0.353 3.545 0.259\n",
      "770 m316.txt 0.355 3.682 0.29\n",
      "771 m470.txt 0.454 3.051 0.191\n",
      "772 m464.txt 0.36 5.167 0.219\n",
      "773 m302.txt 0.247 4.965 0.365\n",
      "774 m458.txt 0.22 4.232 0.344\n",
      "775 m328.txt 0.409 3.79 0.214\n",
      "776 m472.txt 0.455 2.622 0.147\n",
      "777 m314.txt 0.305 4.53 0.245\n",
      "778 m300.txt 0.169 5.644 0.38\n",
      "779 m466.txt 0.273 4.564 0.331\n",
      "780 m499.txt 0.281 5.067 0.303\n",
      "781 m894.txt 0.065 5.774 0.445\n",
      "782 m880.txt 0.351 3.294 0.231\n",
      "783 m658.txt 0.307 4.423 0.314\n",
      "784 m116.txt 0.232 4.634 0.352\n",
      "785 m670.txt 0.359 2.859 0.189\n",
      "786 m664.txt 0.343 4.412 0.251\n",
      "787 m102.txt 0.083 2.417 0.383\n",
      "788 m857.txt 0.374 3.732 0.241\n",
      "789 m843.txt 0.458 3.176 0.189\n",
      "790 m738.txt 0.232 4.735 0.305\n",
      "791 m704.txt 0.384 3.59 0.227\n",
      "792 m710.txt 0.143 5.143 0.543\n",
      "793 m923.txt 0.33 3.33 0.218\n",
      "794 m937.txt 0.414 3.355 0.2\n",
      "795 m83.txt 0.244 5.232 0.291\n",
      "796 m248.txt 0.071 6.607 0.341\n",
      "797 m97.txt 0.245 4.592 0.341\n",
      "798 m506.txt 0.348 3.843 0.259\n",
      "799 m260.txt 0.348 4.217 0.365\n",
      "800 m274.txt 0.227 4.727 0.348\n",
      "801 m512.txt 0.286 3.871 0.266\n",
      "802 m40.txt 0.2 5.01 0.307\n",
      "803 m54.txt 0.252 4.559 0.324\n",
      "804 m68.txt 0.133 5.23 0.465\n",
      "805 m69.txt 0.071 4.357 0.329\n",
      "806 m1059.txt 0.329 3.884 0.265\n",
      "807 m55.txt 0.26 4.058 0.305\n",
      "808 m1065.txt 0.274 4.857 0.3\n",
      "809 m275.txt 0.167 5.014 0.419\n",
      "810 m513.txt 0.242 4.683 0.297\n",
      "811 m507.txt 0.319 3.782 0.244\n",
      "812 m261.txt 0.81 0.398 0.038\n",
      "813 m249.txt 0.167 5.833 0.355\n",
      "814 m96.txt 0.291 4.396 0.288\n",
      "815 m82.txt 0.288 3.835 0.269\n",
      "816 m936.txt 0.215 4.079 0.308\n",
      "817 m922.txt 0.259 4.63 0.348\n",
      "818 m711.txt 0.167 6.583 0.442\n",
      "819 m705.txt 0.189 5.698 0.404\n",
      "820 m739.txt 0.401 3.624 0.194\n",
      "821 m842.txt 0.225 4.232 0.346\n",
      "822 m856.txt 0.312 4.695 0.266\n",
      "823 m665.txt 0.291 4.793 0.27\n",
      "824 m103.txt 0.231 4.663 0.308\n",
      "825 m117.txt 0.358 3.606 0.226\n",
      "826 m671.txt 0.194 5.592 0.386\n",
      "827 m659.txt 0.383 3.929 0.277\n",
      "828 m881.txt 0.343 3.152 0.201\n",
      "829 m895.txt 0.446 3.321 0.197\n",
      "830 m498.txt 0.414 3.366 0.196\n",
      "831 m301.txt 0.197 5.437 0.406\n",
      "832 m467.txt 0.141 4.5 0.398\n",
      "833 m473.txt 0.231 4.415 0.314\n",
      "834 m329.txt 0.233 5.549 0.293\n",
      "835 m311.txt 0.211 5.366 0.315\n",
      "836 m477.txt 0.261 3.993 0.316\n",
      "837 m339.txt 0.053 5.368 0.432\n",
      "838 m488.txt 0.372 3.266 0.2\n",
      "839 m675.txt 0.145 4.783 0.328\n",
      "840 m113.txt 0.37 4.12 0.231\n",
      "841 m107.txt 0.371 3.871 0.226\n",
      "842 m661.txt 0.143 4.509 0.359\n",
      "843 m891.txt 0.348 3.776 0.269\n",
      "844 m649.txt 0.278 7.222 0.244\n",
      "845 m885.txt 0.349 3.428 0.209\n",
      "846 m852.txt 0.624 2.247 0.135\n",
      "847 m701.txt 0.569 2.526 0.138\n",
      "848 m715.txt 0.259 4.531 0.262\n",
      "849 m729.txt 0.197 5.566 0.342\n",
      "850 m926.txt 0.158 4.086 0.35\n",
      "851 m265.txt 0.268 3.951 0.293\n",
      "852 m503.txt 0.291 4.608 0.316\n",
      "853 m517.txt 0.385 3.758 0.229\n",
      "854 m271.txt 0.224 5.121 0.336\n",
      "855 m259.txt 0.143 6.49 0.384\n",
      "856 m86.txt 0.295 4.047 0.228\n",
      "857 m92.txt 0.293 4.178 0.257\n",
      "858 m79.txt 0.194 5.018 0.364\n",
      "859 m1049.txt 0.304 5.196 0.283\n",
      "860 m45.txt 0.353 4.521 0.271\n",
      "861 m1061.txt 0.237 4.868 0.291\n",
      "862 m1060.txt 0.185 5.376 0.373\n",
      "863 m50.txt 0.307 3.726 0.265\n",
      "864 m44.txt 0.371 4.443 0.227\n",
      "865 m1048.txt 0.181 5.764 0.422\n",
      "866 m78.txt 0.27 5.027 0.389\n",
      "867 m258.txt 0.1 5.88 0.392\n",
      "868 m87.txt 0.225 5.235 0.288\n",
      "869 m516.txt 0.305 4.045 0.297\n",
      "870 m270.txt 0.337 3.517 0.223\n",
      "871 m264.txt 0.245 4.321 0.319\n",
      "872 m502.txt 0.158 5.272 0.395\n",
      "873 m933.txt 0.205 4.615 0.31\n",
      "874 m927.txt 0.161 5.226 0.368\n",
      "875 m728.txt 0.411 3.599 0.2\n",
      "876 m714.txt 0.426 3.713 0.202\n",
      "877 m700.txt 0.44 3.397 0.187\n",
      "878 m847.txt 0.41 3.885 0.315\n",
      "879 m884.txt 0.3 3.85 0.264\n",
      "880 m648.txt 0.235 4.444 0.301\n",
      "881 m890.txt 0.372 3.891 0.217\n",
      "882 m106.txt 0.323 5.065 0.342\n",
      "883 m660.txt 0.249 4.89 0.313\n",
      "884 m674.txt 0.277 5.532 0.347\n",
      "885 m112.txt 0.233 4.988 0.349\n",
      "886 m489.txt 0.205 5.159 0.464\n",
      "887 m338.txt 0.454 3.388 0.203\n",
      "888 m462.txt 0.364 3.753 0.201\n",
      "889 m304.txt 0.232 5.348 0.287\n",
      "890 m310.txt 0.442 3.673 0.196\n",
      "891 m476.txt 0.382 4.417 0.209\n",
      "892 m306.txt 0.187 4.542 0.359\n",
      "893 m460.txt 0.35 3.793 0.235\n",
      "894 m474.txt 0.336 4.351 0.269\n",
      "895 m312.txt 0.208 4.858 0.315\n",
      "896 m448.txt 0.245 4.694 0.329\n",
      "897 m662.txt 0.321 4.59 0.313\n",
      "898 m104.txt 0.321 4.017 0.262\n",
      "899 m110.txt 0.448 3.335 0.173\n",
      "900 m676.txt 0.427 3.653 0.219\n",
      "901 m886.txt 0.305 3.326 0.218\n",
      "902 m138.txt 0.291 3.515 0.263\n",
      "903 m892.txt 0.214 4.35 0.361\n",
      "904 m879.txt 0.302 3.937 0.253\n",
      "905 m689.txt 0.302 4.365 0.242\n",
      "906 m851.txt 0.197 4.864 0.332\n",
      "907 m931.txt 0.216 4.511 0.319\n",
      "908 m925.txt 0.382 3.264 0.213\n",
      "909 m272.txt 0.413 3.849 0.195\n",
      "910 m514.txt 0.258 4.317 0.332\n",
      "911 m500.txt 0.197 5.0 0.382\n",
      "912 m266.txt 0.176 5.812 0.431\n",
      "913 m91.txt 0.458 3.21 0.149\n",
      "914 m528.txt 0.262 4.307 0.292\n",
      "915 m85.txt 0.268 5.309 0.273\n",
      "916 m52.txt 0.365 3.768 0.249\n",
      "917 m1062.txt 0.33 4.229 0.277\n",
      "918 m46.txt 0.386 3.54 0.233\n",
      "919 m299.txt 0.263 4.678 0.282\n",
      "920 m47.txt 0.195 4.063 0.361\n",
      "921 m53.txt 0.11 5.266 0.41\n",
      "922 m84.txt 0.274 3.788 0.313\n",
      "923 m90.txt 0.177 3.986 0.275\n",
      "924 m501.txt 0.362 4.043 0.225\n",
      "925 m267.txt 0.131 3.963 0.393\n",
      "926 m924.txt 0.281 3.898 0.249\n",
      "927 m930.txt 0.399 3.513 0.181\n",
      "928 m918.txt 0.193 5.239 0.42\n",
      "929 m703.txt 0.408 3.468 0.213\n",
      "930 m717.txt 0.241 4.571 0.274\n",
      "931 m850.txt 0.304 4.51 0.261\n",
      "932 m688.txt 0.22 5.189 0.318\n",
      "933 m844.txt 0.059 7.0 0.494\n",
      "934 m878.txt 0.347 3.659 0.223\n",
      "935 m893.txt 0.322 4.322 0.302\n",
      "936 m887.txt 0.39 2.885 0.223\n",
      "937 m139.txt 0.274 4.466 0.301\n",
      "938 m111.txt 0.212 4.869 0.313\n",
      "939 m677.txt 0.508 3.333 0.211\n",
      "940 m663.txt 0.243 4.135 0.281\n",
      "941 m105.txt 0.284 4.124 0.283\n",
      "942 m449.txt 0.296 4.687 0.277\n",
      "943 m475.txt 0.198 5.896 0.369\n",
      "944 m307.txt 0.314 4.244 0.242\n",
      "945 m461.txt 0.304 4.567 0.287\n"
     ]
    }
   ],
   "source": [
    "for j in range(499,len(files)):\n",
    "    try:\n",
    "        df = pd.read_csv(files[j],header=None)\n",
    "        df.fillna('nan',inplace=True)\n",
    "        df.columns = ['Speaker','Line','Label','MovieID','MoveiName']\n",
    "\n",
    "        sim = [heuristic_max(df.Line.loc[i],\n",
    "                             df.Line.loc[i+1]) for i in range(len(df)-1)]\n",
    "        df['sim'] = [0]+sim\n",
    "\n",
    "        scores = df.sim.get_values()\n",
    "        labels = df.Label.get_values()\n",
    "\n",
    "        acc,MAE,p_k = texttiling_embedding(labels,scores)\n",
    "\n",
    "        accs.append(acc)\n",
    "        MAEs.append(MAE)\n",
    "        p_ks.append(p_k)\n",
    "        print(j,files[j].split('/')[-1],acc,MAE,p_k)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29023460721868366, 0.12428605092344469)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs),np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.342491507430998, 1.0184881657490008)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MAEs),np.std(MAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2949405520169851, 0.08633173483985833)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(p_ks),np.std(p_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
