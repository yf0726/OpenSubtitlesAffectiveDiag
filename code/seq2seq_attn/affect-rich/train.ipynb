{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from model import Options, Seq2SeqAttn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the command line arguments.\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', type = str, default = '../pre-data/',\n",
    "                    help = 'the directory to the data')\n",
    "\n",
    "parser.add_argument('--word_embeddings_path', type = str, default = '../pre-data/word_embeddings.npy',\n",
    "                    help = 'the directory to the pre-trained word embeddings')\n",
    "parser.add_argument('--VAD_path', type = str, default = '../pre-data/VAD.npy',\n",
    "                    help = 'the directory to VAD')\n",
    "parser.add_argument('--tf_path', type = str, default = '../pre-data/tf.npy',\n",
    "                    help = 'the directory to term frequency')\n",
    "parser.add_argument('--VAD_loss_path', type = str, default = '../pre-data/VAD_loss.npy',\n",
    "                    help = 'the directory to VAD loss for each word')\n",
    "parser.add_argument('--ti_path', type = str, default = '../pre-data/mu_li.npy',\n",
    "                    help = 'the directory to term importance')\n",
    "\n",
    "parser.add_argument('--num_epochs', type = int, default = 5,\n",
    "                    help = 'the number of epochs to train the data')\n",
    "parser.add_argument('--batch_size', type = int, default = 64,\n",
    "                    help = 'the batch size')\n",
    "parser.add_argument('--learning_rate', type = float, default = 0.0001,\n",
    "                    help = 'the learning rate')\n",
    "parser.add_argument('--beam_width', type = int, default = 256,\n",
    "                    help = 'the beam width when decoding')\n",
    "parser.add_argument('--word_embed_size', type = int, default = 256,\n",
    "                    help = 'the size of word embeddings')\n",
    "parser.add_argument('--n_hidden_units_enc', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of encoder')\n",
    "parser.add_argument('--n_hidden_units_dec', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of decoder')\n",
    "# ? attn_depth\n",
    "parser.add_argument('--attn_depth', type = int, default = 128,\n",
    "                    help = 'attention depth')\n",
    "parser.add_argument('--restore_path', type = str, default = '../model_dailydialog_rf',\n",
    "                    help = 'the path to restore the trained model')\n",
    "parser.add_argument('--restore_epoch', type = int, default = 0,\n",
    "                    help = 'the epoch to restore')\n",
    "\n",
    "parser.add_argument('--save_path', type = str, default = '../model_dailydialog_rf',\n",
    "                    help = 'the path to save the trained model to')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    def load_np_files(path):\n",
    "        my_set = {}\n",
    "        my_set['enc_input'] = np.load(os.path.join(path, 'enc_input.npy'))\n",
    "        my_set['dec_input'] = np.load(os.path.join(path, 'dec_input.npy'))\n",
    "        my_set['target'] = np.load(os.path.join(path, 'target.npy'))\n",
    "        my_set['enc_input_len'] = np.load(os.path.join(path, 'enc_input_len.npy'))\n",
    "        my_set['dec_input_len'] = np.load(os.path.join(path, 'dec_input_len.npy'))\n",
    "        return my_set\n",
    "    train_set = load_np_files(os.path.join(data_path, 'train'))\n",
    "    valid_set = load_np_files(os.path.join(data_path, 'validation'))\n",
    "    with open(os.path.join(data_path, 'token2id.pickle'), 'rb') as file:\n",
    "        token2id = pickle.load(file)\n",
    "\n",
    "    return train_set, valid_set, token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the TensorFlow graph...\n",
      "embedding/word_embeddings:0\n",
      "encoding/rnn/gru_cell/gates/kernel:0\n",
      "encoding/rnn/gru_cell/gates/bias:0\n",
      "encoding/rnn/gru_cell/candidate/kernel:0\n",
      "encoding/rnn/gru_cell/candidate/bias:0\n",
      "decoding/memory_layer/kernel:0\n",
      "decoding/attention_v:0\n",
      "decoding/my_bahdanau_attention/query_layer/kernel:0\n",
      "decoding/my_bahdanau_attention/dense/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/bias:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/bias:0\n",
      "decoding/dense/kernel:0\n",
      "decoding/dense/bias:0\n",
      "TensorFlow variables initialized.\n",
      "Start to train the model...\n",
      "Epoch 001/005, valid ppl = None, batch 0001/0002, train loss = 8.131671905517578,test_score=[[0.33333334 0.33333334 0.33333334 ... 0.         0.         0.        ]\n",
      " [0.07142857 0.07142857 0.07142857 ... 0.         0.         0.        ]\n",
      " [0.08333334 0.08333334 0.08333334 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]]\n",
      "Epoch 001/005, valid ppl = None, batch 0002/0002, train loss = 8.116786003112793,test_score=[[0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]]\n",
      "Saving the trained model to ../model_dailydialog_rf/model_epoch_001.ckpt...\n",
      "Epoch 002/005, valid ppl = 3257.0146499438424, batch 0001/0002, train loss = 8.08704948425293,test_score=[[0.09090909 0.09090909 0.09090909 ... 0.         0.         0.        ]\n",
      " [0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " [0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.07692308 0.07692308 0.07692308 ... 0.         0.         0.        ]\n",
      " [0.06666667 0.06666667 0.06666667 ... 0.         0.         0.        ]\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]]\n",
      "Epoch 002/005, valid ppl = 3257.0146499438424, batch 0002/0002, train loss = 8.05186653137207,test_score=[[0.09090909 0.09090909 0.09090909 ... 0.         0.         0.        ]\n",
      " [0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " [0.1        0.1        0.1        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]]\n",
      "Saving the trained model to ../model_dailydialog_rf/model_epoch_002.ckpt...\n",
      "Epoch 003/005, valid ppl = 3110.095159385421, batch 0001/0002, train loss = 8.031251907348633,test_score=[[0.1        0.1        0.1        ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " [0.5        0.5        0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]\n",
      " [0.08333334 0.08333334 0.08333334 ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]]\n",
      "Epoch 003/005, valid ppl = 3110.095159385421, batch 0002/0002, train loss = 8.001907348632812,test_score=[[0.08333334 0.08333334 0.08333334 ... 0.         0.         0.        ]\n",
      " [0.07142857 0.07142857 0.07142857 ... 0.         0.         0.        ]\n",
      " [0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]]\n",
      "Saving the trained model to ../model_dailydialog_rf/model_epoch_003.ckpt...\n",
      "Epoch 004/005, valid ppl = 2970.2551856383084, batch 0001/0002, train loss = 7.972570896148682,test_score=[[0.07142857 0.07142857 0.07142857 ... 0.         0.         0.        ]\n",
      " [0.1        0.1        0.1        ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.25       0.25       0.25       ... 0.         0.         0.        ]\n",
      " [0.14285715 0.14285715 0.14285715 ... 0.         0.         0.        ]\n",
      " [0.2        0.2        0.2        ... 0.         0.         0.        ]]\n",
      "Epoch 004/005, valid ppl = 2970.2551856383084, batch 0002/0002, train loss = 7.953454494476318,test_score=[[0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.1        0.1        0.1        ... 0.         0.         0.        ]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.07142857 0.07142857 0.07142857 ... 0.         0.         0.        ]]\n",
      "Saving the trained model to ../model_dailydialog_rf/model_epoch_004.ckpt...\n",
      "Epoch 005/005, valid ppl = 2835.3276607961884, batch 0001/0002, train loss = 7.917879104614258,test_score=[[0.05263158 0.05263158 0.05263158 ... 0.05263158 0.05263158 0.05263158]\n",
      " [0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.33333334 0.33333334 0.33333334 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.16666667 0.16666667 0.16666667 ... 0.         0.         0.        ]\n",
      " [0.08333334 0.08333334 0.08333334 ... 0.         0.         0.        ]\n",
      " [0.08333334 0.08333334 0.08333334 ... 0.         0.         0.        ]]\n",
      "Epoch 005/005, valid ppl = 2835.3276607961884, batch 0002/0002, train loss = 7.901999473571777,test_score=[[0.125      0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.09090909 0.09090909 0.09090909 ... 0.         0.         0.        ]\n",
      " [0.25       0.25       0.25       ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.25       0.25       0.25       ... 0.         0.         0.        ]\n",
      " [0.11111111 0.11111111 0.11111111 ... 0.         0.         0.        ]\n",
      " [0.33333334 0.33333334 0.33333334 ... 0.         0.         0.        ]]\n",
      "Saving the trained model to ../model_dailydialog_rf/model_epoch_005.ckpt...\n",
      "Epoch 001, valid ppl = 3257.0146499438424\n",
      "Epoch 002, valid ppl = 3110.095159385421\n",
      "Epoch 003, valid ppl = 2970.2551856383084\n",
      "Epoch 004, valid ppl = 2835.3276607961884\n",
      "Epoch 005, valid ppl = 2703.575585123278\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, valid_set, token2id = read_data(args.data_path)\n",
    "    train_set['enc_input'] = train_set['enc_input'][:1280,]\n",
    "    \n",
    "    max_uttr_len_enc = train_set['enc_input'].shape[1]\n",
    "    max_uttr_len_dec = train_set['dec_input'].shape[1]\n",
    "\n",
    "    word_embeddings = np.load(args.word_embeddings_path)\n",
    "    VAD = np.load(args.VAD_path)\n",
    "    termfreq = np.load(args.ti_path) # term importance\n",
    "    termfreq = termfreq.reshape(-1,1)\n",
    "    VAD_loss = np.load(args.VAD_loss_path)\n",
    "    VAD_loss = VAD_loss.reshape(-1,1)\n",
    "    \n",
    "    options = Options(mode = 'TRAIN',\n",
    "                      num_epochs = args.num_epochs,\n",
    "                      batch_size = args.batch_size,\n",
    "                      learning_rate = args.learning_rate,\n",
    "                      beam_width = args.beam_width,\n",
    "                      vocab_size = len(token2id),\n",
    "                      max_uttr_len_enc = max_uttr_len_enc,\n",
    "                      max_uttr_len_dec = max_uttr_len_dec,\n",
    "                      go_index = token2id['<go>'],\n",
    "                      eos_index = token2id['<eos>'],\n",
    "                      word_embed_size = args.word_embed_size,\n",
    "                      n_hidden_units_enc = args.n_hidden_units_enc,\n",
    "                      n_hidden_units_dec = args.n_hidden_units_dec,\n",
    "                      attn_depth = args.attn_depth,\n",
    "                      word_embeddings = word_embeddings,\n",
    "                      corpus_size = VAD.shape[0])\n",
    "    model = Seq2SeqAttn(options)\n",
    "\n",
    "    for var in model.tvars:\n",
    "        print(var.name)\n",
    "\n",
    "    if args.restore_epoch > 0:\n",
    "        model.restore(os.path.join(args.restore_path, 'model_epoch_{:03d}.ckpt'.format(args.restore_epoch)))\n",
    "    else:\n",
    "        model.init_tf_vars()\n",
    "    model.train(train_set, VAD,termfreq, VAD_loss,args.save_path, args.restore_epoch, valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
