{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from model import Options, Seq2SeqAttn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the command line arguments.\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', type = str, default = '../pre-data/',\n",
    "                    help = 'the directory to the data')\n",
    "\n",
    "parser.add_argument('--word_embeddings_path', type = str, default = '../pre-data/word_embeddings.npy',\n",
    "                    help = 'the directory to the pre-trained word embeddings')\n",
    "parser.add_argument('--VAD_path', type = str, default = '../pre-data/VAD.npy',\n",
    "                    help = 'the directory to VAD')\n",
    "parser.add_argument('--tf_path', type = str, default = '../pre-data/tf.npy',\n",
    "                    help = 'the directory to term frequency')\n",
    "\n",
    "parser.add_argument('--num_epochs', type = int, default = 1,\n",
    "                    help = 'the number of epochs to train the data')\n",
    "parser.add_argument('--batch_size', type = int, default = 1,\n",
    "                    help = 'the batch size')\n",
    "parser.add_argument('--learning_rate', type = float, default = 0.001,\n",
    "                    help = 'the learning rate')\n",
    "parser.add_argument('--beam_width', type = int, default = 256,\n",
    "                    help = 'the beam width when decoding')\n",
    "parser.add_argument('--word_embed_size', type = int, default = 256,\n",
    "                    help = 'the size of word embeddings')\n",
    "parser.add_argument('--n_hidden_units_enc', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of encoder')\n",
    "parser.add_argument('--n_hidden_units_dec', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of decoder')\n",
    "# ? attn_depth\n",
    "parser.add_argument('--attn_depth', type = int, default = 128,\n",
    "                    help = 'attention depth')\n",
    "parser.add_argument('--restore_path', type = str, default = '../model_dailydialog_rf',\n",
    "                    help = 'the path to restore the trained model')\n",
    "parser.add_argument('--restore_epoch', type = int, default = 0,\n",
    "                    help = 'the epoch to restore')\n",
    "\n",
    "parser.add_argument('--save_path', type = str, default = '../model_dailydialog_rf',\n",
    "                    help = 'the path to save the trained model to')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    def load_np_files(path):\n",
    "        my_set = {}\n",
    "        my_set['enc_input'] = np.load(os.path.join(path, 'enc_input.npy'))\n",
    "        my_set['dec_input'] = np.load(os.path.join(path, 'dec_input.npy'))\n",
    "        my_set['target'] = np.load(os.path.join(path, 'target.npy'))\n",
    "        my_set['enc_input_len'] = np.load(os.path.join(path, 'enc_input_len.npy'))\n",
    "        my_set['dec_input_len'] = np.load(os.path.join(path, 'dec_input_len.npy'))\n",
    "        return my_set\n",
    "    train_set = load_np_files(os.path.join(data_path, 'train'))\n",
    "    valid_set = load_np_files(os.path.join(data_path, 'validation'))\n",
    "    with open(os.path.join(data_path, 'token2id.pickle'), 'rb') as file:\n",
    "        token2id = pickle.load(file)\n",
    "\n",
    "    return train_set, valid_set, token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the TensorFlow graph...\n",
      "embedding/word_embeddings:0\n",
      "encoding/rnn/gru_cell/gates/kernel:0\n",
      "encoding/rnn/gru_cell/gates/bias:0\n",
      "encoding/rnn/gru_cell/candidate/kernel:0\n",
      "encoding/rnn/gru_cell/candidate/bias:0\n",
      "decoding/memory_layer/kernel:0\n",
      "decoding/attention_v:0\n",
      "decoding/attention_Wb:0\n",
      "decoding/my_bahdanau_attention/query_layer/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/bias:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/bias:0\n",
      "decoding/dense/kernel:0\n",
      "decoding/dense/bias:0\n",
      "TensorFlow variables initialized.\n",
      "Start to train the model...\n",
      "Epoch 001/001, valid ppl = None, batch 0001/0508, train loss = 7.15625524520874\n",
      "Epoch 001/001, valid ppl = None, batch 0002/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0003/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0004/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0005/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0006/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0007/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0008/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0009/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0010/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0011/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0012/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0013/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0014/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0015/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0016/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0017/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0018/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0019/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0020/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0021/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0022/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0023/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0024/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0025/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0026/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0027/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0028/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0029/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0030/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0031/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0032/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0033/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0034/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0035/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0036/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0037/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0038/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0039/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0040/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0041/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0042/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0043/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0044/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0045/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0046/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0047/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0048/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0049/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0050/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0051/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0052/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0053/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0054/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0055/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0056/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0057/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0058/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0059/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0060/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0061/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0062/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0063/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0064/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0065/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0066/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0067/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0068/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0069/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0070/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0071/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0072/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0073/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0074/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0075/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0076/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0077/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0078/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0079/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0080/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0081/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0082/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0083/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0084/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0085/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0086/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0087/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0088/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0089/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0090/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0091/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0092/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0093/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0094/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0095/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0096/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0097/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0098/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0099/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0100/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0101/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0102/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0103/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0104/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0105/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0106/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0107/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0108/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0109/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0110/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0111/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0112/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0113/0508, train loss = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/001, valid ppl = None, batch 0114/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0115/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0116/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0117/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0118/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0119/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0120/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0121/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0122/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0123/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0124/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0125/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0126/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0127/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0128/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0129/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0130/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0131/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0132/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0133/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0134/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0135/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0136/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0137/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0138/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0139/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0140/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0141/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0142/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0143/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0144/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0145/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0146/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0147/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0148/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0149/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0150/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0151/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0152/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0153/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0154/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0155/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0156/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0157/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0158/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0159/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0160/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0161/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0162/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0163/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0164/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0165/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0166/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0167/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0168/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0169/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0170/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0171/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0172/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0173/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0174/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0175/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0176/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0177/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0178/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0179/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0180/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0181/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0182/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0183/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0184/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0185/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0186/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0187/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0188/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0189/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0190/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0191/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0192/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0193/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0194/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0195/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0196/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0197/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0198/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0199/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0200/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0201/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0202/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0203/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0204/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0205/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0206/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0207/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0208/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0209/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0210/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0211/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0212/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0213/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0214/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0215/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0216/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0217/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0218/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0219/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0220/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0221/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0222/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0223/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0224/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0225/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0226/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0227/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0228/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0229/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0230/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0231/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0232/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0233/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0234/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0235/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0236/0508, train loss = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/001, valid ppl = None, batch 0237/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0238/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0239/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0240/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0241/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0242/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0243/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0244/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0245/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0246/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0247/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0248/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0249/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0250/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0251/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0252/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0253/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0254/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0255/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0256/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0257/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0258/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0259/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0260/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0261/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0262/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0263/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0264/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0265/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0266/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0267/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0268/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0269/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0270/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0271/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0272/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0273/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0274/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0275/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0276/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0277/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0278/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0279/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0280/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0281/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0282/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0283/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0284/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0285/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0286/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0287/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0288/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0289/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0290/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0291/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0292/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0293/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0294/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0295/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0296/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0297/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0298/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0299/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0300/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0301/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0302/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0303/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0304/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0305/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0306/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0307/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0308/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0309/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0310/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0311/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0312/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0313/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0314/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0315/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0316/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0317/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0318/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0319/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0320/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0321/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0322/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0323/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0324/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0325/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0326/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0327/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0328/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0329/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0330/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0331/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0332/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0333/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0334/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0335/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0336/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0337/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0338/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0339/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0340/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0341/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0342/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0343/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0344/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0345/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0346/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0347/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0348/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0349/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0350/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0351/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0352/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0353/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0354/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0355/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0356/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0357/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0358/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0359/0508, train loss = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/001, valid ppl = None, batch 0360/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0361/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0362/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0363/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0364/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0365/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0366/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0367/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0368/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0369/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0370/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0371/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0372/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0373/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0374/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0375/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0376/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0377/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0378/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0379/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0380/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0381/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0382/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0383/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0384/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0385/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0386/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0387/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0388/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0389/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0390/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0391/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0392/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0393/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0394/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0395/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0396/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0397/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0398/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0399/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0400/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0401/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0402/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0403/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0404/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0405/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0406/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0407/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0408/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0409/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0410/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0411/0508, train loss = nan\n",
      "Epoch 001/001, valid ppl = None, batch 0412/0508, train loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6ed27d38070d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tf_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_set, VAD, termfreq, save_path, restore_epoch, valid_set)\u001b[0m\n\u001b[1;32m    241\u001b[0m                              self.termfreq: termfreq}\n\u001b[1;32m    242\u001b[0m \u001b[0;31m#                              self.termfreq: train_set['termfreq'][batch_indices]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 print('Epoch {:03d}/{:03d}, valid ppl = {}, batch {:04d}/{:04d}, train loss = {}'.format(epoch + 1,\n\u001b[1;32m    245\u001b[0m                     opts.num_epochs, valid_ppl[-1], batch + 1, num_batches, loss_val), flush = True)\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, valid_set, token2id = read_data(args.data_path)\n",
    "    max_uttr_len_enc = train_set['enc_input'].shape[1]\n",
    "    max_uttr_len_dec = train_set['dec_input'].shape[1]\n",
    "\n",
    "    word_embeddings = np.load(args.word_embeddings_path)\n",
    "    VAD = np.load(args.VAD_path)\n",
    "    termfreq = np.load(args.tf_path)\n",
    "    termfreq = termfreq.reshape(-1,1)\n",
    "\n",
    "    options = Options(mode = 'TRAIN',\n",
    "                      num_epochs = args.num_epochs,\n",
    "                      batch_size = args.batch_size,\n",
    "                      learning_rate = args.learning_rate,\n",
    "                      beam_width = args.beam_width,\n",
    "                      vocab_size = len(token2id),\n",
    "                      max_uttr_len_enc = max_uttr_len_enc,\n",
    "                      max_uttr_len_dec = max_uttr_len_dec,\n",
    "                      go_index = token2id['<go>'],\n",
    "                      eos_index = token2id['<eos>'],\n",
    "                      word_embed_size = args.word_embed_size,\n",
    "                      n_hidden_units_enc = args.n_hidden_units_enc,\n",
    "                      n_hidden_units_dec = args.n_hidden_units_dec,\n",
    "                      attn_depth = args.attn_depth,\n",
    "                      word_embeddings = word_embeddings,\n",
    "                      corpus_size = VAD.shape[0])\n",
    "    model = Seq2SeqAttn(options)\n",
    "\n",
    "    for var in model.tvars:\n",
    "        print(var.name)\n",
    "\n",
    "    if args.restore_epoch > 0:\n",
    "        model.restore(os.path.join(args.restore_path, 'model_epoch_{:03d}.ckpt'.format(args.restore_epoch)))\n",
    "    else:\n",
    "        model.init_tf_vars()\n",
    "    model.train(train_set, VAD,termfreq, args.save_path, args.restore_epoch, valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
