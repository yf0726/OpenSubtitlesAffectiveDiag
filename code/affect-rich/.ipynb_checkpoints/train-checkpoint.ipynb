{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from model import Options, Seq2SeqAttn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the command line arguments.\n",
    "save_dir = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/input/'\n",
    "output_dir = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/output/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', type = str, default = save_dir,\n",
    "                    help = 'the directory to the data')\n",
    "\n",
    "parser.add_argument('--word_embeddings_path', type = str, default = save_dir+'word_embeddings.npy',\n",
    "                    help = 'the directory to the pre-trained word embeddings')\n",
    "parser.add_argument('--VAD_path', type = str, default = save_dir+'VAD.npy',\n",
    "                    help = 'the directory to VAD')\n",
    "parser.add_argument('--tf_path', type = str, default = save_dir+'tf.npy',\n",
    "                    help = 'the directory to term frequency')\n",
    "parser.add_argument('--VAD_loss_path', type = str, default = save_dir+'VAD_loss.npy',\n",
    "                    help = 'the directory to VAD loss for each word')\n",
    "parser.add_argument('--ti_path', type = str, default = save_dir+'mu_li.npy',\n",
    "                    help = 'the directory to term importance')\n",
    "\n",
    "parser.add_argument('--num_epochs', type = int, default = 3,\n",
    "                    help = 'the number of epochs to train the data')\n",
    "parser.add_argument('--batch_size', type = int, default = 64,\n",
    "                    help = 'the batch size')\n",
    "parser.add_argument('--learning_rate', type = float, default = 0.001,\n",
    "                    help = 'the learning rate')\n",
    "parser.add_argument('--beam_width', type = int, default = 32,\n",
    "                    help = 'the beam width when decoding')\n",
    "parser.add_argument('--word_embed_size', type = int, default = 300,\n",
    "                    help = 'the size of word embeddings')\n",
    "parser.add_argument('--n_hidden_units_enc', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of encoder')\n",
    "parser.add_argument('--n_hidden_units_dec', type = int, default = 256,\n",
    "                    help = 'the number of hidden units of decoder')\n",
    "# ? attn_depth\n",
    "parser.add_argument('--attn_depth', type = int, default = 128,\n",
    "                    help = 'attention depth')\n",
    "\n",
    "parser.add_argument('--restore_path_TS', type = str, default = output_dir+'model_dailydialog_rf/model_TS',\n",
    "                    help = 'the path to restore the trained model')\n",
    "parser.add_argument('--save_path_TS', type = str, default = output_dir+'/model_dailydialog_rf/model_TS',\n",
    "                    help = 'the path to save the trained model to')\n",
    "\n",
    "parser.add_argument('--restore_path_ST', type = str, default = output_dir+'model_dailydialog_rf/model_ST',\n",
    "                    help = 'the path to restore the trained model')\n",
    "parser.add_argument('--save_path_ST', type = str, default = output_dir+'/model_dailydialog_rf/model_ST',\n",
    "                    help = 'the path to save the trained model to')\n",
    "\n",
    "parser.add_argument('--restore_epoch', type = int, default = 0,\n",
    "                    help = 'the epoch to restore')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    def load_np_files(path):\n",
    "        my_set = {}\n",
    "        my_set['enc_input'] = np.load(os.path.join(path, 'enc_input.npy'))\n",
    "        my_set['dec_input'] = np.load(os.path.join(path, 'dec_input.npy'))\n",
    "        my_set['target'] = np.load(os.path.join(path, 'target.npy'))\n",
    "        my_set['enc_input_len'] = np.load(os.path.join(path, 'enc_input_len.npy'))\n",
    "        my_set['dec_input_len'] = np.load(os.path.join(path, 'dec_input_len.npy'))\n",
    "        # to check if or not to complete the last batch\n",
    "        idx = np.arange(my_set['dec_input'].shape[0])\n",
    "        left_samples = idx[-1]%args.batch_size\n",
    "        if left_samples:\n",
    "            last_batch_idx = np.random.randint(0,idx[-1]-left_samples,size = args.batch_size - left_samples - 1)\n",
    "            idx = np.concatenate([idx,last_batch_idx])\n",
    "            \n",
    "            my_set['enc_input'] = my_set['enc_input'][idx]\n",
    "            my_set['dec_input'] = my_set['dec_input'][idx]\n",
    "            my_set['target'] = my_set['target'][idx]\n",
    "            my_set['enc_input_len'] = my_set['enc_input_len'][idx]\n",
    "            my_set['dec_input_len'] = my_set['dec_input_len'][idx]\n",
    "        return my_set\n",
    "    train_set = load_np_files(os.path.join(data_path, 'train'))\n",
    "    valid_set = load_np_files(os.path.join(data_path, 'validation'))\n",
    "    \n",
    "    with open(os.path.join(data_path, 'token2id.pickle'), 'rb') as file:\n",
    "        token2id = pickle.load(file)\n",
    "    with open(os.path.join(data_path, 'id2token.pickle'), 'rb') as file:\n",
    "        id2token = pickle.load(file)\n",
    "\n",
    "    return train_set, valid_set, token2id,id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Train model maximizing P(T|S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, token2id,id2token = read_data(args.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46400, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['enc_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the TensorFlow graph...\n",
      "TensorFlow session is closed.\n",
      "embedding/embedding:0\n",
      "encoding/rnn/gru_cell/gates/kernel:0\n",
      "encoding/rnn/gru_cell/gates/bias:0\n",
      "encoding/rnn/gru_cell/candidate/kernel:0\n",
      "encoding/rnn/gru_cell/candidate/bias:0\n",
      "decoding/memory_layer/kernel:0\n",
      "decoding/attention_v:0\n",
      "decoding/my_bahdanau_attention/query_layer/kernel:0\n",
      "decoding/my_bahdanau_attention/attention_Wb/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/bias:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/bias:0\n",
      "decoding/dense/kernel:0\n",
      "decoding/dense/bias:0\n",
      "TensorFlow variables initialized.\n",
      "Start to train the model...\n",
      "Epoch 001/003, valid ppl = None, batch 0001/0725, train loss = 9.971991539001465\n",
      "Epoch 001/003, valid ppl = None, batch 0002/0725, train loss = 9.963825225830078\n",
      "Epoch 001/003, valid ppl = None, batch 0003/0725, train loss = 9.938911437988281\n",
      "Epoch 001/003, valid ppl = None, batch 0004/0725, train loss = 9.929741859436035\n",
      "Epoch 001/003, valid ppl = None, batch 0005/0725, train loss = 9.922157287597656\n",
      "Epoch 001/003, valid ppl = None, batch 0006/0725, train loss = 9.89394474029541\n",
      "Epoch 001/003, valid ppl = None, batch 0007/0725, train loss = 9.873821258544922\n",
      "Epoch 001/003, valid ppl = None, batch 0008/0725, train loss = 9.862236976623535\n",
      "Epoch 001/003, valid ppl = None, batch 0009/0725, train loss = 9.87047004699707\n",
      "Epoch 001/003, valid ppl = None, batch 0010/0725, train loss = 9.843811988830566\n",
      "Epoch 001/003, valid ppl = None, batch 0011/0725, train loss = 9.818928718566895\n",
      "Epoch 001/003, valid ppl = None, batch 0012/0725, train loss = 9.768547058105469\n",
      "Epoch 001/003, valid ppl = None, batch 0013/0725, train loss = 9.80137825012207\n",
      "Epoch 001/003, valid ppl = None, batch 0014/0725, train loss = 9.753385543823242\n",
      "Epoch 001/003, valid ppl = None, batch 0015/0725, train loss = 9.729947090148926\n",
      "Epoch 001/003, valid ppl = None, batch 0016/0725, train loss = 9.687244415283203\n",
      "Epoch 001/003, valid ppl = None, batch 0017/0725, train loss = 9.684529304504395\n",
      "Epoch 001/003, valid ppl = None, batch 0018/0725, train loss = 9.685799598693848\n",
      "Epoch 001/003, valid ppl = None, batch 0019/0725, train loss = 9.678603172302246\n",
      "Epoch 001/003, valid ppl = None, batch 0020/0725, train loss = 9.657007217407227\n",
      "Epoch 001/003, valid ppl = None, batch 0021/0725, train loss = 9.640189170837402\n",
      "Epoch 001/003, valid ppl = None, batch 0022/0725, train loss = 9.61752986907959\n",
      "Epoch 001/003, valid ppl = None, batch 0023/0725, train loss = 9.539448738098145\n",
      "Epoch 001/003, valid ppl = None, batch 0024/0725, train loss = 9.502635955810547\n",
      "Epoch 001/003, valid ppl = None, batch 0025/0725, train loss = 9.579358100891113\n",
      "Epoch 001/003, valid ppl = None, batch 0026/0725, train loss = 9.48092269897461\n",
      "Epoch 001/003, valid ppl = None, batch 0027/0725, train loss = 9.4625244140625\n",
      "Epoch 001/003, valid ppl = None, batch 0028/0725, train loss = 9.423355102539062\n",
      "Epoch 001/003, valid ppl = None, batch 0029/0725, train loss = 9.403194427490234\n",
      "Epoch 001/003, valid ppl = None, batch 0030/0725, train loss = 9.358738899230957\n",
      "Epoch 001/003, valid ppl = None, batch 0031/0725, train loss = 9.309123992919922\n",
      "Epoch 001/003, valid ppl = None, batch 0032/0725, train loss = 9.354525566101074\n",
      "Epoch 001/003, valid ppl = None, batch 0033/0725, train loss = 9.211501121520996\n",
      "Epoch 001/003, valid ppl = None, batch 0034/0725, train loss = 9.236900329589844\n",
      "Epoch 001/003, valid ppl = None, batch 0035/0725, train loss = 9.19715690612793\n",
      "Epoch 001/003, valid ppl = None, batch 0036/0725, train loss = 9.127613067626953\n",
      "Epoch 001/003, valid ppl = None, batch 0037/0725, train loss = 9.029731750488281\n",
      "Epoch 001/003, valid ppl = None, batch 0038/0725, train loss = 8.915031433105469\n",
      "Epoch 001/003, valid ppl = None, batch 0039/0725, train loss = 8.923213958740234\n",
      "Epoch 001/003, valid ppl = None, batch 0040/0725, train loss = 8.77656364440918\n",
      "Epoch 001/003, valid ppl = None, batch 0041/0725, train loss = 8.656548500061035\n",
      "Epoch 001/003, valid ppl = None, batch 0042/0725, train loss = 8.642680168151855\n",
      "Epoch 001/003, valid ppl = None, batch 0043/0725, train loss = 8.717936515808105\n",
      "Epoch 001/003, valid ppl = None, batch 0044/0725, train loss = 8.373645782470703\n",
      "Epoch 001/003, valid ppl = None, batch 0045/0725, train loss = 8.3903226852417\n",
      "Epoch 001/003, valid ppl = None, batch 0046/0725, train loss = 8.322564125061035\n",
      "Epoch 001/003, valid ppl = None, batch 0047/0725, train loss = 8.241267204284668\n",
      "Epoch 001/003, valid ppl = None, batch 0048/0725, train loss = 8.108731269836426\n",
      "Epoch 001/003, valid ppl = None, batch 0049/0725, train loss = 8.068634986877441\n",
      "Epoch 001/003, valid ppl = None, batch 0050/0725, train loss = 8.162043571472168\n",
      "Epoch 001/003, valid ppl = None, batch 0051/0725, train loss = 8.14142894744873\n",
      "Epoch 001/003, valid ppl = None, batch 0052/0725, train loss = 7.899241924285889\n",
      "Epoch 001/003, valid ppl = None, batch 0053/0725, train loss = 7.814157485961914\n",
      "Epoch 001/003, valid ppl = None, batch 0054/0725, train loss = 7.893831729888916\n",
      "Epoch 001/003, valid ppl = None, batch 0055/0725, train loss = 7.768786907196045\n",
      "Epoch 001/003, valid ppl = None, batch 0056/0725, train loss = 7.848720550537109\n",
      "Epoch 001/003, valid ppl = None, batch 0057/0725, train loss = 7.880517482757568\n",
      "Epoch 001/003, valid ppl = None, batch 0058/0725, train loss = 7.813884735107422\n",
      "Epoch 001/003, valid ppl = None, batch 0059/0725, train loss = 7.851185321807861\n",
      "Epoch 001/003, valid ppl = None, batch 0060/0725, train loss = 7.976894855499268\n",
      "Epoch 001/003, valid ppl = None, batch 0061/0725, train loss = 7.671658039093018\n",
      "Epoch 001/003, valid ppl = None, batch 0062/0725, train loss = 7.4505181312561035\n",
      "Epoch 001/003, valid ppl = None, batch 0063/0725, train loss = 7.516598224639893\n",
      "Epoch 001/003, valid ppl = None, batch 0064/0725, train loss = 7.475370407104492\n",
      "Epoch 001/003, valid ppl = None, batch 0065/0725, train loss = 7.581817150115967\n",
      "Epoch 001/003, valid ppl = None, batch 0066/0725, train loss = 7.354034900665283\n",
      "Epoch 001/003, valid ppl = None, batch 0067/0725, train loss = 7.489773273468018\n",
      "Epoch 001/003, valid ppl = None, batch 0068/0725, train loss = 7.230820178985596\n",
      "Epoch 001/003, valid ppl = None, batch 0069/0725, train loss = 7.330759525299072\n",
      "Epoch 001/003, valid ppl = None, batch 0070/0725, train loss = 7.2777099609375\n",
      "Epoch 001/003, valid ppl = None, batch 0071/0725, train loss = 7.331179141998291\n",
      "Epoch 001/003, valid ppl = None, batch 0072/0725, train loss = 7.189728736877441\n",
      "Epoch 001/003, valid ppl = None, batch 0073/0725, train loss = 7.179346561431885\n",
      "Epoch 001/003, valid ppl = None, batch 0074/0725, train loss = 7.056800365447998\n",
      "Epoch 001/003, valid ppl = None, batch 0075/0725, train loss = 7.145870208740234\n",
      "Epoch 001/003, valid ppl = None, batch 0076/0725, train loss = 7.05073881149292\n",
      "Epoch 001/003, valid ppl = None, batch 0077/0725, train loss = 7.181979179382324\n",
      "Epoch 001/003, valid ppl = None, batch 0078/0725, train loss = 7.116835117340088\n",
      "Epoch 001/003, valid ppl = None, batch 0079/0725, train loss = 7.264216423034668\n",
      "Epoch 001/003, valid ppl = None, batch 0080/0725, train loss = 6.85825252532959\n",
      "Epoch 001/003, valid ppl = None, batch 0081/0725, train loss = 6.827094078063965\n",
      "Epoch 001/003, valid ppl = None, batch 0082/0725, train loss = 7.039834499359131\n",
      "Epoch 001/003, valid ppl = None, batch 0083/0725, train loss = 6.754608154296875\n",
      "Epoch 001/003, valid ppl = None, batch 0084/0725, train loss = 6.85994291305542\n",
      "Epoch 001/003, valid ppl = None, batch 0085/0725, train loss = 6.717609882354736\n",
      "Epoch 001/003, valid ppl = None, batch 0086/0725, train loss = 6.863637447357178\n",
      "Epoch 001/003, valid ppl = None, batch 0087/0725, train loss = 6.911129474639893\n",
      "Epoch 001/003, valid ppl = None, batch 0088/0725, train loss = 6.659008026123047\n",
      "Epoch 001/003, valid ppl = None, batch 0089/0725, train loss = 6.826333522796631\n",
      "Epoch 001/003, valid ppl = None, batch 0090/0725, train loss = 6.6757283210754395\n",
      "Epoch 001/003, valid ppl = None, batch 0091/0725, train loss = 6.6589226722717285\n",
      "Epoch 001/003, valid ppl = None, batch 0092/0725, train loss = 6.665920734405518\n",
      "Epoch 001/003, valid ppl = None, batch 0093/0725, train loss = 6.614409446716309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0094/0725, train loss = 6.5913004875183105\n",
      "Epoch 001/003, valid ppl = None, batch 0095/0725, train loss = 6.527729034423828\n",
      "Epoch 001/003, valid ppl = None, batch 0096/0725, train loss = 6.566829204559326\n",
      "Epoch 001/003, valid ppl = None, batch 0097/0725, train loss = 6.553555965423584\n",
      "Epoch 001/003, valid ppl = None, batch 0098/0725, train loss = 6.611718654632568\n",
      "Epoch 001/003, valid ppl = None, batch 0099/0725, train loss = 6.594954490661621\n",
      "Epoch 001/003, valid ppl = None, batch 0100/0725, train loss = 6.489307880401611\n",
      "Epoch 001/003, valid ppl = None, batch 0101/0725, train loss = 6.447384357452393\n",
      "Epoch 001/003, valid ppl = None, batch 0102/0725, train loss = 6.396202564239502\n",
      "Epoch 001/003, valid ppl = None, batch 0103/0725, train loss = 6.54709005355835\n",
      "Epoch 001/003, valid ppl = None, batch 0104/0725, train loss = 6.341094017028809\n",
      "Epoch 001/003, valid ppl = None, batch 0105/0725, train loss = 6.305828094482422\n",
      "Epoch 001/003, valid ppl = None, batch 0106/0725, train loss = 6.463806629180908\n",
      "Epoch 001/003, valid ppl = None, batch 0107/0725, train loss = 6.21429443359375\n",
      "Epoch 001/003, valid ppl = None, batch 0108/0725, train loss = 6.284547328948975\n",
      "Epoch 001/003, valid ppl = None, batch 0109/0725, train loss = 6.340201377868652\n",
      "Epoch 001/003, valid ppl = None, batch 0110/0725, train loss = 6.130189895629883\n",
      "Epoch 001/003, valid ppl = None, batch 0111/0725, train loss = 6.369490146636963\n",
      "Epoch 001/003, valid ppl = None, batch 0112/0725, train loss = 6.213160991668701\n",
      "Epoch 001/003, valid ppl = None, batch 0113/0725, train loss = 6.354860782623291\n",
      "Epoch 001/003, valid ppl = None, batch 0114/0725, train loss = 6.11923360824585\n",
      "Epoch 001/003, valid ppl = None, batch 0115/0725, train loss = 5.887290000915527\n",
      "Epoch 001/003, valid ppl = None, batch 0116/0725, train loss = 6.183226108551025\n",
      "Epoch 001/003, valid ppl = None, batch 0117/0725, train loss = 6.0740180015563965\n",
      "Epoch 001/003, valid ppl = None, batch 0118/0725, train loss = 6.050844669342041\n",
      "Epoch 001/003, valid ppl = None, batch 0119/0725, train loss = 6.132260322570801\n",
      "Epoch 001/003, valid ppl = None, batch 0120/0725, train loss = 5.929649353027344\n",
      "Epoch 001/003, valid ppl = None, batch 0121/0725, train loss = 6.1649394035339355\n",
      "Epoch 001/003, valid ppl = None, batch 0122/0725, train loss = 5.985363006591797\n",
      "Epoch 001/003, valid ppl = None, batch 0123/0725, train loss = 5.850720405578613\n",
      "Epoch 001/003, valid ppl = None, batch 0124/0725, train loss = 6.097479343414307\n",
      "Epoch 001/003, valid ppl = None, batch 0125/0725, train loss = 5.905072212219238\n",
      "Epoch 001/003, valid ppl = None, batch 0126/0725, train loss = 5.76995325088501\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, valid_set, token2id,id2token = read_data(args.data_path)\n",
    "#     train_set['enc_input'] = train_set['enc_input'][:128,]\n",
    "    \n",
    "    max_uttr_len_enc = train_set['enc_input'].shape[1]\n",
    "    max_uttr_len_dec = train_set['dec_input'].shape[1]\n",
    "\n",
    "    word_embeddings = np.load(args.word_embeddings_path)\n",
    "    VAD = np.load(args.VAD_path)\n",
    "    termfreq = np.load(args.ti_path) # term importance\n",
    "    termfreq = termfreq.reshape(-1,1)\n",
    "    VAD_loss = np.load(args.VAD_loss_path)\n",
    "    VAD_loss = VAD_loss.reshape(-1,1)\n",
    "    \n",
    "    options = Options(mode = 'TRAIN',\n",
    "                      VAD_mode = True,\n",
    "                      num_epochs = args.num_epochs,\n",
    "                      batch_size = args.batch_size,\n",
    "                      learning_rate = args.learning_rate,\n",
    "                      beam_width = args.beam_width,\n",
    "                      corpus_size = len(token2id),\n",
    "                      max_uttr_len_enc = max_uttr_len_enc,\n",
    "                      max_uttr_len_dec = max_uttr_len_dec,\n",
    "                      go_index = token2id['<go>'],\n",
    "                      eos_index = token2id['<eos>'],\n",
    "                      word_embed_size = args.word_embed_size,\n",
    "                      n_hidden_units_enc = args.n_hidden_units_enc,\n",
    "                      n_hidden_units_dec = args.n_hidden_units_dec,\n",
    "                      attn_depth = args.attn_depth,\n",
    "                      word_embeddings = word_embeddings)\n",
    "    model_TS = Seq2SeqAttn(options)\n",
    "\n",
    "    for var in model_TS.tvars:\n",
    "        print(var.name)\n",
    "\n",
    "    if args.restore_epoch > 0:\n",
    "        model_TS.restore(os.path.join(args.restore_path_TS, 'model_epoch_{:03d}.ckpt'.format(args.restore_epoch)))\n",
    "    else:\n",
    "        model_TS.init_tf_vars()\n",
    "    model_TS.train(train_set, VAD,termfreq, VAD_loss,args.save_path_TS, args.restore_epoch, valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Train model P(S|T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert(myset):\n",
    "    enc_input = myset['dec_input'][:,1:]\n",
    "    dec_input =  np.insert(myset['enc_input'], 0, token2id['<go>'], axis=1) # add <go> in the beginning of decoder\n",
    "\n",
    "    target = np.insert(myset['enc_input'], -1, 0, axis=1) \n",
    "    tmp_idx = [np.where(s==0)[0][0] for s in target] \n",
    "    target[np.arange(target.shape[0]),tmp_idx] = token2id['<eos>'] # add <eos> at the end of decoder\n",
    "    \n",
    "    newset = {}\n",
    "    \n",
    "    newset['enc_input'] = enc_input\n",
    "    newset['dec_input'] = dec_input\n",
    "    newset['target'] = target\n",
    "    newset['enc_input_len'] = myset['dec_input_len']\n",
    "    newset['dec_input_len'] = myset['enc_input_len']\n",
    "    return newset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the TensorFlow graph...\n",
      "embedding/embedding:0\n",
      "encoding/rnn/gru_cell/gates/kernel:0\n",
      "encoding/rnn/gru_cell/gates/bias:0\n",
      "encoding/rnn/gru_cell/candidate/kernel:0\n",
      "encoding/rnn/gru_cell/candidate/bias:0\n",
      "decoding/memory_layer/kernel:0\n",
      "decoding/attention_v:0\n",
      "decoding/my_bahdanau_attention/query_layer/kernel:0\n",
      "decoding/my_bahdanau_attention/attention_Wb/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/gates/bias:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/kernel:0\n",
      "decoding/attention_wrapper/gru_cell/candidate/bias:0\n",
      "decoding/dense/kernel:0\n",
      "decoding/dense/bias:0\n",
      "Restoring a pre-trained model from /Users/yan/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/output/model_dailydialog_rf/model_ST/model_epoch_003.ckpt...\n",
      "INFO:tensorflow:Restoring parameters from /Users/yan/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/output/model_dailydialog_rf/model_ST/model_epoch_003.ckpt\n",
      "Start to train the model...\n",
      "Epoch 001/003, valid ppl = None, batch 0001/0644, train loss = 3.2666079998016357\n",
      "Epoch 001/003, valid ppl = None, batch 0002/0644, train loss = 3.336803436279297\n",
      "Epoch 001/003, valid ppl = None, batch 0003/0644, train loss = 3.376894235610962\n",
      "Epoch 001/003, valid ppl = None, batch 0004/0644, train loss = 3.2248053550720215\n",
      "Epoch 001/003, valid ppl = None, batch 0005/0644, train loss = 3.586209774017334\n",
      "Epoch 001/003, valid ppl = None, batch 0006/0644, train loss = 3.6286957263946533\n",
      "Epoch 001/003, valid ppl = None, batch 0007/0644, train loss = 3.5644960403442383\n",
      "Epoch 001/003, valid ppl = None, batch 0008/0644, train loss = 3.6135306358337402\n",
      "Epoch 001/003, valid ppl = None, batch 0009/0644, train loss = 3.5056986808776855\n",
      "Epoch 001/003, valid ppl = None, batch 0010/0644, train loss = 3.280404806137085\n",
      "Epoch 001/003, valid ppl = None, batch 0011/0644, train loss = 3.4034764766693115\n",
      "Epoch 001/003, valid ppl = None, batch 0012/0644, train loss = 3.4891538619995117\n",
      "Epoch 001/003, valid ppl = None, batch 0013/0644, train loss = 3.562598466873169\n",
      "Epoch 001/003, valid ppl = None, batch 0014/0644, train loss = 3.4276232719421387\n",
      "Epoch 001/003, valid ppl = None, batch 0015/0644, train loss = 3.5128815174102783\n",
      "Epoch 001/003, valid ppl = None, batch 0016/0644, train loss = 3.399783134460449\n",
      "Epoch 001/003, valid ppl = None, batch 0017/0644, train loss = 3.4107699394226074\n",
      "Epoch 001/003, valid ppl = None, batch 0018/0644, train loss = 3.364720106124878\n",
      "Epoch 001/003, valid ppl = None, batch 0019/0644, train loss = 3.510704755783081\n",
      "Epoch 001/003, valid ppl = None, batch 0020/0644, train loss = 3.285238265991211\n",
      "Epoch 001/003, valid ppl = None, batch 0021/0644, train loss = 3.453873872756958\n",
      "Epoch 001/003, valid ppl = None, batch 0022/0644, train loss = 3.6482365131378174\n",
      "Epoch 001/003, valid ppl = None, batch 0023/0644, train loss = 3.5968637466430664\n",
      "Epoch 001/003, valid ppl = None, batch 0024/0644, train loss = 3.431739091873169\n",
      "Epoch 001/003, valid ppl = None, batch 0025/0644, train loss = 3.4459686279296875\n",
      "Epoch 001/003, valid ppl = None, batch 0026/0644, train loss = 3.335905075073242\n",
      "Epoch 001/003, valid ppl = None, batch 0027/0644, train loss = 3.312495708465576\n",
      "Epoch 001/003, valid ppl = None, batch 0028/0644, train loss = 3.333197593688965\n",
      "Epoch 001/003, valid ppl = None, batch 0029/0644, train loss = 3.469581365585327\n",
      "Epoch 001/003, valid ppl = None, batch 0030/0644, train loss = 3.4890952110290527\n",
      "Epoch 001/003, valid ppl = None, batch 0031/0644, train loss = 3.421647548675537\n",
      "Epoch 001/003, valid ppl = None, batch 0032/0644, train loss = 3.536774158477783\n",
      "Epoch 001/003, valid ppl = None, batch 0033/0644, train loss = 3.4972198009490967\n",
      "Epoch 001/003, valid ppl = None, batch 0034/0644, train loss = 3.33536958694458\n",
      "Epoch 001/003, valid ppl = None, batch 0035/0644, train loss = 3.3766632080078125\n",
      "Epoch 001/003, valid ppl = None, batch 0036/0644, train loss = 3.3923306465148926\n",
      "Epoch 001/003, valid ppl = None, batch 0037/0644, train loss = 3.4391465187072754\n",
      "Epoch 001/003, valid ppl = None, batch 0038/0644, train loss = 3.412952184677124\n",
      "Epoch 001/003, valid ppl = None, batch 0039/0644, train loss = 3.5471460819244385\n",
      "Epoch 001/003, valid ppl = None, batch 0040/0644, train loss = 3.403721570968628\n",
      "Epoch 001/003, valid ppl = None, batch 0041/0644, train loss = 3.3104703426361084\n",
      "Epoch 001/003, valid ppl = None, batch 0042/0644, train loss = 3.5330300331115723\n",
      "Epoch 001/003, valid ppl = None, batch 0043/0644, train loss = 3.3136146068573\n",
      "Epoch 001/003, valid ppl = None, batch 0044/0644, train loss = 3.1831421852111816\n",
      "Epoch 001/003, valid ppl = None, batch 0045/0644, train loss = 3.3424599170684814\n",
      "Epoch 001/003, valid ppl = None, batch 0046/0644, train loss = 3.6922385692596436\n",
      "Epoch 001/003, valid ppl = None, batch 0047/0644, train loss = 3.3801064491271973\n",
      "Epoch 001/003, valid ppl = None, batch 0048/0644, train loss = 3.366816282272339\n",
      "Epoch 001/003, valid ppl = None, batch 0049/0644, train loss = 3.527738094329834\n",
      "Epoch 001/003, valid ppl = None, batch 0050/0644, train loss = 3.5082831382751465\n",
      "Epoch 001/003, valid ppl = None, batch 0051/0644, train loss = 3.5161967277526855\n",
      "Epoch 001/003, valid ppl = None, batch 0052/0644, train loss = 3.328252077102661\n",
      "Epoch 001/003, valid ppl = None, batch 0053/0644, train loss = 3.3556253910064697\n",
      "Epoch 001/003, valid ppl = None, batch 0054/0644, train loss = 3.5746853351593018\n",
      "Epoch 001/003, valid ppl = None, batch 0055/0644, train loss = 3.758272647857666\n",
      "Epoch 001/003, valid ppl = None, batch 0056/0644, train loss = 3.483124256134033\n",
      "Epoch 001/003, valid ppl = None, batch 0057/0644, train loss = 3.436166286468506\n",
      "Epoch 001/003, valid ppl = None, batch 0058/0644, train loss = 3.352813720703125\n",
      "Epoch 001/003, valid ppl = None, batch 0059/0644, train loss = 3.5156564712524414\n",
      "Epoch 001/003, valid ppl = None, batch 0060/0644, train loss = 3.488542318344116\n",
      "Epoch 001/003, valid ppl = None, batch 0061/0644, train loss = 3.481537103652954\n",
      "Epoch 001/003, valid ppl = None, batch 0062/0644, train loss = 3.3616700172424316\n",
      "Epoch 001/003, valid ppl = None, batch 0063/0644, train loss = 3.3239855766296387\n",
      "Epoch 001/003, valid ppl = None, batch 0064/0644, train loss = 3.318758249282837\n",
      "Epoch 001/003, valid ppl = None, batch 0065/0644, train loss = 3.140591621398926\n",
      "Epoch 001/003, valid ppl = None, batch 0066/0644, train loss = 3.5363264083862305\n",
      "Epoch 001/003, valid ppl = None, batch 0067/0644, train loss = 3.4953601360321045\n",
      "Epoch 001/003, valid ppl = None, batch 0068/0644, train loss = 3.426408529281616\n",
      "Epoch 001/003, valid ppl = None, batch 0069/0644, train loss = 3.652672290802002\n",
      "Epoch 001/003, valid ppl = None, batch 0070/0644, train loss = 3.4622936248779297\n",
      "Epoch 001/003, valid ppl = None, batch 0071/0644, train loss = 3.5898046493530273\n",
      "Epoch 001/003, valid ppl = None, batch 0072/0644, train loss = 3.4869797229766846\n",
      "Epoch 001/003, valid ppl = None, batch 0073/0644, train loss = 3.3814165592193604\n",
      "Epoch 001/003, valid ppl = None, batch 0074/0644, train loss = 3.420374870300293\n",
      "Epoch 001/003, valid ppl = None, batch 0075/0644, train loss = 3.7312121391296387\n",
      "Epoch 001/003, valid ppl = None, batch 0076/0644, train loss = 3.3859479427337646\n",
      "Epoch 001/003, valid ppl = None, batch 0077/0644, train loss = 3.466686248779297\n",
      "Epoch 001/003, valid ppl = None, batch 0078/0644, train loss = 3.3016252517700195\n",
      "Epoch 001/003, valid ppl = None, batch 0079/0644, train loss = 3.2743544578552246\n",
      "Epoch 001/003, valid ppl = None, batch 0080/0644, train loss = 3.5864391326904297\n",
      "Epoch 001/003, valid ppl = None, batch 0081/0644, train loss = 3.5297930240631104\n",
      "Epoch 001/003, valid ppl = None, batch 0082/0644, train loss = 3.620861530303955\n",
      "Epoch 001/003, valid ppl = None, batch 0083/0644, train loss = 3.5278167724609375\n",
      "Epoch 001/003, valid ppl = None, batch 0084/0644, train loss = 3.2847886085510254\n",
      "Epoch 001/003, valid ppl = None, batch 0085/0644, train loss = 3.4111487865448\n",
      "Epoch 001/003, valid ppl = None, batch 0086/0644, train loss = 3.222066640853882\n",
      "Epoch 001/003, valid ppl = None, batch 0087/0644, train loss = 3.490757942199707\n",
      "Epoch 001/003, valid ppl = None, batch 0088/0644, train loss = 3.2973012924194336\n",
      "Epoch 001/003, valid ppl = None, batch 0089/0644, train loss = 3.4297945499420166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0090/0644, train loss = 3.399214506149292\n",
      "Epoch 001/003, valid ppl = None, batch 0091/0644, train loss = 3.545828104019165\n",
      "Epoch 001/003, valid ppl = None, batch 0092/0644, train loss = 3.2699573040008545\n",
      "Epoch 001/003, valid ppl = None, batch 0093/0644, train loss = 3.2847533226013184\n",
      "Epoch 001/003, valid ppl = None, batch 0094/0644, train loss = 3.451704740524292\n",
      "Epoch 001/003, valid ppl = None, batch 0095/0644, train loss = 3.317626476287842\n",
      "Epoch 001/003, valid ppl = None, batch 0096/0644, train loss = 3.354041814804077\n",
      "Epoch 001/003, valid ppl = None, batch 0097/0644, train loss = 3.570060968399048\n",
      "Epoch 001/003, valid ppl = None, batch 0098/0644, train loss = 3.414484977722168\n",
      "Epoch 001/003, valid ppl = None, batch 0099/0644, train loss = 3.440544605255127\n",
      "Epoch 001/003, valid ppl = None, batch 0100/0644, train loss = 3.3308064937591553\n",
      "Epoch 001/003, valid ppl = None, batch 0101/0644, train loss = 3.2305238246917725\n",
      "Epoch 001/003, valid ppl = None, batch 0102/0644, train loss = 3.568769693374634\n",
      "Epoch 001/003, valid ppl = None, batch 0103/0644, train loss = 3.5150649547576904\n",
      "Epoch 001/003, valid ppl = None, batch 0104/0644, train loss = 3.4474029541015625\n",
      "Epoch 001/003, valid ppl = None, batch 0105/0644, train loss = 3.4390504360198975\n",
      "Epoch 001/003, valid ppl = None, batch 0106/0644, train loss = 3.357489824295044\n",
      "Epoch 001/003, valid ppl = None, batch 0107/0644, train loss = 3.5432629585266113\n",
      "Epoch 001/003, valid ppl = None, batch 0108/0644, train loss = 3.5465097427368164\n",
      "Epoch 001/003, valid ppl = None, batch 0109/0644, train loss = 3.0656960010528564\n",
      "Epoch 001/003, valid ppl = None, batch 0110/0644, train loss = 3.243053436279297\n",
      "Epoch 001/003, valid ppl = None, batch 0111/0644, train loss = 3.2746658325195312\n",
      "Epoch 001/003, valid ppl = None, batch 0112/0644, train loss = 3.342040777206421\n",
      "Epoch 001/003, valid ppl = None, batch 0113/0644, train loss = 3.367856740951538\n",
      "Epoch 001/003, valid ppl = None, batch 0114/0644, train loss = 3.2048988342285156\n",
      "Epoch 001/003, valid ppl = None, batch 0115/0644, train loss = 3.4651734828948975\n",
      "Epoch 001/003, valid ppl = None, batch 0116/0644, train loss = 3.439146041870117\n",
      "Epoch 001/003, valid ppl = None, batch 0117/0644, train loss = 3.4184072017669678\n",
      "Epoch 001/003, valid ppl = None, batch 0118/0644, train loss = 3.4622998237609863\n",
      "Epoch 001/003, valid ppl = None, batch 0119/0644, train loss = 3.467038869857788\n",
      "Epoch 001/003, valid ppl = None, batch 0120/0644, train loss = 3.6711976528167725\n",
      "Epoch 001/003, valid ppl = None, batch 0121/0644, train loss = 3.174973964691162\n",
      "Epoch 001/003, valid ppl = None, batch 0122/0644, train loss = 3.4529197216033936\n",
      "Epoch 001/003, valid ppl = None, batch 0123/0644, train loss = 3.4341342449188232\n",
      "Epoch 001/003, valid ppl = None, batch 0124/0644, train loss = 3.4801433086395264\n",
      "Epoch 001/003, valid ppl = None, batch 0125/0644, train loss = 3.266218423843384\n",
      "Epoch 001/003, valid ppl = None, batch 0126/0644, train loss = 3.4810781478881836\n",
      "Epoch 001/003, valid ppl = None, batch 0127/0644, train loss = 3.568472385406494\n",
      "Epoch 001/003, valid ppl = None, batch 0128/0644, train loss = 3.37809157371521\n",
      "Epoch 001/003, valid ppl = None, batch 0129/0644, train loss = 3.305650234222412\n",
      "Epoch 001/003, valid ppl = None, batch 0130/0644, train loss = 3.3001327514648438\n",
      "Epoch 001/003, valid ppl = None, batch 0131/0644, train loss = 3.614675521850586\n",
      "Epoch 001/003, valid ppl = None, batch 0132/0644, train loss = 3.519308090209961\n",
      "Epoch 001/003, valid ppl = None, batch 0133/0644, train loss = 3.2008039951324463\n",
      "Epoch 001/003, valid ppl = None, batch 0134/0644, train loss = 3.387406587600708\n",
      "Epoch 001/003, valid ppl = None, batch 0135/0644, train loss = 3.517467737197876\n",
      "Epoch 001/003, valid ppl = None, batch 0136/0644, train loss = 3.458618640899658\n",
      "Epoch 001/003, valid ppl = None, batch 0137/0644, train loss = 3.3794844150543213\n",
      "Epoch 001/003, valid ppl = None, batch 0138/0644, train loss = 3.625004291534424\n",
      "Epoch 001/003, valid ppl = None, batch 0139/0644, train loss = 3.5330119132995605\n",
      "Epoch 001/003, valid ppl = None, batch 0140/0644, train loss = 3.476897716522217\n",
      "Epoch 001/003, valid ppl = None, batch 0141/0644, train loss = 3.491001844406128\n",
      "Epoch 001/003, valid ppl = None, batch 0142/0644, train loss = 3.4423229694366455\n",
      "Epoch 001/003, valid ppl = None, batch 0143/0644, train loss = 3.4347522258758545\n",
      "Epoch 001/003, valid ppl = None, batch 0144/0644, train loss = 3.257122755050659\n",
      "Epoch 001/003, valid ppl = None, batch 0145/0644, train loss = 3.2730987071990967\n",
      "Epoch 001/003, valid ppl = None, batch 0146/0644, train loss = 3.286350965499878\n",
      "Epoch 001/003, valid ppl = None, batch 0147/0644, train loss = 3.2959020137786865\n",
      "Epoch 001/003, valid ppl = None, batch 0148/0644, train loss = 3.2911219596862793\n",
      "Epoch 001/003, valid ppl = None, batch 0149/0644, train loss = 3.4146528244018555\n",
      "Epoch 001/003, valid ppl = None, batch 0150/0644, train loss = 3.5637686252593994\n",
      "Epoch 001/003, valid ppl = None, batch 0151/0644, train loss = 3.4642159938812256\n",
      "Epoch 001/003, valid ppl = None, batch 0152/0644, train loss = 3.4763526916503906\n",
      "Epoch 001/003, valid ppl = None, batch 0153/0644, train loss = 3.5757453441619873\n",
      "Epoch 001/003, valid ppl = None, batch 0154/0644, train loss = 3.447314500808716\n",
      "Epoch 001/003, valid ppl = None, batch 0155/0644, train loss = 3.5195422172546387\n",
      "Epoch 001/003, valid ppl = None, batch 0156/0644, train loss = 3.478947877883911\n",
      "Epoch 001/003, valid ppl = None, batch 0157/0644, train loss = 3.5096004009246826\n",
      "Epoch 001/003, valid ppl = None, batch 0158/0644, train loss = 3.209832191467285\n",
      "Epoch 001/003, valid ppl = None, batch 0159/0644, train loss = 3.7330105304718018\n",
      "Epoch 001/003, valid ppl = None, batch 0160/0644, train loss = 3.5512747764587402\n",
      "Epoch 001/003, valid ppl = None, batch 0161/0644, train loss = 3.389896869659424\n",
      "Epoch 001/003, valid ppl = None, batch 0162/0644, train loss = 3.4203145503997803\n",
      "Epoch 001/003, valid ppl = None, batch 0163/0644, train loss = 3.411034345626831\n",
      "Epoch 001/003, valid ppl = None, batch 0164/0644, train loss = 3.3940846920013428\n",
      "Epoch 001/003, valid ppl = None, batch 0165/0644, train loss = 3.367391586303711\n",
      "Epoch 001/003, valid ppl = None, batch 0166/0644, train loss = 3.6186723709106445\n",
      "Epoch 001/003, valid ppl = None, batch 0167/0644, train loss = 3.4853243827819824\n",
      "Epoch 001/003, valid ppl = None, batch 0168/0644, train loss = 3.8096792697906494\n",
      "Epoch 001/003, valid ppl = None, batch 0169/0644, train loss = 3.3383610248565674\n",
      "Epoch 001/003, valid ppl = None, batch 0170/0644, train loss = 3.3390066623687744\n",
      "Epoch 001/003, valid ppl = None, batch 0171/0644, train loss = 3.44027042388916\n",
      "Epoch 001/003, valid ppl = None, batch 0172/0644, train loss = 3.2100086212158203\n",
      "Epoch 001/003, valid ppl = None, batch 0173/0644, train loss = 3.4487218856811523\n",
      "Epoch 001/003, valid ppl = None, batch 0174/0644, train loss = 3.5087969303131104\n",
      "Epoch 001/003, valid ppl = None, batch 0175/0644, train loss = 3.242469549179077\n",
      "Epoch 001/003, valid ppl = None, batch 0176/0644, train loss = 3.5776546001434326\n",
      "Epoch 001/003, valid ppl = None, batch 0177/0644, train loss = 3.381944179534912\n",
      "Epoch 001/003, valid ppl = None, batch 0178/0644, train loss = 3.448146343231201\n",
      "Epoch 001/003, valid ppl = None, batch 0179/0644, train loss = 3.3483939170837402\n",
      "Epoch 001/003, valid ppl = None, batch 0180/0644, train loss = 3.442209482192993\n",
      "Epoch 001/003, valid ppl = None, batch 0181/0644, train loss = 3.6050429344177246\n",
      "Epoch 001/003, valid ppl = None, batch 0182/0644, train loss = 3.3530709743499756\n",
      "Epoch 001/003, valid ppl = None, batch 0183/0644, train loss = 3.489177942276001\n",
      "Epoch 001/003, valid ppl = None, batch 0184/0644, train loss = 3.2765555381774902\n",
      "Epoch 001/003, valid ppl = None, batch 0185/0644, train loss = 3.374880790710449\n",
      "Epoch 001/003, valid ppl = None, batch 0186/0644, train loss = 3.100358009338379\n",
      "Epoch 001/003, valid ppl = None, batch 0187/0644, train loss = 3.5295958518981934\n",
      "Epoch 001/003, valid ppl = None, batch 0188/0644, train loss = 3.6368088722229004\n",
      "Epoch 001/003, valid ppl = None, batch 0189/0644, train loss = 3.3071725368499756\n",
      "Epoch 001/003, valid ppl = None, batch 0190/0644, train loss = 3.4834089279174805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0191/0644, train loss = 3.3014495372772217\n",
      "Epoch 001/003, valid ppl = None, batch 0192/0644, train loss = 3.2710516452789307\n",
      "Epoch 001/003, valid ppl = None, batch 0193/0644, train loss = 3.2774171829223633\n",
      "Epoch 001/003, valid ppl = None, batch 0194/0644, train loss = 3.3398709297180176\n",
      "Epoch 001/003, valid ppl = None, batch 0195/0644, train loss = 3.5668599605560303\n",
      "Epoch 001/003, valid ppl = None, batch 0196/0644, train loss = 3.487105369567871\n",
      "Epoch 001/003, valid ppl = None, batch 0197/0644, train loss = 3.5610101222991943\n",
      "Epoch 001/003, valid ppl = None, batch 0198/0644, train loss = 3.3424322605133057\n",
      "Epoch 001/003, valid ppl = None, batch 0199/0644, train loss = 3.426948308944702\n",
      "Epoch 001/003, valid ppl = None, batch 0200/0644, train loss = 3.4501280784606934\n",
      "Epoch 001/003, valid ppl = None, batch 0201/0644, train loss = 3.364928722381592\n",
      "Epoch 001/003, valid ppl = None, batch 0202/0644, train loss = 3.342785120010376\n",
      "Epoch 001/003, valid ppl = None, batch 0203/0644, train loss = 3.4814062118530273\n",
      "Epoch 001/003, valid ppl = None, batch 0204/0644, train loss = 3.44572114944458\n",
      "Epoch 001/003, valid ppl = None, batch 0205/0644, train loss = 3.2070353031158447\n",
      "Epoch 001/003, valid ppl = None, batch 0206/0644, train loss = 3.42618465423584\n",
      "Epoch 001/003, valid ppl = None, batch 0207/0644, train loss = 3.3978960514068604\n",
      "Epoch 001/003, valid ppl = None, batch 0208/0644, train loss = 3.626018524169922\n",
      "Epoch 001/003, valid ppl = None, batch 0209/0644, train loss = 3.431469678878784\n",
      "Epoch 001/003, valid ppl = None, batch 0210/0644, train loss = 3.496006727218628\n",
      "Epoch 001/003, valid ppl = None, batch 0211/0644, train loss = 3.5511815547943115\n",
      "Epoch 001/003, valid ppl = None, batch 0212/0644, train loss = 3.3660261631011963\n",
      "Epoch 001/003, valid ppl = None, batch 0213/0644, train loss = 3.5113279819488525\n",
      "Epoch 001/003, valid ppl = None, batch 0214/0644, train loss = 3.4405105113983154\n",
      "Epoch 001/003, valid ppl = None, batch 0215/0644, train loss = 3.641601085662842\n",
      "Epoch 001/003, valid ppl = None, batch 0216/0644, train loss = 3.3983006477355957\n",
      "Epoch 001/003, valid ppl = None, batch 0217/0644, train loss = 3.3544654846191406\n",
      "Epoch 001/003, valid ppl = None, batch 0218/0644, train loss = 3.171494960784912\n",
      "Epoch 001/003, valid ppl = None, batch 0219/0644, train loss = 3.4657976627349854\n",
      "Epoch 001/003, valid ppl = None, batch 0220/0644, train loss = 3.352710723876953\n",
      "Epoch 001/003, valid ppl = None, batch 0221/0644, train loss = 3.4998881816864014\n",
      "Epoch 001/003, valid ppl = None, batch 0222/0644, train loss = 3.3333799839019775\n",
      "Epoch 001/003, valid ppl = None, batch 0223/0644, train loss = 3.308894395828247\n",
      "Epoch 001/003, valid ppl = None, batch 0224/0644, train loss = 3.3607707023620605\n",
      "Epoch 001/003, valid ppl = None, batch 0225/0644, train loss = 3.396841049194336\n",
      "Epoch 001/003, valid ppl = None, batch 0226/0644, train loss = 3.0821633338928223\n",
      "Epoch 001/003, valid ppl = None, batch 0227/0644, train loss = 3.416767120361328\n",
      "Epoch 001/003, valid ppl = None, batch 0228/0644, train loss = 3.4162285327911377\n",
      "Epoch 001/003, valid ppl = None, batch 0229/0644, train loss = 3.1037373542785645\n",
      "Epoch 001/003, valid ppl = None, batch 0230/0644, train loss = 3.3814704418182373\n",
      "Epoch 001/003, valid ppl = None, batch 0231/0644, train loss = 3.4448890686035156\n",
      "Epoch 001/003, valid ppl = None, batch 0232/0644, train loss = 3.4772469997406006\n",
      "Epoch 001/003, valid ppl = None, batch 0233/0644, train loss = 3.3990726470947266\n",
      "Epoch 001/003, valid ppl = None, batch 0234/0644, train loss = 3.5459938049316406\n",
      "Epoch 001/003, valid ppl = None, batch 0235/0644, train loss = 3.4544856548309326\n",
      "Epoch 001/003, valid ppl = None, batch 0236/0644, train loss = 3.654635190963745\n",
      "Epoch 001/003, valid ppl = None, batch 0237/0644, train loss = 3.378737688064575\n",
      "Epoch 001/003, valid ppl = None, batch 0238/0644, train loss = 3.34204363822937\n",
      "Epoch 001/003, valid ppl = None, batch 0239/0644, train loss = 3.48435378074646\n",
      "Epoch 001/003, valid ppl = None, batch 0240/0644, train loss = 3.2594003677368164\n",
      "Epoch 001/003, valid ppl = None, batch 0241/0644, train loss = 3.40755558013916\n",
      "Epoch 001/003, valid ppl = None, batch 0242/0644, train loss = 3.3645691871643066\n",
      "Epoch 001/003, valid ppl = None, batch 0243/0644, train loss = 3.2558813095092773\n",
      "Epoch 001/003, valid ppl = None, batch 0244/0644, train loss = 3.3925628662109375\n",
      "Epoch 001/003, valid ppl = None, batch 0245/0644, train loss = 3.327838659286499\n",
      "Epoch 001/003, valid ppl = None, batch 0246/0644, train loss = 3.3653202056884766\n",
      "Epoch 001/003, valid ppl = None, batch 0247/0644, train loss = 3.6760036945343018\n",
      "Epoch 001/003, valid ppl = None, batch 0248/0644, train loss = 3.4583029747009277\n",
      "Epoch 001/003, valid ppl = None, batch 0249/0644, train loss = 3.503610134124756\n",
      "Epoch 001/003, valid ppl = None, batch 0250/0644, train loss = 3.3732404708862305\n",
      "Epoch 001/003, valid ppl = None, batch 0251/0644, train loss = 3.441392421722412\n",
      "Epoch 001/003, valid ppl = None, batch 0252/0644, train loss = 3.3977694511413574\n",
      "Epoch 001/003, valid ppl = None, batch 0253/0644, train loss = 3.434164524078369\n",
      "Epoch 001/003, valid ppl = None, batch 0254/0644, train loss = 3.2858307361602783\n",
      "Epoch 001/003, valid ppl = None, batch 0255/0644, train loss = 3.2203025817871094\n",
      "Epoch 001/003, valid ppl = None, batch 0256/0644, train loss = 3.4682910442352295\n",
      "Epoch 001/003, valid ppl = None, batch 0257/0644, train loss = 3.329357624053955\n",
      "Epoch 001/003, valid ppl = None, batch 0258/0644, train loss = 3.328702211380005\n",
      "Epoch 001/003, valid ppl = None, batch 0259/0644, train loss = 3.6152236461639404\n",
      "Epoch 001/003, valid ppl = None, batch 0260/0644, train loss = 3.419748306274414\n",
      "Epoch 001/003, valid ppl = None, batch 0261/0644, train loss = 3.4064559936523438\n",
      "Epoch 001/003, valid ppl = None, batch 0262/0644, train loss = 3.4777989387512207\n",
      "Epoch 001/003, valid ppl = None, batch 0263/0644, train loss = 3.2138190269470215\n",
      "Epoch 001/003, valid ppl = None, batch 0264/0644, train loss = 3.286149501800537\n",
      "Epoch 001/003, valid ppl = None, batch 0265/0644, train loss = 3.4959003925323486\n",
      "Epoch 001/003, valid ppl = None, batch 0266/0644, train loss = 3.543816089630127\n",
      "Epoch 001/003, valid ppl = None, batch 0267/0644, train loss = 3.4817371368408203\n",
      "Epoch 001/003, valid ppl = None, batch 0268/0644, train loss = 3.325544595718384\n",
      "Epoch 001/003, valid ppl = None, batch 0269/0644, train loss = 3.4617278575897217\n",
      "Epoch 001/003, valid ppl = None, batch 0270/0644, train loss = 3.3186399936676025\n",
      "Epoch 001/003, valid ppl = None, batch 0271/0644, train loss = 3.459743022918701\n",
      "Epoch 001/003, valid ppl = None, batch 0272/0644, train loss = 3.3528826236724854\n",
      "Epoch 001/003, valid ppl = None, batch 0273/0644, train loss = 3.3697502613067627\n",
      "Epoch 001/003, valid ppl = None, batch 0274/0644, train loss = 3.5101237297058105\n",
      "Epoch 001/003, valid ppl = None, batch 0275/0644, train loss = 3.3940370082855225\n",
      "Epoch 001/003, valid ppl = None, batch 0276/0644, train loss = 3.367640495300293\n",
      "Epoch 001/003, valid ppl = None, batch 0277/0644, train loss = 3.2867844104766846\n",
      "Epoch 001/003, valid ppl = None, batch 0278/0644, train loss = 3.3619959354400635\n",
      "Epoch 001/003, valid ppl = None, batch 0279/0644, train loss = 3.4746549129486084\n",
      "Epoch 001/003, valid ppl = None, batch 0280/0644, train loss = 3.660531759262085\n",
      "Epoch 001/003, valid ppl = None, batch 0281/0644, train loss = 3.210622787475586\n",
      "Epoch 001/003, valid ppl = None, batch 0282/0644, train loss = 3.4963479042053223\n",
      "Epoch 001/003, valid ppl = None, batch 0283/0644, train loss = 3.3857083320617676\n",
      "Epoch 001/003, valid ppl = None, batch 0284/0644, train loss = 3.33174991607666\n",
      "Epoch 001/003, valid ppl = None, batch 0285/0644, train loss = 3.390878438949585\n",
      "Epoch 001/003, valid ppl = None, batch 0286/0644, train loss = 3.416447401046753\n",
      "Epoch 001/003, valid ppl = None, batch 0287/0644, train loss = 3.43973708152771\n",
      "Epoch 001/003, valid ppl = None, batch 0288/0644, train loss = 3.4902241230010986\n",
      "Epoch 001/003, valid ppl = None, batch 0289/0644, train loss = 3.242027759552002\n",
      "Epoch 001/003, valid ppl = None, batch 0290/0644, train loss = 3.3497719764709473\n",
      "Epoch 001/003, valid ppl = None, batch 0291/0644, train loss = 3.29951810836792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0292/0644, train loss = 3.633577823638916\n",
      "Epoch 001/003, valid ppl = None, batch 0293/0644, train loss = 3.47641658782959\n",
      "Epoch 001/003, valid ppl = None, batch 0294/0644, train loss = 3.461153268814087\n",
      "Epoch 001/003, valid ppl = None, batch 0295/0644, train loss = 3.1805920600891113\n",
      "Epoch 001/003, valid ppl = None, batch 0296/0644, train loss = 3.3204360008239746\n",
      "Epoch 001/003, valid ppl = None, batch 0297/0644, train loss = 3.3599531650543213\n",
      "Epoch 001/003, valid ppl = None, batch 0298/0644, train loss = 3.2904303073883057\n",
      "Epoch 001/003, valid ppl = None, batch 0299/0644, train loss = 3.482123851776123\n",
      "Epoch 001/003, valid ppl = None, batch 0300/0644, train loss = 3.323749303817749\n",
      "Epoch 001/003, valid ppl = None, batch 0301/0644, train loss = 3.425752878189087\n",
      "Epoch 001/003, valid ppl = None, batch 0302/0644, train loss = 3.3481907844543457\n",
      "Epoch 001/003, valid ppl = None, batch 0303/0644, train loss = 3.4876575469970703\n",
      "Epoch 001/003, valid ppl = None, batch 0304/0644, train loss = 3.3620760440826416\n",
      "Epoch 001/003, valid ppl = None, batch 0305/0644, train loss = 3.4171807765960693\n",
      "Epoch 001/003, valid ppl = None, batch 0306/0644, train loss = 3.5377376079559326\n",
      "Epoch 001/003, valid ppl = None, batch 0307/0644, train loss = 3.330406665802002\n",
      "Epoch 001/003, valid ppl = None, batch 0308/0644, train loss = 3.413973569869995\n",
      "Epoch 001/003, valid ppl = None, batch 0309/0644, train loss = 3.5040807723999023\n",
      "Epoch 001/003, valid ppl = None, batch 0310/0644, train loss = 3.326960325241089\n",
      "Epoch 001/003, valid ppl = None, batch 0311/0644, train loss = 3.2783401012420654\n",
      "Epoch 001/003, valid ppl = None, batch 0312/0644, train loss = 3.4005520343780518\n",
      "Epoch 001/003, valid ppl = None, batch 0313/0644, train loss = 3.42877197265625\n",
      "Epoch 001/003, valid ppl = None, batch 0314/0644, train loss = 3.413506269454956\n",
      "Epoch 001/003, valid ppl = None, batch 0315/0644, train loss = 3.450759172439575\n",
      "Epoch 001/003, valid ppl = None, batch 0316/0644, train loss = 3.5038537979125977\n",
      "Epoch 001/003, valid ppl = None, batch 0317/0644, train loss = 3.5250093936920166\n",
      "Epoch 001/003, valid ppl = None, batch 0318/0644, train loss = 3.28135347366333\n",
      "Epoch 001/003, valid ppl = None, batch 0319/0644, train loss = 3.4412479400634766\n",
      "Epoch 001/003, valid ppl = None, batch 0320/0644, train loss = 3.1963417530059814\n",
      "Epoch 001/003, valid ppl = None, batch 0321/0644, train loss = 3.6782336235046387\n",
      "Epoch 001/003, valid ppl = None, batch 0322/0644, train loss = 3.556896686553955\n",
      "Epoch 001/003, valid ppl = None, batch 0323/0644, train loss = 3.197848320007324\n",
      "Epoch 001/003, valid ppl = None, batch 0324/0644, train loss = 3.3094730377197266\n",
      "Epoch 001/003, valid ppl = None, batch 0325/0644, train loss = 3.4151360988616943\n",
      "Epoch 001/003, valid ppl = None, batch 0326/0644, train loss = 3.4936137199401855\n",
      "Epoch 001/003, valid ppl = None, batch 0327/0644, train loss = 3.35485577583313\n",
      "Epoch 001/003, valid ppl = None, batch 0328/0644, train loss = 3.4374074935913086\n",
      "Epoch 001/003, valid ppl = None, batch 0329/0644, train loss = 3.561872720718384\n",
      "Epoch 001/003, valid ppl = None, batch 0330/0644, train loss = 3.3985228538513184\n",
      "Epoch 001/003, valid ppl = None, batch 0331/0644, train loss = 3.314518928527832\n",
      "Epoch 001/003, valid ppl = None, batch 0332/0644, train loss = 3.427530527114868\n",
      "Epoch 001/003, valid ppl = None, batch 0333/0644, train loss = 3.4473607540130615\n",
      "Epoch 001/003, valid ppl = None, batch 0334/0644, train loss = 3.4142682552337646\n",
      "Epoch 001/003, valid ppl = None, batch 0335/0644, train loss = 3.2599411010742188\n",
      "Epoch 001/003, valid ppl = None, batch 0336/0644, train loss = 3.681478261947632\n",
      "Epoch 001/003, valid ppl = None, batch 0337/0644, train loss = 3.3016746044158936\n",
      "Epoch 001/003, valid ppl = None, batch 0338/0644, train loss = 3.349775552749634\n",
      "Epoch 001/003, valid ppl = None, batch 0339/0644, train loss = 3.3650660514831543\n",
      "Epoch 001/003, valid ppl = None, batch 0340/0644, train loss = 3.4623489379882812\n",
      "Epoch 001/003, valid ppl = None, batch 0341/0644, train loss = 3.604543685913086\n",
      "Epoch 001/003, valid ppl = None, batch 0342/0644, train loss = 3.585350275039673\n",
      "Epoch 001/003, valid ppl = None, batch 0343/0644, train loss = 3.408973455429077\n",
      "Epoch 001/003, valid ppl = None, batch 0344/0644, train loss = 3.2314178943634033\n",
      "Epoch 001/003, valid ppl = None, batch 0345/0644, train loss = 3.3987536430358887\n",
      "Epoch 001/003, valid ppl = None, batch 0346/0644, train loss = 3.278843879699707\n",
      "Epoch 001/003, valid ppl = None, batch 0347/0644, train loss = 3.0647084712982178\n",
      "Epoch 001/003, valid ppl = None, batch 0348/0644, train loss = 3.365601062774658\n",
      "Epoch 001/003, valid ppl = None, batch 0349/0644, train loss = 3.5582399368286133\n",
      "Epoch 001/003, valid ppl = None, batch 0350/0644, train loss = 3.183159351348877\n",
      "Epoch 001/003, valid ppl = None, batch 0351/0644, train loss = 3.448032855987549\n",
      "Epoch 001/003, valid ppl = None, batch 0352/0644, train loss = 3.4462811946868896\n",
      "Epoch 001/003, valid ppl = None, batch 0353/0644, train loss = 3.33225679397583\n",
      "Epoch 001/003, valid ppl = None, batch 0354/0644, train loss = 3.4630372524261475\n",
      "Epoch 001/003, valid ppl = None, batch 0355/0644, train loss = 3.4317140579223633\n",
      "Epoch 001/003, valid ppl = None, batch 0356/0644, train loss = 3.3780972957611084\n",
      "Epoch 001/003, valid ppl = None, batch 0357/0644, train loss = 3.2797834873199463\n",
      "Epoch 001/003, valid ppl = None, batch 0358/0644, train loss = 3.3750007152557373\n",
      "Epoch 001/003, valid ppl = None, batch 0359/0644, train loss = 3.4499542713165283\n",
      "Epoch 001/003, valid ppl = None, batch 0360/0644, train loss = 3.2830231189727783\n",
      "Epoch 001/003, valid ppl = None, batch 0361/0644, train loss = 3.1189730167388916\n",
      "Epoch 001/003, valid ppl = None, batch 0362/0644, train loss = 3.381892681121826\n",
      "Epoch 001/003, valid ppl = None, batch 0363/0644, train loss = 3.3923022747039795\n",
      "Epoch 001/003, valid ppl = None, batch 0364/0644, train loss = 3.467738389968872\n",
      "Epoch 001/003, valid ppl = None, batch 0365/0644, train loss = 3.6050291061401367\n",
      "Epoch 001/003, valid ppl = None, batch 0366/0644, train loss = 3.5008950233459473\n",
      "Epoch 001/003, valid ppl = None, batch 0367/0644, train loss = 3.4955809116363525\n",
      "Epoch 001/003, valid ppl = None, batch 0368/0644, train loss = 3.550856828689575\n",
      "Epoch 001/003, valid ppl = None, batch 0369/0644, train loss = 3.242469549179077\n",
      "Epoch 001/003, valid ppl = None, batch 0370/0644, train loss = 3.2181079387664795\n",
      "Epoch 001/003, valid ppl = None, batch 0371/0644, train loss = 3.539503574371338\n",
      "Epoch 001/003, valid ppl = None, batch 0372/0644, train loss = 3.4073476791381836\n",
      "Epoch 001/003, valid ppl = None, batch 0373/0644, train loss = 3.318324327468872\n",
      "Epoch 001/003, valid ppl = None, batch 0374/0644, train loss = 3.5286953449249268\n",
      "Epoch 001/003, valid ppl = None, batch 0375/0644, train loss = 3.391961097717285\n",
      "Epoch 001/003, valid ppl = None, batch 0376/0644, train loss = 3.348559617996216\n",
      "Epoch 001/003, valid ppl = None, batch 0377/0644, train loss = 3.4962260723114014\n",
      "Epoch 001/003, valid ppl = None, batch 0378/0644, train loss = 3.384246587753296\n",
      "Epoch 001/003, valid ppl = None, batch 0379/0644, train loss = 3.194340705871582\n",
      "Epoch 001/003, valid ppl = None, batch 0380/0644, train loss = 3.2206482887268066\n",
      "Epoch 001/003, valid ppl = None, batch 0381/0644, train loss = 3.2364673614501953\n",
      "Epoch 001/003, valid ppl = None, batch 0382/0644, train loss = 3.4961209297180176\n",
      "Epoch 001/003, valid ppl = None, batch 0383/0644, train loss = 3.4294612407684326\n",
      "Epoch 001/003, valid ppl = None, batch 0384/0644, train loss = 3.3949830532073975\n",
      "Epoch 001/003, valid ppl = None, batch 0385/0644, train loss = 3.539334774017334\n",
      "Epoch 001/003, valid ppl = None, batch 0386/0644, train loss = 3.486395835876465\n",
      "Epoch 001/003, valid ppl = None, batch 0387/0644, train loss = 3.192753553390503\n",
      "Epoch 001/003, valid ppl = None, batch 0388/0644, train loss = 3.345076560974121\n",
      "Epoch 001/003, valid ppl = None, batch 0389/0644, train loss = 3.5841922760009766\n",
      "Epoch 001/003, valid ppl = None, batch 0390/0644, train loss = 3.2451531887054443\n",
      "Epoch 001/003, valid ppl = None, batch 0391/0644, train loss = 3.3644237518310547\n",
      "Epoch 001/003, valid ppl = None, batch 0392/0644, train loss = 3.5852315425872803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0393/0644, train loss = 3.4407825469970703\n",
      "Epoch 001/003, valid ppl = None, batch 0394/0644, train loss = 3.145026922225952\n",
      "Epoch 001/003, valid ppl = None, batch 0395/0644, train loss = 3.251859664916992\n",
      "Epoch 001/003, valid ppl = None, batch 0396/0644, train loss = 3.363626480102539\n",
      "Epoch 001/003, valid ppl = None, batch 0397/0644, train loss = 3.4544429779052734\n",
      "Epoch 001/003, valid ppl = None, batch 0398/0644, train loss = 3.33648419380188\n",
      "Epoch 001/003, valid ppl = None, batch 0399/0644, train loss = 3.394709825515747\n",
      "Epoch 001/003, valid ppl = None, batch 0400/0644, train loss = 3.5435426235198975\n",
      "Epoch 001/003, valid ppl = None, batch 0401/0644, train loss = 3.5506417751312256\n",
      "Epoch 001/003, valid ppl = None, batch 0402/0644, train loss = 3.5132765769958496\n",
      "Epoch 001/003, valid ppl = None, batch 0403/0644, train loss = 3.3067731857299805\n",
      "Epoch 001/003, valid ppl = None, batch 0404/0644, train loss = 3.1436033248901367\n",
      "Epoch 001/003, valid ppl = None, batch 0405/0644, train loss = 3.417586088180542\n",
      "Epoch 001/003, valid ppl = None, batch 0406/0644, train loss = 3.380675792694092\n",
      "Epoch 001/003, valid ppl = None, batch 0407/0644, train loss = 3.33650279045105\n",
      "Epoch 001/003, valid ppl = None, batch 0408/0644, train loss = 3.4458682537078857\n",
      "Epoch 001/003, valid ppl = None, batch 0409/0644, train loss = 3.612105131149292\n",
      "Epoch 001/003, valid ppl = None, batch 0410/0644, train loss = 3.4616427421569824\n",
      "Epoch 001/003, valid ppl = None, batch 0411/0644, train loss = 3.1617352962493896\n",
      "Epoch 001/003, valid ppl = None, batch 0412/0644, train loss = 3.254716157913208\n",
      "Epoch 001/003, valid ppl = None, batch 0413/0644, train loss = 3.415710687637329\n",
      "Epoch 001/003, valid ppl = None, batch 0414/0644, train loss = 3.2328977584838867\n",
      "Epoch 001/003, valid ppl = None, batch 0415/0644, train loss = 3.4508674144744873\n",
      "Epoch 001/003, valid ppl = None, batch 0416/0644, train loss = 3.3449132442474365\n",
      "Epoch 001/003, valid ppl = None, batch 0417/0644, train loss = 3.259155035018921\n",
      "Epoch 001/003, valid ppl = None, batch 0418/0644, train loss = 3.2806670665740967\n",
      "Epoch 001/003, valid ppl = None, batch 0419/0644, train loss = 3.4902660846710205\n",
      "Epoch 001/003, valid ppl = None, batch 0420/0644, train loss = 3.393144130706787\n",
      "Epoch 001/003, valid ppl = None, batch 0421/0644, train loss = 3.3465464115142822\n",
      "Epoch 001/003, valid ppl = None, batch 0422/0644, train loss = 3.5491786003112793\n",
      "Epoch 001/003, valid ppl = None, batch 0423/0644, train loss = 3.3318376541137695\n",
      "Epoch 001/003, valid ppl = None, batch 0424/0644, train loss = 3.6846275329589844\n",
      "Epoch 001/003, valid ppl = None, batch 0425/0644, train loss = 3.461517810821533\n",
      "Epoch 001/003, valid ppl = None, batch 0426/0644, train loss = 3.2384729385375977\n",
      "Epoch 001/003, valid ppl = None, batch 0427/0644, train loss = 3.4826040267944336\n",
      "Epoch 001/003, valid ppl = None, batch 0428/0644, train loss = 3.6648759841918945\n",
      "Epoch 001/003, valid ppl = None, batch 0429/0644, train loss = 3.4484663009643555\n",
      "Epoch 001/003, valid ppl = None, batch 0430/0644, train loss = 3.4081761837005615\n",
      "Epoch 001/003, valid ppl = None, batch 0431/0644, train loss = 3.5053951740264893\n",
      "Epoch 001/003, valid ppl = None, batch 0432/0644, train loss = 3.498277425765991\n",
      "Epoch 001/003, valid ppl = None, batch 0433/0644, train loss = 3.3986659049987793\n",
      "Epoch 001/003, valid ppl = None, batch 0434/0644, train loss = 3.1479263305664062\n",
      "Epoch 001/003, valid ppl = None, batch 0435/0644, train loss = 3.3840205669403076\n",
      "Epoch 001/003, valid ppl = None, batch 0436/0644, train loss = 3.1955108642578125\n",
      "Epoch 001/003, valid ppl = None, batch 0437/0644, train loss = 3.63547945022583\n",
      "Epoch 001/003, valid ppl = None, batch 0438/0644, train loss = 3.3670268058776855\n",
      "Epoch 001/003, valid ppl = None, batch 0439/0644, train loss = 3.216404438018799\n",
      "Epoch 001/003, valid ppl = None, batch 0440/0644, train loss = 3.415639638900757\n",
      "Epoch 001/003, valid ppl = None, batch 0441/0644, train loss = 3.329338788986206\n",
      "Epoch 001/003, valid ppl = None, batch 0442/0644, train loss = 3.471181631088257\n",
      "Epoch 001/003, valid ppl = None, batch 0443/0644, train loss = 3.6129071712493896\n",
      "Epoch 001/003, valid ppl = None, batch 0444/0644, train loss = 3.1586337089538574\n",
      "Epoch 001/003, valid ppl = None, batch 0445/0644, train loss = 3.5798962116241455\n",
      "Epoch 001/003, valid ppl = None, batch 0446/0644, train loss = 3.528230667114258\n",
      "Epoch 001/003, valid ppl = None, batch 0447/0644, train loss = 3.3256208896636963\n",
      "Epoch 001/003, valid ppl = None, batch 0448/0644, train loss = 3.4537651538848877\n",
      "Epoch 001/003, valid ppl = None, batch 0449/0644, train loss = 3.1716525554656982\n",
      "Epoch 001/003, valid ppl = None, batch 0450/0644, train loss = 3.123631000518799\n",
      "Epoch 001/003, valid ppl = None, batch 0451/0644, train loss = 3.4617908000946045\n",
      "Epoch 001/003, valid ppl = None, batch 0452/0644, train loss = 3.285202741622925\n",
      "Epoch 001/003, valid ppl = None, batch 0453/0644, train loss = 3.339653730392456\n",
      "Epoch 001/003, valid ppl = None, batch 0454/0644, train loss = 3.513385534286499\n",
      "Epoch 001/003, valid ppl = None, batch 0455/0644, train loss = 3.355926752090454\n",
      "Epoch 001/003, valid ppl = None, batch 0456/0644, train loss = 3.3689351081848145\n",
      "Epoch 001/003, valid ppl = None, batch 0457/0644, train loss = 3.3417463302612305\n",
      "Epoch 001/003, valid ppl = None, batch 0458/0644, train loss = 3.3622238636016846\n",
      "Epoch 001/003, valid ppl = None, batch 0459/0644, train loss = 3.5766725540161133\n",
      "Epoch 001/003, valid ppl = None, batch 0460/0644, train loss = 3.341153144836426\n",
      "Epoch 001/003, valid ppl = None, batch 0461/0644, train loss = 3.328500270843506\n",
      "Epoch 001/003, valid ppl = None, batch 0462/0644, train loss = 3.4693150520324707\n",
      "Epoch 001/003, valid ppl = None, batch 0463/0644, train loss = 3.461041212081909\n",
      "Epoch 001/003, valid ppl = None, batch 0464/0644, train loss = 3.438194751739502\n",
      "Epoch 001/003, valid ppl = None, batch 0465/0644, train loss = 3.2995147705078125\n",
      "Epoch 001/003, valid ppl = None, batch 0466/0644, train loss = 3.492715835571289\n",
      "Epoch 001/003, valid ppl = None, batch 0467/0644, train loss = 3.2555317878723145\n",
      "Epoch 001/003, valid ppl = None, batch 0468/0644, train loss = 3.634997606277466\n",
      "Epoch 001/003, valid ppl = None, batch 0469/0644, train loss = 3.4712460041046143\n",
      "Epoch 001/003, valid ppl = None, batch 0470/0644, train loss = 3.4502344131469727\n",
      "Epoch 001/003, valid ppl = None, batch 0471/0644, train loss = 3.2941925525665283\n",
      "Epoch 001/003, valid ppl = None, batch 0472/0644, train loss = 3.3601133823394775\n",
      "Epoch 001/003, valid ppl = None, batch 0473/0644, train loss = 3.5427801609039307\n",
      "Epoch 001/003, valid ppl = None, batch 0474/0644, train loss = 3.3493666648864746\n",
      "Epoch 001/003, valid ppl = None, batch 0475/0644, train loss = 3.461723566055298\n",
      "Epoch 001/003, valid ppl = None, batch 0476/0644, train loss = 3.464313268661499\n",
      "Epoch 001/003, valid ppl = None, batch 0477/0644, train loss = 3.2855746746063232\n",
      "Epoch 001/003, valid ppl = None, batch 0478/0644, train loss = 3.2949674129486084\n",
      "Epoch 001/003, valid ppl = None, batch 0479/0644, train loss = 3.344892740249634\n",
      "Epoch 001/003, valid ppl = None, batch 0480/0644, train loss = 3.5265986919403076\n",
      "Epoch 001/003, valid ppl = None, batch 0481/0644, train loss = 3.4642603397369385\n",
      "Epoch 001/003, valid ppl = None, batch 0482/0644, train loss = 3.392683744430542\n",
      "Epoch 001/003, valid ppl = None, batch 0483/0644, train loss = 3.5785622596740723\n",
      "Epoch 001/003, valid ppl = None, batch 0484/0644, train loss = 3.283409357070923\n",
      "Epoch 001/003, valid ppl = None, batch 0485/0644, train loss = 3.245917797088623\n",
      "Epoch 001/003, valid ppl = None, batch 0486/0644, train loss = 3.377511501312256\n",
      "Epoch 001/003, valid ppl = None, batch 0487/0644, train loss = 3.42826771736145\n",
      "Epoch 001/003, valid ppl = None, batch 0488/0644, train loss = 3.4512922763824463\n",
      "Epoch 001/003, valid ppl = None, batch 0489/0644, train loss = 3.2793848514556885\n",
      "Epoch 001/003, valid ppl = None, batch 0490/0644, train loss = 3.356698751449585\n",
      "Epoch 001/003, valid ppl = None, batch 0491/0644, train loss = 3.421199083328247\n",
      "Epoch 001/003, valid ppl = None, batch 0492/0644, train loss = 3.4641478061676025\n",
      "Epoch 001/003, valid ppl = None, batch 0493/0644, train loss = 3.5185701847076416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0494/0644, train loss = 3.367311477661133\n",
      "Epoch 001/003, valid ppl = None, batch 0495/0644, train loss = 3.4536354541778564\n",
      "Epoch 001/003, valid ppl = None, batch 0496/0644, train loss = 3.4083495140075684\n",
      "Epoch 001/003, valid ppl = None, batch 0497/0644, train loss = 3.251432418823242\n",
      "Epoch 001/003, valid ppl = None, batch 0498/0644, train loss = 3.439368486404419\n",
      "Epoch 001/003, valid ppl = None, batch 0499/0644, train loss = 3.458909511566162\n",
      "Epoch 001/003, valid ppl = None, batch 0500/0644, train loss = 3.2603726387023926\n",
      "Epoch 001/003, valid ppl = None, batch 0501/0644, train loss = 3.4993557929992676\n",
      "Epoch 001/003, valid ppl = None, batch 0502/0644, train loss = 3.4372639656066895\n",
      "Epoch 001/003, valid ppl = None, batch 0503/0644, train loss = 3.2193307876586914\n",
      "Epoch 001/003, valid ppl = None, batch 0504/0644, train loss = 3.578834056854248\n",
      "Epoch 001/003, valid ppl = None, batch 0505/0644, train loss = 3.3467345237731934\n",
      "Epoch 001/003, valid ppl = None, batch 0506/0644, train loss = 3.4198312759399414\n",
      "Epoch 001/003, valid ppl = None, batch 0507/0644, train loss = 3.4572415351867676\n",
      "Epoch 001/003, valid ppl = None, batch 0508/0644, train loss = 3.059016466140747\n",
      "Epoch 001/003, valid ppl = None, batch 0509/0644, train loss = 3.495539665222168\n",
      "Epoch 001/003, valid ppl = None, batch 0510/0644, train loss = 3.387169361114502\n",
      "Epoch 001/003, valid ppl = None, batch 0511/0644, train loss = 3.6059679985046387\n",
      "Epoch 001/003, valid ppl = None, batch 0512/0644, train loss = 3.347095251083374\n",
      "Epoch 001/003, valid ppl = None, batch 0513/0644, train loss = 3.3599917888641357\n",
      "Epoch 001/003, valid ppl = None, batch 0514/0644, train loss = 3.284879446029663\n",
      "Epoch 001/003, valid ppl = None, batch 0515/0644, train loss = 3.4926095008850098\n",
      "Epoch 001/003, valid ppl = None, batch 0516/0644, train loss = 3.288114070892334\n",
      "Epoch 001/003, valid ppl = None, batch 0517/0644, train loss = 3.3755249977111816\n",
      "Epoch 001/003, valid ppl = None, batch 0518/0644, train loss = 3.097007989883423\n",
      "Epoch 001/003, valid ppl = None, batch 0519/0644, train loss = 3.361271381378174\n",
      "Epoch 001/003, valid ppl = None, batch 0520/0644, train loss = 3.4321417808532715\n",
      "Epoch 001/003, valid ppl = None, batch 0521/0644, train loss = 3.32417893409729\n",
      "Epoch 001/003, valid ppl = None, batch 0522/0644, train loss = 3.461592197418213\n",
      "Epoch 001/003, valid ppl = None, batch 0523/0644, train loss = 3.2794106006622314\n",
      "Epoch 001/003, valid ppl = None, batch 0524/0644, train loss = 3.344609260559082\n",
      "Epoch 001/003, valid ppl = None, batch 0525/0644, train loss = 3.544543743133545\n",
      "Epoch 001/003, valid ppl = None, batch 0526/0644, train loss = 3.0530965328216553\n",
      "Epoch 001/003, valid ppl = None, batch 0527/0644, train loss = 3.289053440093994\n",
      "Epoch 001/003, valid ppl = None, batch 0528/0644, train loss = 3.5425429344177246\n",
      "Epoch 001/003, valid ppl = None, batch 0529/0644, train loss = 3.4357657432556152\n",
      "Epoch 001/003, valid ppl = None, batch 0530/0644, train loss = 3.197153329849243\n",
      "Epoch 001/003, valid ppl = None, batch 0531/0644, train loss = 3.4155941009521484\n",
      "Epoch 001/003, valid ppl = None, batch 0532/0644, train loss = 3.346261978149414\n",
      "Epoch 001/003, valid ppl = None, batch 0533/0644, train loss = 3.2135064601898193\n",
      "Epoch 001/003, valid ppl = None, batch 0534/0644, train loss = 3.380676746368408\n",
      "Epoch 001/003, valid ppl = None, batch 0535/0644, train loss = 3.5824029445648193\n",
      "Epoch 001/003, valid ppl = None, batch 0536/0644, train loss = 3.2414710521698\n",
      "Epoch 001/003, valid ppl = None, batch 0537/0644, train loss = 3.532198190689087\n",
      "Epoch 001/003, valid ppl = None, batch 0538/0644, train loss = 3.2786314487457275\n",
      "Epoch 001/003, valid ppl = None, batch 0539/0644, train loss = 3.5376222133636475\n",
      "Epoch 001/003, valid ppl = None, batch 0540/0644, train loss = 3.261263847351074\n",
      "Epoch 001/003, valid ppl = None, batch 0541/0644, train loss = 3.4959561824798584\n",
      "Epoch 001/003, valid ppl = None, batch 0542/0644, train loss = 3.22541880607605\n",
      "Epoch 001/003, valid ppl = None, batch 0543/0644, train loss = 3.1924028396606445\n",
      "Epoch 001/003, valid ppl = None, batch 0544/0644, train loss = 3.2604928016662598\n",
      "Epoch 001/003, valid ppl = None, batch 0545/0644, train loss = 3.4650328159332275\n",
      "Epoch 001/003, valid ppl = None, batch 0546/0644, train loss = 3.2736544609069824\n",
      "Epoch 001/003, valid ppl = None, batch 0547/0644, train loss = 3.6409237384796143\n",
      "Epoch 001/003, valid ppl = None, batch 0548/0644, train loss = 3.574763298034668\n",
      "Epoch 001/003, valid ppl = None, batch 0549/0644, train loss = 3.3604114055633545\n",
      "Epoch 001/003, valid ppl = None, batch 0550/0644, train loss = 3.1917147636413574\n",
      "Epoch 001/003, valid ppl = None, batch 0551/0644, train loss = 3.1795754432678223\n",
      "Epoch 001/003, valid ppl = None, batch 0552/0644, train loss = 3.4391424655914307\n",
      "Epoch 001/003, valid ppl = None, batch 0553/0644, train loss = 3.4763975143432617\n",
      "Epoch 001/003, valid ppl = None, batch 0554/0644, train loss = 3.3184595108032227\n",
      "Epoch 001/003, valid ppl = None, batch 0555/0644, train loss = 3.3739688396453857\n",
      "Epoch 001/003, valid ppl = None, batch 0556/0644, train loss = 3.226594924926758\n",
      "Epoch 001/003, valid ppl = None, batch 0557/0644, train loss = 3.5280141830444336\n",
      "Epoch 001/003, valid ppl = None, batch 0558/0644, train loss = 3.3743581771850586\n",
      "Epoch 001/003, valid ppl = None, batch 0559/0644, train loss = 3.6138579845428467\n",
      "Epoch 001/003, valid ppl = None, batch 0560/0644, train loss = 3.207907199859619\n",
      "Epoch 001/003, valid ppl = None, batch 0561/0644, train loss = 3.5785884857177734\n",
      "Epoch 001/003, valid ppl = None, batch 0562/0644, train loss = 3.3384132385253906\n",
      "Epoch 001/003, valid ppl = None, batch 0563/0644, train loss = 3.4106152057647705\n",
      "Epoch 001/003, valid ppl = None, batch 0564/0644, train loss = 3.3989663124084473\n",
      "Epoch 001/003, valid ppl = None, batch 0565/0644, train loss = 3.1370272636413574\n",
      "Epoch 001/003, valid ppl = None, batch 0566/0644, train loss = 3.640977621078491\n",
      "Epoch 001/003, valid ppl = None, batch 0567/0644, train loss = 3.506117582321167\n",
      "Epoch 001/003, valid ppl = None, batch 0568/0644, train loss = 3.3082611560821533\n",
      "Epoch 001/003, valid ppl = None, batch 0569/0644, train loss = 3.2638702392578125\n",
      "Epoch 001/003, valid ppl = None, batch 0570/0644, train loss = 3.236138105392456\n",
      "Epoch 001/003, valid ppl = None, batch 0571/0644, train loss = 3.308288812637329\n",
      "Epoch 001/003, valid ppl = None, batch 0572/0644, train loss = 3.294266700744629\n",
      "Epoch 001/003, valid ppl = None, batch 0573/0644, train loss = 3.4502923488616943\n",
      "Epoch 001/003, valid ppl = None, batch 0574/0644, train loss = 3.483292818069458\n",
      "Epoch 001/003, valid ppl = None, batch 0575/0644, train loss = 3.455155849456787\n",
      "Epoch 001/003, valid ppl = None, batch 0576/0644, train loss = 3.386016368865967\n",
      "Epoch 001/003, valid ppl = None, batch 0577/0644, train loss = 3.31840181350708\n",
      "Epoch 001/003, valid ppl = None, batch 0578/0644, train loss = 3.4783787727355957\n",
      "Epoch 001/003, valid ppl = None, batch 0579/0644, train loss = 3.3886280059814453\n",
      "Epoch 001/003, valid ppl = None, batch 0580/0644, train loss = 3.532243013381958\n",
      "Epoch 001/003, valid ppl = None, batch 0581/0644, train loss = 3.342644691467285\n",
      "Epoch 001/003, valid ppl = None, batch 0582/0644, train loss = 3.194993257522583\n",
      "Epoch 001/003, valid ppl = None, batch 0583/0644, train loss = 3.524573564529419\n",
      "Epoch 001/003, valid ppl = None, batch 0584/0644, train loss = 3.4197299480438232\n",
      "Epoch 001/003, valid ppl = None, batch 0585/0644, train loss = 3.315065860748291\n",
      "Epoch 001/003, valid ppl = None, batch 0586/0644, train loss = 3.490447998046875\n",
      "Epoch 001/003, valid ppl = None, batch 0587/0644, train loss = 3.1978816986083984\n",
      "Epoch 001/003, valid ppl = None, batch 0588/0644, train loss = 3.3174984455108643\n",
      "Epoch 001/003, valid ppl = None, batch 0589/0644, train loss = 3.235478162765503\n",
      "Epoch 001/003, valid ppl = None, batch 0590/0644, train loss = 3.1196889877319336\n",
      "Epoch 001/003, valid ppl = None, batch 0591/0644, train loss = 3.33903169631958\n",
      "Epoch 001/003, valid ppl = None, batch 0592/0644, train loss = 3.237816095352173\n",
      "Epoch 001/003, valid ppl = None, batch 0593/0644, train loss = 3.5255022048950195\n",
      "Epoch 001/003, valid ppl = None, batch 0594/0644, train loss = 3.2860591411590576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/003, valid ppl = None, batch 0595/0644, train loss = 3.5746467113494873\n",
      "Epoch 001/003, valid ppl = None, batch 0596/0644, train loss = 3.2554233074188232\n",
      "Epoch 001/003, valid ppl = None, batch 0597/0644, train loss = 3.2502455711364746\n",
      "Epoch 001/003, valid ppl = None, batch 0598/0644, train loss = 3.348299980163574\n",
      "Epoch 001/003, valid ppl = None, batch 0599/0644, train loss = 3.395965814590454\n",
      "Epoch 001/003, valid ppl = None, batch 0600/0644, train loss = 3.4007151126861572\n",
      "Epoch 001/003, valid ppl = None, batch 0601/0644, train loss = 3.510460615158081\n",
      "Epoch 001/003, valid ppl = None, batch 0602/0644, train loss = 3.3868494033813477\n",
      "Epoch 001/003, valid ppl = None, batch 0603/0644, train loss = 3.295961380004883\n",
      "Epoch 001/003, valid ppl = None, batch 0604/0644, train loss = 3.418672800064087\n",
      "Epoch 001/003, valid ppl = None, batch 0605/0644, train loss = 3.3511343002319336\n",
      "Epoch 001/003, valid ppl = None, batch 0606/0644, train loss = 3.4673094749450684\n",
      "Epoch 001/003, valid ppl = None, batch 0607/0644, train loss = 3.2905850410461426\n",
      "Epoch 001/003, valid ppl = None, batch 0608/0644, train loss = 3.4296815395355225\n",
      "Epoch 001/003, valid ppl = None, batch 0609/0644, train loss = 3.1544713973999023\n",
      "Epoch 001/003, valid ppl = None, batch 0610/0644, train loss = 3.5392067432403564\n",
      "Epoch 001/003, valid ppl = None, batch 0611/0644, train loss = 3.2757279872894287\n",
      "Epoch 001/003, valid ppl = None, batch 0612/0644, train loss = 3.2322545051574707\n",
      "Epoch 001/003, valid ppl = None, batch 0613/0644, train loss = 3.532252550125122\n",
      "Epoch 001/003, valid ppl = None, batch 0614/0644, train loss = 3.6624579429626465\n",
      "Epoch 001/003, valid ppl = None, batch 0615/0644, train loss = 3.3923261165618896\n",
      "Epoch 001/003, valid ppl = None, batch 0616/0644, train loss = 3.480964183807373\n",
      "Epoch 001/003, valid ppl = None, batch 0617/0644, train loss = 3.3294386863708496\n",
      "Epoch 001/003, valid ppl = None, batch 0618/0644, train loss = 3.4162964820861816\n",
      "Epoch 001/003, valid ppl = None, batch 0619/0644, train loss = 3.3139991760253906\n",
      "Epoch 001/003, valid ppl = None, batch 0620/0644, train loss = 3.3383302688598633\n",
      "Epoch 001/003, valid ppl = None, batch 0621/0644, train loss = 3.3384976387023926\n",
      "Epoch 001/003, valid ppl = None, batch 0622/0644, train loss = 3.3317501544952393\n",
      "Epoch 001/003, valid ppl = None, batch 0623/0644, train loss = 3.3759450912475586\n",
      "Epoch 001/003, valid ppl = None, batch 0624/0644, train loss = 3.3616738319396973\n",
      "Epoch 001/003, valid ppl = None, batch 0625/0644, train loss = 3.305433750152588\n",
      "Epoch 001/003, valid ppl = None, batch 0626/0644, train loss = 3.3772337436676025\n",
      "Epoch 001/003, valid ppl = None, batch 0627/0644, train loss = 3.2343642711639404\n",
      "Epoch 001/003, valid ppl = None, batch 0628/0644, train loss = 3.402513027191162\n",
      "Epoch 001/003, valid ppl = None, batch 0629/0644, train loss = 3.231499433517456\n",
      "Epoch 001/003, valid ppl = None, batch 0630/0644, train loss = 3.436471700668335\n",
      "Epoch 001/003, valid ppl = None, batch 0631/0644, train loss = 3.4489357471466064\n",
      "Epoch 001/003, valid ppl = None, batch 0632/0644, train loss = 3.2416529655456543\n",
      "Epoch 001/003, valid ppl = None, batch 0633/0644, train loss = 3.427412509918213\n",
      "Epoch 001/003, valid ppl = None, batch 0634/0644, train loss = 3.19112491607666\n",
      "Epoch 001/003, valid ppl = None, batch 0635/0644, train loss = 3.173346757888794\n",
      "Epoch 001/003, valid ppl = None, batch 0636/0644, train loss = 3.247915267944336\n",
      "Epoch 001/003, valid ppl = None, batch 0637/0644, train loss = 3.5193331241607666\n",
      "Epoch 001/003, valid ppl = None, batch 0638/0644, train loss = 3.270811080932617\n",
      "Epoch 001/003, valid ppl = None, batch 0639/0644, train loss = 3.2510764598846436\n",
      "Epoch 001/003, valid ppl = None, batch 0640/0644, train loss = 3.398941993713379\n",
      "Epoch 001/003, valid ppl = None, batch 0641/0644, train loss = 3.4340338706970215\n",
      "Epoch 001/003, valid ppl = None, batch 0642/0644, train loss = 3.3118510246276855\n",
      "Epoch 001/003, valid ppl = None, batch 0643/0644, train loss = 3.374829053878784\n",
      "Epoch 001/003, valid ppl = None, batch 0644/0644, train loss = 3.2427773475646973\n",
      "Saving the trained model to /Users/yan/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/output//model_dailydialog_rf/model_ST/model_epoch_004.ckpt...\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0001/0644, train loss = 3.464568853378296\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0002/0644, train loss = 3.3073959350585938\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0003/0644, train loss = 3.4353621006011963\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0004/0644, train loss = 3.3598129749298096\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0005/0644, train loss = 3.246751546859741\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0006/0644, train loss = 3.518749952316284\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0007/0644, train loss = 3.4556591510772705\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0008/0644, train loss = 3.307166576385498\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0009/0644, train loss = 3.344439744949341\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0010/0644, train loss = 3.456740379333496\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0011/0644, train loss = 3.308955192565918\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0012/0644, train loss = 3.3131930828094482\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0013/0644, train loss = 3.1601521968841553\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0014/0644, train loss = 3.2812602519989014\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0015/0644, train loss = 3.3696625232696533\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0016/0644, train loss = 3.5777902603149414\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0017/0644, train loss = 3.0466315746307373\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0018/0644, train loss = 3.3799240589141846\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0019/0644, train loss = 3.3601322174072266\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0020/0644, train loss = 3.1348910331726074\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0021/0644, train loss = 3.2982912063598633\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0022/0644, train loss = 3.2728278636932373\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0023/0644, train loss = 3.3034586906433105\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0024/0644, train loss = 3.3676438331604004\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0025/0644, train loss = 3.3133740425109863\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0026/0644, train loss = 3.3646397590637207\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0027/0644, train loss = 3.4487242698669434\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0028/0644, train loss = 3.125715970993042\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0029/0644, train loss = 3.2853798866271973\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0030/0644, train loss = 3.254354238510132\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0031/0644, train loss = 3.104018449783325\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0032/0644, train loss = 3.099457263946533\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0033/0644, train loss = 3.1459946632385254\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0034/0644, train loss = 3.2812278270721436\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0035/0644, train loss = 3.4327359199523926\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0036/0644, train loss = 3.4341936111450195\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0037/0644, train loss = 3.3284270763397217\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0038/0644, train loss = 3.3522324562072754\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0039/0644, train loss = 3.251098871231079\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0040/0644, train loss = 3.193342685699463\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0041/0644, train loss = 3.368577003479004\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0042/0644, train loss = 3.3358452320098877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0043/0644, train loss = 3.4286251068115234\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0044/0644, train loss = 3.271486282348633\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0045/0644, train loss = 3.5112597942352295\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0046/0644, train loss = 3.138451337814331\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0047/0644, train loss = 3.1375489234924316\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0048/0644, train loss = 3.2385849952697754\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0049/0644, train loss = 3.3029229640960693\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0050/0644, train loss = 3.3642096519470215\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0051/0644, train loss = 3.2462403774261475\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0052/0644, train loss = 3.5532941818237305\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0053/0644, train loss = 3.1400442123413086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0054/0644, train loss = 3.4269840717315674\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0055/0644, train loss = 3.2335493564605713\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0056/0644, train loss = 3.3193297386169434\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0057/0644, train loss = 3.277270555496216\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0058/0644, train loss = 3.3299264907836914\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0059/0644, train loss = 3.2555601596832275\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0060/0644, train loss = 3.411226272583008\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0061/0644, train loss = 3.261789083480835\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0062/0644, train loss = 3.4084737300872803\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0063/0644, train loss = 3.208869695663452\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0064/0644, train loss = 3.469682455062866\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0065/0644, train loss = 3.2670912742614746\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0066/0644, train loss = 3.4668900966644287\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0067/0644, train loss = 3.245966911315918\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0068/0644, train loss = 3.27522611618042\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0069/0644, train loss = 3.4888086318969727\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0070/0644, train loss = 3.315364360809326\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0071/0644, train loss = 3.480698347091675\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0072/0644, train loss = 3.2998483180999756\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0073/0644, train loss = 3.496464490890503\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0074/0644, train loss = 3.340182065963745\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0075/0644, train loss = 3.5549521446228027\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0076/0644, train loss = 3.25734543800354\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0077/0644, train loss = 3.4206175804138184\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0078/0644, train loss = 3.2741024494171143\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0079/0644, train loss = 3.068074941635132\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0080/0644, train loss = 3.375570297241211\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0081/0644, train loss = 3.1074421405792236\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0082/0644, train loss = 3.256042003631592\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0083/0644, train loss = 3.259974718093872\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0084/0644, train loss = 3.1943767070770264\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0085/0644, train loss = 3.251859426498413\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0086/0644, train loss = 3.14044451713562\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0087/0644, train loss = 3.5112509727478027\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0088/0644, train loss = 3.40140700340271\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0089/0644, train loss = 3.3149709701538086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0090/0644, train loss = 3.231882333755493\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0091/0644, train loss = 3.390044927597046\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0092/0644, train loss = 3.2828328609466553\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0093/0644, train loss = 3.4544849395751953\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0094/0644, train loss = 3.576890468597412\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0095/0644, train loss = 3.2443723678588867\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0096/0644, train loss = 3.453782796859741\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0097/0644, train loss = 3.3294405937194824\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0098/0644, train loss = 3.4389865398406982\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0099/0644, train loss = 3.1244754791259766\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0100/0644, train loss = 3.4017860889434814\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0101/0644, train loss = 3.3443706035614014\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0102/0644, train loss = 3.331331253051758\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0103/0644, train loss = 3.39223575592041\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0104/0644, train loss = 3.113229990005493\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0105/0644, train loss = 3.5451700687408447\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0106/0644, train loss = 3.2256546020507812\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0107/0644, train loss = 3.318033456802368\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0108/0644, train loss = 3.4209847450256348\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0109/0644, train loss = 3.4058327674865723\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0110/0644, train loss = 3.306814432144165\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0111/0644, train loss = 3.1985409259796143\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0112/0644, train loss = 3.3854172229766846\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0113/0644, train loss = 3.296684980392456\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0114/0644, train loss = 3.305771827697754\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0115/0644, train loss = 3.085855007171631\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0116/0644, train loss = 3.4585185050964355\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0117/0644, train loss = 3.274695634841919\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0118/0644, train loss = 3.282961130142212\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0119/0644, train loss = 3.2440004348754883\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0120/0644, train loss = 3.383075714111328\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0121/0644, train loss = 3.4617385864257812\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0122/0644, train loss = 3.255124568939209\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0123/0644, train loss = 3.1462714672088623\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0124/0644, train loss = 3.3568592071533203\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0125/0644, train loss = 3.610379934310913\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0126/0644, train loss = 3.2737605571746826\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0127/0644, train loss = 3.1909689903259277\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0128/0644, train loss = 3.2971439361572266\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0129/0644, train loss = 3.1655802726745605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0130/0644, train loss = 3.351308584213257\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0131/0644, train loss = 3.356323719024658\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0132/0644, train loss = 3.495096206665039\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0133/0644, train loss = 3.273498058319092\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0134/0644, train loss = 3.3468122482299805\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0135/0644, train loss = 3.281017303466797\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0136/0644, train loss = 3.270460605621338\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0137/0644, train loss = 3.142301559448242\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0138/0644, train loss = 3.3943841457366943\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0139/0644, train loss = 3.432379961013794\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0140/0644, train loss = 3.236806869506836\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0141/0644, train loss = 3.334284782409668\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0142/0644, train loss = 3.284811019897461\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0143/0644, train loss = 3.2299764156341553\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0144/0644, train loss = 3.3933119773864746\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0145/0644, train loss = 3.124706268310547\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0146/0644, train loss = 3.323164463043213\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0147/0644, train loss = 3.492464303970337\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0148/0644, train loss = 3.2432425022125244\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0149/0644, train loss = 3.1751489639282227\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0150/0644, train loss = 3.3322901725769043\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0151/0644, train loss = 3.442786693572998\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0152/0644, train loss = 3.4579226970672607\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0153/0644, train loss = 3.2800285816192627\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0154/0644, train loss = 3.549243688583374\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0155/0644, train loss = 3.1920697689056396\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0156/0644, train loss = 3.387822151184082\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0157/0644, train loss = 3.4715795516967773\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0158/0644, train loss = 3.4023590087890625\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0159/0644, train loss = 3.304636001586914\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0160/0644, train loss = 3.1331934928894043\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0161/0644, train loss = 3.4211034774780273\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0162/0644, train loss = 3.3898355960845947\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0163/0644, train loss = 3.2896342277526855\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0164/0644, train loss = 3.4491591453552246\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0165/0644, train loss = 3.0034279823303223\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0166/0644, train loss = 3.3617653846740723\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0167/0644, train loss = 3.433997869491577\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0168/0644, train loss = 3.1426243782043457\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0169/0644, train loss = 3.357109785079956\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0170/0644, train loss = 3.300689697265625\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0171/0644, train loss = 3.2563984394073486\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0172/0644, train loss = 3.3438780307769775\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0173/0644, train loss = 3.3623087406158447\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0174/0644, train loss = 3.0033152103424072\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0175/0644, train loss = 3.2682957649230957\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0176/0644, train loss = 3.1167941093444824\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0177/0644, train loss = 3.406895399093628\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0178/0644, train loss = 3.3155410289764404\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0179/0644, train loss = 3.3333353996276855\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0180/0644, train loss = 3.124235153198242\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0181/0644, train loss = 3.42630934715271\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0182/0644, train loss = 3.4144864082336426\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0183/0644, train loss = 3.1715481281280518\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0184/0644, train loss = 3.1915712356567383\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0185/0644, train loss = 3.1542980670928955\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0186/0644, train loss = 3.2495360374450684\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0187/0644, train loss = 3.4125313758850098\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0188/0644, train loss = 3.23488712310791\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0189/0644, train loss = 3.2505784034729004\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0190/0644, train loss = 3.247089385986328\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0191/0644, train loss = 3.2384583950042725\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0192/0644, train loss = 3.333993911743164\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0193/0644, train loss = 3.548185110092163\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0194/0644, train loss = 3.103111743927002\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0195/0644, train loss = 3.440000295639038\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0196/0644, train loss = 3.2795145511627197\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0197/0644, train loss = 3.2623648643493652\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0198/0644, train loss = 3.455653667449951\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0199/0644, train loss = 3.3505148887634277\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0200/0644, train loss = 3.2185816764831543\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0201/0644, train loss = 3.371265172958374\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0202/0644, train loss = 3.4710536003112793\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0203/0644, train loss = 3.4977900981903076\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0204/0644, train loss = 3.21591854095459\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0205/0644, train loss = 3.2883119583129883\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0206/0644, train loss = 3.477766990661621\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0207/0644, train loss = 3.1074211597442627\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0208/0644, train loss = 3.258596420288086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0209/0644, train loss = 3.5086822509765625\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0210/0644, train loss = 3.539257049560547\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0211/0644, train loss = 3.2597718238830566\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0212/0644, train loss = 3.2880783081054688\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0213/0644, train loss = 3.299522638320923\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0214/0644, train loss = 3.325471878051758\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0215/0644, train loss = 3.258976459503174\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0216/0644, train loss = 3.4245078563690186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0217/0644, train loss = 3.5206422805786133\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0218/0644, train loss = 3.44258975982666\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0219/0644, train loss = 3.1083059310913086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0220/0644, train loss = 3.158205032348633\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0221/0644, train loss = 3.1169590950012207\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0222/0644, train loss = 3.084209442138672\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0223/0644, train loss = 3.3966805934906006\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0224/0644, train loss = 3.269355297088623\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0225/0644, train loss = 3.537851333618164\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0226/0644, train loss = 3.446751832962036\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0227/0644, train loss = 3.04621958732605\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0228/0644, train loss = 3.438901424407959\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0229/0644, train loss = 3.342496395111084\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0230/0644, train loss = 3.290503978729248\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0231/0644, train loss = 3.324702501296997\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0232/0644, train loss = 3.4643173217773438\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0233/0644, train loss = 3.3479368686676025\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0234/0644, train loss = 3.4659852981567383\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0235/0644, train loss = 3.4040210247039795\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0236/0644, train loss = 3.3199706077575684\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0237/0644, train loss = 3.231618881225586\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0238/0644, train loss = 3.2515792846679688\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0239/0644, train loss = 3.4044995307922363\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0240/0644, train loss = 3.499922037124634\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0241/0644, train loss = 3.5172338485717773\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0242/0644, train loss = 3.3453142642974854\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0243/0644, train loss = 3.293901205062866\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0244/0644, train loss = 3.2349917888641357\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0245/0644, train loss = 3.3962669372558594\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0246/0644, train loss = 3.153660297393799\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0247/0644, train loss = 3.3239998817443848\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0248/0644, train loss = 3.3098721504211426\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0249/0644, train loss = 3.2781448364257812\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0250/0644, train loss = 3.435854434967041\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0251/0644, train loss = 3.3005752563476562\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0252/0644, train loss = 3.2562415599823\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0253/0644, train loss = 3.4631268978118896\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0254/0644, train loss = 3.342519760131836\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0255/0644, train loss = 3.1073765754699707\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0256/0644, train loss = 3.19372296333313\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0257/0644, train loss = 3.162935972213745\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0258/0644, train loss = 3.2426035404205322\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0259/0644, train loss = 3.152876377105713\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0260/0644, train loss = 3.3118889331817627\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0261/0644, train loss = 3.5058112144470215\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0262/0644, train loss = 3.331648826599121\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0263/0644, train loss = 3.2033252716064453\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0264/0644, train loss = 3.251713275909424\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0265/0644, train loss = 3.1376280784606934\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0266/0644, train loss = 3.12147855758667\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0267/0644, train loss = 3.4087471961975098\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0268/0644, train loss = 3.168815851211548\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0269/0644, train loss = 3.3366212844848633\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0270/0644, train loss = 3.3717153072357178\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0271/0644, train loss = 3.1871843338012695\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0272/0644, train loss = 3.2988338470458984\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0273/0644, train loss = 3.376723527908325\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0274/0644, train loss = 3.3283755779266357\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0275/0644, train loss = 3.3545260429382324\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0276/0644, train loss = 3.1556546688079834\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0277/0644, train loss = 3.2301406860351562\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0278/0644, train loss = 3.2448267936706543\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0279/0644, train loss = 3.0984365940093994\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0280/0644, train loss = 3.3808236122131348\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0281/0644, train loss = 3.2150964736938477\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0282/0644, train loss = 3.3897111415863037\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0283/0644, train loss = 3.499054193496704\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0284/0644, train loss = 3.454914093017578\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0285/0644, train loss = 3.2926650047302246\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0286/0644, train loss = 3.2863807678222656\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0287/0644, train loss = 3.416891574859619\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0288/0644, train loss = 3.580655813217163\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0289/0644, train loss = 3.4453494548797607\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0290/0644, train loss = 3.0021862983703613\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0291/0644, train loss = 3.1910078525543213\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0292/0644, train loss = 3.410832643508911\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0293/0644, train loss = 3.3522861003875732\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0294/0644, train loss = 3.372748851776123\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0295/0644, train loss = 3.422642707824707\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0296/0644, train loss = 3.0885701179504395\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0297/0644, train loss = 3.4276530742645264\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0298/0644, train loss = 3.2754578590393066\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0299/0644, train loss = 3.4248955249786377\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0300/0644, train loss = 3.356008291244507\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0301/0644, train loss = 3.3957712650299072\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0302/0644, train loss = 3.3169007301330566\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0303/0644, train loss = 3.339315414428711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0304/0644, train loss = 3.3232555389404297\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0305/0644, train loss = 3.4494121074676514\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0306/0644, train loss = 3.0839314460754395\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0307/0644, train loss = 3.304769277572632\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0308/0644, train loss = 3.2405881881713867\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0309/0644, train loss = 3.280585527420044\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0310/0644, train loss = 3.426680088043213\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0311/0644, train loss = 3.2811625003814697\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0312/0644, train loss = 3.2175803184509277\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0313/0644, train loss = 3.228987693786621\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0314/0644, train loss = 3.3417234420776367\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0315/0644, train loss = 3.3375868797302246\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0316/0644, train loss = 3.2708802223205566\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0317/0644, train loss = 3.3010520935058594\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0318/0644, train loss = 3.803469657897949\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0319/0644, train loss = 3.4130232334136963\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0320/0644, train loss = 3.408756732940674\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0321/0644, train loss = 3.339642286300659\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0322/0644, train loss = 3.300118923187256\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0323/0644, train loss = 3.5290746688842773\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0324/0644, train loss = 3.398712158203125\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0325/0644, train loss = 3.0475099086761475\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0326/0644, train loss = 3.3167433738708496\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0327/0644, train loss = 3.2967472076416016\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0328/0644, train loss = 3.4580461978912354\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0329/0644, train loss = 3.297332286834717\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0330/0644, train loss = 3.1925747394561768\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0331/0644, train loss = 3.4547312259674072\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0332/0644, train loss = 3.3089449405670166\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0333/0644, train loss = 3.3069252967834473\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0334/0644, train loss = 3.421196222305298\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0335/0644, train loss = 3.168452501296997\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0336/0644, train loss = 3.3459177017211914\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0337/0644, train loss = 3.1751275062561035\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0338/0644, train loss = 3.261995553970337\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0339/0644, train loss = 3.3599536418914795\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0340/0644, train loss = 3.3530659675598145\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0341/0644, train loss = 3.487210988998413\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0342/0644, train loss = 3.3117964267730713\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0343/0644, train loss = 3.1431305408477783\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0344/0644, train loss = 3.3455657958984375\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0345/0644, train loss = 3.366483211517334\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0346/0644, train loss = 3.2923827171325684\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0347/0644, train loss = 3.2274277210235596\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0348/0644, train loss = 3.510979175567627\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0349/0644, train loss = 3.3489880561828613\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0350/0644, train loss = 3.2674400806427\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0351/0644, train loss = 3.495988607406616\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0352/0644, train loss = 3.3092055320739746\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0353/0644, train loss = 3.144807815551758\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0354/0644, train loss = 3.2310562133789062\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0355/0644, train loss = 3.144226312637329\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0356/0644, train loss = 3.191452980041504\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0357/0644, train loss = 3.304518222808838\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0358/0644, train loss = 3.4333035945892334\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0359/0644, train loss = 3.031597375869751\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0360/0644, train loss = 3.357006311416626\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0361/0644, train loss = 3.3024213314056396\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0362/0644, train loss = 3.2421908378601074\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0363/0644, train loss = 3.239719867706299\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0364/0644, train loss = 3.299593448638916\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0365/0644, train loss = 3.5523951053619385\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0366/0644, train loss = 3.1573874950408936\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0367/0644, train loss = 3.1568825244903564\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0368/0644, train loss = 3.2537331581115723\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0369/0644, train loss = 3.4820399284362793\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0370/0644, train loss = 3.3555638790130615\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0371/0644, train loss = 3.261476993560791\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0372/0644, train loss = 3.2750308513641357\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0373/0644, train loss = 3.278262138366699\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0374/0644, train loss = 3.284895658493042\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0375/0644, train loss = 3.430436134338379\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0376/0644, train loss = 3.3666799068450928\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0377/0644, train loss = 3.355785369873047\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0378/0644, train loss = 3.3714447021484375\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0379/0644, train loss = 3.1821446418762207\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0380/0644, train loss = 3.548412799835205\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0381/0644, train loss = 3.2038440704345703\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0382/0644, train loss = 3.28786301612854\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0383/0644, train loss = 3.2157063484191895\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0384/0644, train loss = 3.2540206909179688\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0385/0644, train loss = 3.353194236755371\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0386/0644, train loss = 3.0419423580169678\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0387/0644, train loss = 3.2752530574798584\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0388/0644, train loss = 3.395559549331665\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0389/0644, train loss = 3.323375701904297\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0390/0644, train loss = 3.2041046619415283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0391/0644, train loss = 3.1517412662506104\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0392/0644, train loss = 3.1229474544525146\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0393/0644, train loss = 3.393700361251831\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0394/0644, train loss = 3.108192205429077\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0395/0644, train loss = 3.504847526550293\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0396/0644, train loss = 3.410048246383667\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0397/0644, train loss = 3.397461175918579\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0398/0644, train loss = 3.310055732727051\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0399/0644, train loss = 3.1433756351470947\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0400/0644, train loss = 3.2876014709472656\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0401/0644, train loss = 3.448582649230957\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0402/0644, train loss = 3.4621503353118896\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0403/0644, train loss = 3.4194929599761963\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0404/0644, train loss = 3.494511604309082\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0405/0644, train loss = 3.2529773712158203\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0406/0644, train loss = 3.4453108310699463\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0407/0644, train loss = 3.326846122741699\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0408/0644, train loss = 3.3683300018310547\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0409/0644, train loss = 3.448084831237793\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0410/0644, train loss = 3.366046667098999\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0411/0644, train loss = 3.416219472885132\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0412/0644, train loss = 3.1757431030273438\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0413/0644, train loss = 3.3247060775756836\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0414/0644, train loss = 3.3156776428222656\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0415/0644, train loss = 3.597989320755005\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0416/0644, train loss = 3.3688015937805176\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0417/0644, train loss = 3.2811098098754883\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0418/0644, train loss = 3.1854968070983887\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0419/0644, train loss = 3.2376632690429688\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0420/0644, train loss = 3.0738322734832764\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0421/0644, train loss = 3.297830820083618\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0422/0644, train loss = 3.2427804470062256\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0423/0644, train loss = 3.2589266300201416\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0424/0644, train loss = 3.1981024742126465\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0425/0644, train loss = 3.197375774383545\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0426/0644, train loss = 3.419769525527954\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0427/0644, train loss = 3.2845685482025146\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0428/0644, train loss = 3.380378007888794\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0429/0644, train loss = 3.1647396087646484\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0430/0644, train loss = 3.0745203495025635\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0431/0644, train loss = 3.624361515045166\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0432/0644, train loss = 3.4775149822235107\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0433/0644, train loss = 3.37225341796875\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0434/0644, train loss = 3.420050621032715\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0435/0644, train loss = 3.2336480617523193\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0436/0644, train loss = 3.2917776107788086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0437/0644, train loss = 3.3594682216644287\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0438/0644, train loss = 3.197171211242676\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0439/0644, train loss = 3.3038713932037354\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0440/0644, train loss = 3.2414464950561523\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0441/0644, train loss = 3.3880093097686768\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0442/0644, train loss = 3.295849084854126\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0443/0644, train loss = 3.529832363128662\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0444/0644, train loss = 3.137599468231201\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0445/0644, train loss = 3.2703146934509277\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0446/0644, train loss = 3.4503021240234375\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0447/0644, train loss = 3.2141952514648438\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0448/0644, train loss = 3.5149712562561035\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0449/0644, train loss = 3.541646718978882\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0450/0644, train loss = 3.3504557609558105\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0451/0644, train loss = 3.3740005493164062\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0452/0644, train loss = 3.296931743621826\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0453/0644, train loss = 3.4162158966064453\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0454/0644, train loss = 3.2050678730010986\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0455/0644, train loss = 3.3641507625579834\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0456/0644, train loss = 3.463989019393921\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0457/0644, train loss = 3.37979793548584\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0458/0644, train loss = 3.4486305713653564\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0459/0644, train loss = 3.4708518981933594\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0460/0644, train loss = 3.365360736846924\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0461/0644, train loss = 3.051882743835449\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0462/0644, train loss = 3.1582303047180176\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0463/0644, train loss = 3.363654851913452\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0464/0644, train loss = 3.3054769039154053\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0465/0644, train loss = 3.4778964519500732\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0466/0644, train loss = 3.0910205841064453\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0467/0644, train loss = 3.2295095920562744\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0468/0644, train loss = 3.129819393157959\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0469/0644, train loss = 3.5562636852264404\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0470/0644, train loss = 3.374567747116089\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0471/0644, train loss = 3.411822557449341\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0472/0644, train loss = 3.0485544204711914\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0473/0644, train loss = 3.390418529510498\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0474/0644, train loss = 3.2461965084075928\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0475/0644, train loss = 3.490412473678589\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0476/0644, train loss = 3.222006320953369\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0477/0644, train loss = 3.3070249557495117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0478/0644, train loss = 3.024843692779541\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0479/0644, train loss = 3.3270480632781982\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0480/0644, train loss = 3.4354851245880127\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0481/0644, train loss = 3.422672748565674\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0482/0644, train loss = 3.135908365249634\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0483/0644, train loss = 3.2078566551208496\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0484/0644, train loss = 3.132645845413208\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0485/0644, train loss = 3.0957860946655273\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0486/0644, train loss = 3.265941858291626\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0487/0644, train loss = 3.6352107524871826\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0488/0644, train loss = 3.0741708278656006\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0489/0644, train loss = 3.239946126937866\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0490/0644, train loss = 3.1756205558776855\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0491/0644, train loss = 3.3288097381591797\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0492/0644, train loss = 3.1386234760284424\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0493/0644, train loss = 3.2308499813079834\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0494/0644, train loss = 3.388705015182495\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0495/0644, train loss = 3.1947836875915527\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0496/0644, train loss = 3.4668734073638916\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0497/0644, train loss = 3.295419931411743\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0498/0644, train loss = 3.1261191368103027\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0499/0644, train loss = 3.25211238861084\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0500/0644, train loss = 3.250969648361206\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0501/0644, train loss = 3.165109157562256\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0502/0644, train loss = 3.2287278175354004\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0503/0644, train loss = 3.218492031097412\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0504/0644, train loss = 3.214935302734375\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0505/0644, train loss = 3.2400856018066406\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0506/0644, train loss = 3.293062686920166\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0507/0644, train loss = 3.245074987411499\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0508/0644, train loss = 3.2538905143737793\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0509/0644, train loss = 3.4622385501861572\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0510/0644, train loss = 3.334974527359009\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0511/0644, train loss = 3.306290626525879\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0512/0644, train loss = 3.4738991260528564\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0513/0644, train loss = 3.2880747318267822\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0514/0644, train loss = 3.3735544681549072\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0515/0644, train loss = 3.1209614276885986\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0516/0644, train loss = 3.110692262649536\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0517/0644, train loss = 3.0237011909484863\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0518/0644, train loss = 3.1726279258728027\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0519/0644, train loss = 3.4629838466644287\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0520/0644, train loss = 3.2943148612976074\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0521/0644, train loss = 3.2098352909088135\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0522/0644, train loss = 3.2849233150482178\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0523/0644, train loss = 3.496096134185791\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0524/0644, train loss = 3.484780788421631\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0525/0644, train loss = 3.448773145675659\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0526/0644, train loss = 3.282614231109619\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0527/0644, train loss = 3.4891998767852783\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0528/0644, train loss = 3.5144660472869873\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0529/0644, train loss = 3.1545588970184326\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0530/0644, train loss = 3.197146415710449\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0531/0644, train loss = 3.5467140674591064\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0532/0644, train loss = 3.351640462875366\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0533/0644, train loss = 3.3723294734954834\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0534/0644, train loss = 3.409860610961914\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0535/0644, train loss = 3.393547773361206\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0536/0644, train loss = 3.4045495986938477\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0537/0644, train loss = 3.5136852264404297\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0538/0644, train loss = 3.001636505126953\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0539/0644, train loss = 3.3124520778656006\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0540/0644, train loss = 3.2747209072113037\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0541/0644, train loss = 3.287414073944092\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0542/0644, train loss = 3.2800354957580566\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0543/0644, train loss = 3.577666759490967\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0544/0644, train loss = 3.192073345184326\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0545/0644, train loss = 3.5481183528900146\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0546/0644, train loss = 3.43034291267395\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0547/0644, train loss = 3.6113834381103516\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0548/0644, train loss = 3.5525004863739014\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0549/0644, train loss = 3.5397355556488037\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0550/0644, train loss = 3.2491846084594727\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0551/0644, train loss = 3.192351818084717\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0552/0644, train loss = 2.9677743911743164\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0553/0644, train loss = 3.1932566165924072\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0554/0644, train loss = 3.2924859523773193\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0555/0644, train loss = 3.3779659271240234\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0556/0644, train loss = 3.162025213241577\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0557/0644, train loss = 3.154513120651245\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0558/0644, train loss = 3.520024299621582\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0559/0644, train loss = 3.2620882987976074\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0560/0644, train loss = 3.369335412979126\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0561/0644, train loss = 3.2949905395507812\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0562/0644, train loss = 3.2095160484313965\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0563/0644, train loss = 3.2887628078460693\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0564/0644, train loss = 3.321211099624634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0565/0644, train loss = 3.057060718536377\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0566/0644, train loss = 3.232100248336792\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0567/0644, train loss = 3.2810676097869873\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0568/0644, train loss = 3.2927322387695312\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0569/0644, train loss = 3.5062308311462402\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0570/0644, train loss = 3.2119266986846924\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0571/0644, train loss = 3.3050920963287354\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0572/0644, train loss = 3.5290586948394775\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0573/0644, train loss = 3.447561025619507\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0574/0644, train loss = 3.2325656414031982\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0575/0644, train loss = 3.230506658554077\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0576/0644, train loss = 3.5467467308044434\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0577/0644, train loss = 3.3056914806365967\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0578/0644, train loss = 3.3154141902923584\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0579/0644, train loss = 3.3633430004119873\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0580/0644, train loss = 3.4162540435791016\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0581/0644, train loss = 3.122931718826294\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0582/0644, train loss = 3.2516186237335205\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0583/0644, train loss = 3.279301404953003\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0584/0644, train loss = 3.4909491539001465\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0585/0644, train loss = 3.259387254714966\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0586/0644, train loss = 3.461237668991089\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0587/0644, train loss = 3.396481513977051\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0588/0644, train loss = 3.2687602043151855\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0589/0644, train loss = 3.1591684818267822\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0590/0644, train loss = 3.1069116592407227\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0591/0644, train loss = 3.182649612426758\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0592/0644, train loss = 3.425875425338745\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0593/0644, train loss = 3.150329351425171\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0594/0644, train loss = 3.3625328540802\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0595/0644, train loss = 3.4020466804504395\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0596/0644, train loss = 3.184231996536255\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0597/0644, train loss = 3.410186767578125\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0598/0644, train loss = 3.2989509105682373\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0599/0644, train loss = 3.2230958938598633\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0600/0644, train loss = 3.252338171005249\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0601/0644, train loss = 3.166393280029297\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0602/0644, train loss = 3.5034821033477783\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0603/0644, train loss = 3.220642328262329\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0604/0644, train loss = 3.147052049636841\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0605/0644, train loss = 3.4707555770874023\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0606/0644, train loss = 3.4121851921081543\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0607/0644, train loss = 3.2612810134887695\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0608/0644, train loss = 3.141570806503296\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0609/0644, train loss = 3.1900620460510254\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0610/0644, train loss = 3.2152903079986572\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0611/0644, train loss = 3.1706230640411377\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0612/0644, train loss = 3.3596444129943848\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0613/0644, train loss = 3.469778060913086\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0614/0644, train loss = 3.156916618347168\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0615/0644, train loss = 3.310908555984497\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0616/0644, train loss = 3.254561185836792\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0617/0644, train loss = 3.3002190589904785\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0618/0644, train loss = 3.302600860595703\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0619/0644, train loss = 3.2154908180236816\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0620/0644, train loss = 3.2307608127593994\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0621/0644, train loss = 3.455594301223755\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0622/0644, train loss = 3.0381574630737305\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0623/0644, train loss = 3.490189552307129\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0624/0644, train loss = 3.2234864234924316\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0625/0644, train loss = 3.2661213874816895\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0626/0644, train loss = 3.3097891807556152\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0627/0644, train loss = 3.4100823402404785\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0628/0644, train loss = 3.2319107055664062\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0629/0644, train loss = 3.1652441024780273\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0630/0644, train loss = 3.482649087905884\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0631/0644, train loss = 3.3435518741607666\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0632/0644, train loss = 3.3606925010681152\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0633/0644, train loss = 3.413729667663574\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0634/0644, train loss = 3.2851712703704834\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0635/0644, train loss = 3.4723317623138428\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0636/0644, train loss = 3.2098896503448486\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0637/0644, train loss = 3.531872272491455\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0638/0644, train loss = 3.3750762939453125\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0639/0644, train loss = 3.3670122623443604\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0640/0644, train loss = 3.2610034942626953\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0641/0644, train loss = 3.1297669410705566\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0642/0644, train loss = 3.294734001159668\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0643/0644, train loss = 3.2506794929504395\n",
      "Epoch 002/003, valid ppl = 74.42816363173927, batch 0644/0644, train loss = 3.476112127304077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-25899f5a75f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel_ST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tf_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel_ST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAD_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path_ST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_set, VAD, termfreq, VAD_loss, save_path, restore_epoch, valid_set)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalid_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mvalid_ppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAD_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_epoch_{:03d}.ckpt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/document/EPFL/MA2/semesterprj/code/seq2seq_attn/affect-rich/model.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, valid_set, VAD, termfreq, VAD_loss)\u001b[0m\n\u001b[1;32m    241\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermfreq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtermfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                          self.VAD_loss:VAD_loss}\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/semester/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, valid_set, token2id,id2token = read_data(args.data_path)\n",
    "    train_set = revert(train_set)\n",
    "    valid_set = revert(valid_set)\n",
    "#     train_set['enc_input'] = train_set['enc_input'][:128,]\n",
    "    \n",
    "    max_uttr_len_enc = train_set['enc_input'].shape[1]\n",
    "    max_uttr_len_dec = train_set['dec_input'].shape[1]\n",
    "\n",
    "    word_embeddings = np.load(args.word_embeddings_path)\n",
    "    VAD = np.load(args.VAD_path)\n",
    "    termfreq = np.load(args.ti_path) # term importance\n",
    "    termfreq = termfreq.reshape(-1,1)\n",
    "    VAD_loss = np.load(args.VAD_loss_path)\n",
    "    VAD_loss = VAD_loss.reshape(-1,1)\n",
    "    \n",
    "    options = Options(mode = 'TRAIN',\n",
    "                      VAD_mode = 'FALSE',\n",
    "                      num_epochs = args.num_epochs,\n",
    "                      batch_size = args.batch_size,\n",
    "                      learning_rate = args.learning_rate,\n",
    "                      beam_width = args.beam_width,\n",
    "                      corpus_size = len(token2id),\n",
    "                      max_uttr_len_enc = max_uttr_len_enc,\n",
    "                      max_uttr_len_dec = max_uttr_len_dec,\n",
    "                      go_index = token2id['<go>'],\n",
    "                      eos_index = token2id['<eos>'],\n",
    "                      word_embed_size = args.word_embed_size,\n",
    "                      n_hidden_units_enc = args.n_hidden_units_enc,\n",
    "                      n_hidden_units_dec = args.n_hidden_units_dec,\n",
    "                      attn_depth = args.attn_depth,\n",
    "                      word_embeddings = word_embeddings)\n",
    "    model_ST = Seq2SeqAttn(options)\n",
    "\n",
    "    for var in model_ST.tvars:\n",
    "        print(var.name)\n",
    "\n",
    "    if args.restore_epoch > 0:\n",
    "        model_ST.restore(os.path.join(args.restore_path_ST, 'model_epoch_{:03d}.ckpt'.format(args.restore_epoch)))\n",
    "    else:\n",
    "        model_ST.init_tf_vars()\n",
    "    model_ST.train(train_set, VAD,termfreq, VAD_loss,args.save_path_ST, args.restore_epoch, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
