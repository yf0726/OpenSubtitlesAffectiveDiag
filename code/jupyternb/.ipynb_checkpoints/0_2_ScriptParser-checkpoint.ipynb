{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to parse and save well-structured dialogues from scripts.\n",
    "\n",
    "Finally we got 945 labelled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the scripts and segment dialogues\n",
    "\n",
    "The scripts are not well formatted: even though they are in html format, actually the lines are not well constructed in tags. We cannot parse them with tags. Fortunately, every characters and changes of scenes are bolded with tag 'b', and we have files containing characters information. So first we extract all bolded lines, and substract characters, then changes of scenes are left, and then we can know the boundaries of dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/datasets/scripts/'\n",
    "path = folder_path+'scripts'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if (file.endswith('.html')) & (~file.startswith('fd')) & (~file.startswith('tbbt')) & (~file.startswith('friends')):\n",
    "            test_path = folder_path+'sentences/'+file.split('.html')[0]+'-speakers.txt'\n",
    "            if os.path.exists(test_path):\n",
    "                files.append(file.split('.html')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser(files,j):\n",
    "    \"\"\"\n",
    "    This function is used to parse the scripts in .html.\n",
    "    Inputs:\n",
    "        files: List of scripts' directory.\n",
    "        j: index\n",
    "    \"\"\"\n",
    "    file_path = folder_path+'sentences/'+files[j]+'-speakers.txt' # read the file with speakers in that script\n",
    "\n",
    "    f = open(file_path)               \n",
    "    lines = f.readlines()               \n",
    "    tags_speakers = []\n",
    "    for line in lines: \n",
    "        tags_speakers.append(line.replace('continued','').upper().rstrip())\n",
    "    tags_speakers = set(tags_speakers) # characters in the scripts\n",
    "    \n",
    "    file_path = folder_path+'scripts/'+files[j]+'.html'\n",
    "    soup = BeautifulSoup(open(file_path, errors='ignore'))\n",
    "    \n",
    "    tags = []\n",
    "    for a in soup.find_all('b'):\n",
    "        tags.append(a.string.rstrip().lstrip())\n",
    "    tags = set(tags) # all bolded tags\n",
    "    tags_background = tags - tags_speakers # only changes of scenes are left\n",
    "\n",
    "    texts = [' '.join(x.rstrip().lstrip().split('\\n\\n')[0].split()) for x in soup.strings if str.strip(x) != '']\n",
    "\n",
    "    idxs = []\n",
    "    idxs_bg = []\n",
    "    speaker = []\n",
    "    lines = []\n",
    "    for i in range(len(texts)):\n",
    "        if texts[i] in tags_background:\n",
    "            idxs_bg.append(i)\n",
    "        if texts[i] not in tags_speakers:\n",
    "            continue\n",
    "        else:\n",
    "            speaker.append(texts[i])\n",
    "            line = re.sub(u\"\\\\(.*?\\\\)|\\\\{.*?}|\\\\[.*?]|\\\\♪.*?♪|\\\\#.*?#|\\\\=.*?=|\\\\¶.*?¶\", \"\", texts[i+1])\n",
    "            lines.append(line)\n",
    "            idxs.append(i)\n",
    "            \n",
    "    s = pd.Series(idxs)\n",
    "    boundaries = pd.cut(s,idxs_bg, labels=False, retbins=False, right=False).get_values()\n",
    "    boundaries = [1]+list((boundaries[1:] != boundaries[:-1])*1)\n",
    "    \n",
    "    MovieID = ['m%s'%(str(j))] * len(lines)\n",
    "    MovieName = [files[j]] * len(lines)\n",
    "\n",
    "    dialogue = pd.DataFrame([speaker,lines,boundaries,MovieID,MovieName]).T\n",
    "    dialogue.columns = ['Speaker','Line','Label','MovieID','MoveiName']\n",
    "    dialogue.to_csv(folder_path+'parsed/'+MovieID[0]+'.txt',sep=',', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Crow-Salvation,-The\n",
      "12 Star-Trek-First-Contact\n",
      "23 i-walked_with_a_zombie\n",
      "41 Who-Framed-Roger-Rabbit%3f\n",
      "42 Platoon\n",
      "43 the-x-files_production\n",
      "51 Pitch-Black\n",
      "56 pet-sematary\n",
      "62 thethinman\n",
      "93 Leaving-Las-Vegas\n",
      "134 Stepmom\n",
      "136 oneflewover\n",
      "142 Star-Trek-Generations\n",
      "147 Bones\n",
      "149 Minority-Report\n",
      "150 natural-born-killers_early\n",
      "170 Buffy-the-Vampire-Slayer\n",
      "177 Star-Trek-The-Motion-Picture\n",
      "179 fivefeetandrising\n",
      "181 Crying-Game\n",
      "193 Clueless\n",
      "197 natural-born-killers_shoot\n",
      "215 Tremors\n",
      "243 Sixth-Sense,-The\n",
      "256 John-Q\n",
      "273 Orgy-of-the-Dead\n",
      "284 Almost-Famous\n",
      "288 Blast-from-the-Past,-The\n",
      "293 Anastasia\n",
      "296 Memento\n",
      "298 Aladdin\n",
      "303 fabulous_baker_boys_final\n",
      "305 Blade-II\n",
      "308 hellraiser_ii\n",
      "313 mission-impossible-2_shoot\n",
      "315 English-Patient,-The\n",
      "322 Independence-Day\n",
      "340 halloween\n",
      "364 Apartment,-The\n",
      "368 kundun\n",
      "373 Shampoo\n",
      "374 True-Romance\n",
      "378 Star-Trek-II-The-Wrath-of-Khan\n",
      "390 Life-As-A-House\n",
      "413 Little-Mermaid,-The\n",
      "427 Red-Planet\n",
      "432 Withnail-and-I\n",
      "434 Heavy-Metal\n",
      "436 Pearl-Harbor\n",
      "442 thetimemachine_1959\n",
      "451 48-Hrs.\n",
      "455 X-Men\n",
      "459 Ace-Ventura-Pet-Detective\n",
      "463 Beach,-The\n",
      "480 12\n",
      "481 Sugar-and-Spice\n",
      "504 Mary-Poppins\n",
      "515 Highlander-Endgame\n",
      "520 Broadcast-News\n",
      "529 Ninth-Gate,-The\n",
      "540 happy_birthday_wanda_june\n",
      "563 Erik-the-Viking\n",
      "566 Resident-Evil\n",
      "568 Rambo-First-Blood-II-The-Mission\n",
      "579 Top-Gun\n",
      "582 vertigo\n",
      "587 They\n",
      "588 goodfellas\n",
      "591 Nightbreed\n",
      "600 Star-Wars-The-Phantom-Menace\n",
      "630 E.T.\n",
      "631 house-on-haunted-hill\n",
      "635 the-man-who-wasn't-there\n",
      "650 Planet-of-the-Apes,-The\n",
      "684 Nurse-Betty\n",
      "692 Punch-Drunk-Love\n",
      "702 Saint,-The\n",
      "716 Never-Been-Kissed\n",
      "719 At-First-Sight\n",
      "732 grosse_point_blank\n",
      "749 Blow\n",
      "759 avengers\n",
      "760 Rescuers-Down-Under,-The\n",
      "781 Bottle-Rocket\n",
      "786 True-Grit\n",
      "787 Cinema-Paradiso\n",
      "797 Battle-of-Algiers,-The\n",
      "802 Halloween-The-Curse-of-Michael-Myers\n",
      "816 Awakenings\n",
      "820 Enemy-of-the-State\n",
      "834 Usual-Suspects,-The\n",
      "845 millers_crossing\n",
      "846 Mission-Impossible\n",
      "853 spareme\n",
      "876 Swingers\n",
      "900 Mulan\n",
      "902 Cube\n",
      "919 Dawn-of-the-Dead\n",
      "920 the_day_the_clown_cried\n",
      "929 Brazil\n",
      "932 fabulous_baker_boys_april_1985\n",
      "934 unforgiven\n",
      "939 logans_run\n",
      "948 Labyrinth\n",
      "949 Burlesque\n",
      "957 Frequency\n",
      "976 Return-of-the-Apes\n",
      "977 Toy-Story\n",
      "985 all_the_presidents_men\n",
      "987 Jurassic-Park-III\n",
      "1000 Air-Force-One\n",
      "1003 Mystery-Men\n",
      "1025 Neverending-Story,-The\n",
      "1027 Real-Genius\n",
      "1031 Copycat\n",
      "1037 Four-Feathers\n",
      "1040 quantumproject\n",
      "1051 Sex,-Lies-and-Videotape\n",
      "1058 thebijou\n",
      "1063 fletch\n",
      "1064 White-Ribbon,-The\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(files)):\n",
    "    try:\n",
    "        Parser(files,j)\n",
    "    except:\n",
    "        print(j,files[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/datasets/scripts/parsed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files in that folder\n",
    "info = [os.path.join(folder_path,file) for file in os.listdir(folder_path) if file.endswith('.txt') ]\n",
    "script_data_set = pd.concat((pd.read_csv(f,header=None) for f in info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "script_data_set.columns = ['Speaker','Line','Label','MovieID','MovieName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_data_set.to_csv('/Users/yan/Documents/document/EPFL/MA2/semesterprj/datasets/scripts/script_data_set.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Line</th>\n",
       "      <th>Label</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>MovieName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MODERATOR</td>\n",
       "      <td>Tonight we'll discuss a subject most of us see...</td>\n",
       "      <td>1</td>\n",
       "      <td>m478</td>\n",
       "      <td>Midnight-Cowboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRATE WOMAN</td>\n",
       "      <td>They always put it that way, but well, all it ...</td>\n",
       "      <td>1</td>\n",
       "      <td>m478</td>\n",
       "      <td>Midnight-Cowboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COOL WOMAN</td>\n",
       "      <td>This, this image of the, the man eating woman....</td>\n",
       "      <td>1</td>\n",
       "      <td>m478</td>\n",
       "      <td>Midnight-Cowboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAD WOMAN</td>\n",
       "      <td>No, I never had, well, whatever it is you call...</td>\n",
       "      <td>1</td>\n",
       "      <td>m478</td>\n",
       "      <td>Midnight-Cowboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAD WOMAN'S VOICE</td>\n",
       "      <td>... but it's a problem. A big problem. With so...</td>\n",
       "      <td>1</td>\n",
       "      <td>m478</td>\n",
       "      <td>Midnight-Cowboy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Speaker                                               Line  \\\n",
       "0          MODERATOR  Tonight we'll discuss a subject most of us see...   \n",
       "1        IRATE WOMAN  They always put it that way, but well, all it ...   \n",
       "2         COOL WOMAN  This, this image of the, the man eating woman....   \n",
       "3          SAD WOMAN  No, I never had, well, whatever it is you call...   \n",
       "4  SAD WOMAN'S VOICE  ... but it's a problem. A big problem. With so...   \n",
       "\n",
       "   Label MovieID        MovieName  \n",
       "0      1    m478  Midnight-Cowboy  \n",
       "1      1    m478  Midnight-Cowboy  \n",
       "2      1    m478  Midnight-Cowboy  \n",
       "3      1    m478  Midnight-Cowboy  \n",
       "4      1    m478  Midnight-Cowboy  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(script_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162832"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_data_set.Label.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 718524 sentences and 162832 dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
