{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import chardet\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "TextTiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity determination:\n",
    "\n",
    "\n",
    "* Vocabulary Introduction: Similarity is measured as the negative of the number of new terms introduced on either side of the gap\n",
    "\n",
    "* Block Comparison: compute correlation coefficients between left and right blocks based on within-block term frequency (without inverse document frequency) (We will use this method) Normalized inner product of two word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cornell dataset\n",
    "\n",
    "### sort lines by IDs and save to .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import smart_open\n",
    "import os\n",
    "import chardet\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = set(stopwords.words('english'))\n",
    "\n",
    "def read_lines(dirname):\n",
    "    line_dict = {}\n",
    "    with open(dirname, 'r', encoding='iso-8859-1') as f:  # TODO: Solve Iso encoding pb !\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        for line in f:\n",
    "            line = line.replace('[','').replace(']','')\n",
    "            tmp = line.split('\\n')[0].split(\" +++$+++ \")\n",
    "            line_ = nltk.word_tokenize(tmp[-1])\n",
    "#             line_ = tokenizer.tokenize(tmp[-1].lower())\n",
    "#             line_ = [x for x in line_ if x not in stop]\n",
    "            line_dict[tmp[0]] = {'ID1':tmp[1],'MovieID':tmp[2],'Name':tmp[3],'Line':line_}\n",
    "        return line_dict\n",
    "    \n",
    "def read_conversations(dirname):\n",
    "    conva_dict = {}\n",
    "    with open(dirname, 'r', encoding='iso-8859-1') as f:  # TODO: Solve Iso encoding pb !\n",
    "        for line in f:\n",
    "            line = line.replace('[','').replace(']','').replace('\\'','')\n",
    "            tmp = line.split('\\n')[0].split(\" +++$+++ \")\n",
    "            yield tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines = read_lines('../datasets/cornell-corpus/movie_lines.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conversations = read_conversations('../datasets/cornell-corpus/movie_conversations.txt')\n",
    "conversations = [x for x in conversations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeakerID1</th>\n",
       "      <th>SpeakerID2</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>LineIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L194, L195, L196, L197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L198, L199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L200, L201, L202, L203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L204, L205, L206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L207, L208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SpeakerID1 SpeakerID2 MovieID                 LineIDs\n",
       "0         u0         u2      m0  L194, L195, L196, L197\n",
       "1         u0         u2      m0              L198, L199\n",
       "2         u0         u2      m0  L200, L201, L202, L203\n",
       "3         u0         u2      m0        L204, L205, L206\n",
       "4         u0         u2      m0              L207, L208"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations = pd.DataFrame(conversations)\n",
    "conversations.columns = ['SpeakerID1','SpeakerID2','MovieID','LineIDs']\n",
    "conversations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeakerID1</th>\n",
       "      <th>SpeakerID2</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>LineIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L194, L195, L196, L197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L198, L199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L200, L201, L202, L203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L204, L205, L206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L207, L208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L271, L272, L273, L274, L275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L276, L277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L280, L281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L363, L364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L365, L366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L367, L368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L401, L402, L403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L404, L405, L406, L407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L575, L576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L577, L578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L662, L663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L693, L694, L695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L696, L697, L698, L699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L860, L861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L862, L863, L864, L865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L866, L867, L868, L869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L870, L871, L872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L924, L925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L984, L985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L1044, L1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L571, L572, L573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L579, L580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L595, L596, L597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L598, L599, L600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83067</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>m615</td>\n",
       "      <td>L666158, L666159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83068</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>m615</td>\n",
       "      <td>L666160, L666161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83069</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>m615</td>\n",
       "      <td>L666166, L666167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83070</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>m615</td>\n",
       "      <td>L666168, L666169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83071</th>\n",
       "      <td>u9021</td>\n",
       "      <td>u9023</td>\n",
       "      <td>m615</td>\n",
       "      <td>L665987, L665988, L665989, L665990, L665991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83072</th>\n",
       "      <td>u9021</td>\n",
       "      <td>u9023</td>\n",
       "      <td>m615</td>\n",
       "      <td>L665992, L665993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83073</th>\n",
       "      <td>u9021</td>\n",
       "      <td>u9023</td>\n",
       "      <td>m615</td>\n",
       "      <td>L665994, L665995, L665996, L665997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83074</th>\n",
       "      <td>u9025</td>\n",
       "      <td>u9026</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666361, L666362, L666363, L666364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83075</th>\n",
       "      <td>u9025</td>\n",
       "      <td>u9026</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666365, L666366, L666367, L666368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83076</th>\n",
       "      <td>u9025</td>\n",
       "      <td>u9026</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666462, L666463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83077</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9032</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666388, L666389, L666390, L666391, L666392, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83078</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9032</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666503, L666504, L666505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83079</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666246, L666247, L666248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83080</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666249, L666250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83081</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666357, L666358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83082</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666480, L666481, L666482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83083</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666483, L666484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83084</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666487, L666488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83085</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666251, L666252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83086</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666383, L666384, L666385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83087</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666460, L666461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83088</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666485, L666486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83089</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666546, L666547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83090</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666497, L666498, L666499, L666500, L666501, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83091</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666262, L666263, L666264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83092</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666324, L666325, L666326, L666327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83093</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666575, L666576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83094</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666256, L666257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83095</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666369, L666370, L666371, L666372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83096</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>L666520, L666521, L666522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83097 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SpeakerID1 SpeakerID2 MovieID  \\\n",
       "0             u0         u2      m0   \n",
       "1             u0         u2      m0   \n",
       "2             u0         u2      m0   \n",
       "3             u0         u2      m0   \n",
       "4             u0         u2      m0   \n",
       "5             u0         u2      m0   \n",
       "6             u0         u2      m0   \n",
       "7             u0         u2      m0   \n",
       "8             u0         u2      m0   \n",
       "9             u0         u2      m0   \n",
       "10            u0         u2      m0   \n",
       "11            u0         u2      m0   \n",
       "12            u0         u2      m0   \n",
       "13            u0         u2      m0   \n",
       "14            u0         u2      m0   \n",
       "15            u0         u2      m0   \n",
       "16            u0         u2      m0   \n",
       "17            u0         u2      m0   \n",
       "18            u0         u2      m0   \n",
       "19            u0         u2      m0   \n",
       "20            u0         u2      m0   \n",
       "21            u0         u2      m0   \n",
       "22            u0         u2      m0   \n",
       "23            u0         u2      m0   \n",
       "24            u0         u2      m0   \n",
       "25            u0         u3      m0   \n",
       "26            u0         u3      m0   \n",
       "27            u0         u3      m0   \n",
       "28            u0         u3      m0   \n",
       "29            u0         u3      m0   \n",
       "...          ...        ...     ...   \n",
       "83067      u9019      u9020    m615   \n",
       "83068      u9019      u9020    m615   \n",
       "83069      u9019      u9020    m615   \n",
       "83070      u9019      u9020    m615   \n",
       "83071      u9021      u9023    m615   \n",
       "83072      u9021      u9023    m615   \n",
       "83073      u9021      u9023    m615   \n",
       "83074      u9025      u9026    m616   \n",
       "83075      u9025      u9026    m616   \n",
       "83076      u9025      u9026    m616   \n",
       "83077      u9027      u9032    m616   \n",
       "83078      u9027      u9032    m616   \n",
       "83079      u9027      u9030    m616   \n",
       "83080      u9027      u9030    m616   \n",
       "83081      u9027      u9030    m616   \n",
       "83082      u9027      u9030    m616   \n",
       "83083      u9027      u9030    m616   \n",
       "83084      u9027      u9030    m616   \n",
       "83085      u9027      u9029    m616   \n",
       "83086      u9027      u9029    m616   \n",
       "83087      u9027      u9029    m616   \n",
       "83088      u9027      u9029    m616   \n",
       "83089      u9027      u9029    m616   \n",
       "83090      u9028      u9033    m616   \n",
       "83091      u9028      u9031    m616   \n",
       "83092      u9028      u9031    m616   \n",
       "83093      u9028      u9031    m616   \n",
       "83094      u9030      u9034    m616   \n",
       "83095      u9030      u9034    m616   \n",
       "83096      u9030      u9034    m616   \n",
       "\n",
       "                                                 LineIDs  \n",
       "0                                 L194, L195, L196, L197  \n",
       "1                                             L198, L199  \n",
       "2                                 L200, L201, L202, L203  \n",
       "3                                       L204, L205, L206  \n",
       "4                                             L207, L208  \n",
       "5                           L271, L272, L273, L274, L275  \n",
       "6                                             L276, L277  \n",
       "7                                             L280, L281  \n",
       "8                                             L363, L364  \n",
       "9                                             L365, L366  \n",
       "10                                            L367, L368  \n",
       "11                                      L401, L402, L403  \n",
       "12                                L404, L405, L406, L407  \n",
       "13                                            L575, L576  \n",
       "14                                            L577, L578  \n",
       "15                                            L662, L663  \n",
       "16                                      L693, L694, L695  \n",
       "17                                L696, L697, L698, L699  \n",
       "18                                            L860, L861  \n",
       "19                                L862, L863, L864, L865  \n",
       "20                                L866, L867, L868, L869  \n",
       "21                                      L870, L871, L872  \n",
       "22                                            L924, L925  \n",
       "23                                            L984, L985  \n",
       "24                                          L1044, L1045  \n",
       "25                                         L49, L50, L51  \n",
       "26                                      L571, L572, L573  \n",
       "27                                            L579, L580  \n",
       "28                                      L595, L596, L597  \n",
       "29                                      L598, L599, L600  \n",
       "...                                                  ...  \n",
       "83067                                   L666158, L666159  \n",
       "83068                                   L666160, L666161  \n",
       "83069                                   L666166, L666167  \n",
       "83070                                   L666168, L666169  \n",
       "83071        L665987, L665988, L665989, L665990, L665991  \n",
       "83072                                   L665992, L665993  \n",
       "83073                 L665994, L665995, L665996, L665997  \n",
       "83074                 L666361, L666362, L666363, L666364  \n",
       "83075                 L666365, L666366, L666367, L666368  \n",
       "83076                                   L666462, L666463  \n",
       "83077  L666388, L666389, L666390, L666391, L666392, L...  \n",
       "83078                          L666503, L666504, L666505  \n",
       "83079                          L666246, L666247, L666248  \n",
       "83080                                   L666249, L666250  \n",
       "83081                                   L666357, L666358  \n",
       "83082                          L666480, L666481, L666482  \n",
       "83083                                   L666483, L666484  \n",
       "83084                                   L666487, L666488  \n",
       "83085                                   L666251, L666252  \n",
       "83086                          L666383, L666384, L666385  \n",
       "83087                                   L666460, L666461  \n",
       "83088                                   L666485, L666486  \n",
       "83089                                   L666546, L666547  \n",
       "83090  L666497, L666498, L666499, L666500, L666501, L...  \n",
       "83091                          L666262, L666263, L666264  \n",
       "83092                 L666324, L666325, L666326, L666327  \n",
       "83093                                   L666575, L666576  \n",
       "83094                                   L666256, L666257  \n",
       "83095                 L666369, L666370, L666371, L666372  \n",
       "83096                          L666520, L666521, L666522  \n",
       "\n",
       "[83097 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L194 Can we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad . Again .\n",
      "L195 Well , I thought we 'd start with pronunciation , if that 's okay with you .\n",
      "L196 Not the hacking and gagging and spitting part . Please .\n",
      "L197 Okay ... then how 'bout we try out some French cuisine . Saturday ? Night ?\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[0].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L198 You 're asking me out . That 's so cute . What 's your name again ?\n",
      "L199 Forget it .\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[1].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L200 No , no , it 's my fault -- we did n't have a proper introduction -- -\n",
      "L201 Cameron .\n",
      "L202 The thing is , Cameron -- I 'm at the mercy of a particularly hideous breed of loser . My sister . I ca n't date until she does .\n",
      "L203 Seems like she could get a date easy enough ...\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[2].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L204 Why ?\n",
      "L205 Unsolved mystery . She used to be really popular when she started high school , then it was just like she got sick of it or something .\n",
      "L206 That 's a shame .\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[3].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L207 Gosh , if only we could find Kat a boyfriend ...\n",
      "L208 Let me see what I can do .\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[4].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeakerID1</th>\n",
       "      <th>SpeakerID2</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>LineIDs</th>\n",
       "      <th>startID</th>\n",
       "      <th>endID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>L59, L60, L61, L62</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L63, L64, L65</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L66, L67, L68, L69, L70, L71, L72, L73, L74</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L77, L78</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SpeakerID1 SpeakerID2 MovieID                                      LineIDs  \\\n",
       "0         u0         u3      m0                                L49, L50, L51   \n",
       "1         u8         u9      m0                           L59, L60, L61, L62   \n",
       "2         u2         u7      m0                                L63, L64, L65   \n",
       "3         u2         u7      m0  L66, L67, L68, L69, L70, L71, L72, L73, L74   \n",
       "4         u2         u7      m0                                     L77, L78   \n",
       "\n",
       "   startID  endID  \n",
       "0       49     51  \n",
       "1       59     62  \n",
       "2       63     65  \n",
       "3       66     74  \n",
       "4       77     78  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_func(string):\n",
    "    return int(string.split(', ')[0][1:])\n",
    "def split_func2(string):\n",
    "    return int(string.split(', ')[-1][1:])\n",
    "\n",
    "conversations['startID'] = conversations.LineIDs.apply(split_func)\n",
    "conversations['endID'] = conversations.LineIDs.apply(split_func2)\n",
    "conversations = conversations.sort_values(by='startID').reset_index(drop=True)\n",
    "conversations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeakerID1</th>\n",
       "      <th>SpeakerID2</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>LineIDs</th>\n",
       "      <th>startID</th>\n",
       "      <th>endID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>L59, L60, L61, L62</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L63, L64, L65</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L66, L67, L68, L69, L70, L71, L72, L73, L74</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L77, L78</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SpeakerID1 SpeakerID2 MovieID                                      LineIDs  \\\n",
       "0         u0         u3      m0                                L49, L50, L51   \n",
       "1         u8         u9      m0                           L59, L60, L61, L62   \n",
       "2         u2         u7      m0                                L63, L64, L65   \n",
       "3         u2         u7      m0  L66, L67, L68, L69, L70, L71, L72, L73, L74   \n",
       "4         u2         u7      m0                                     L77, L78   \n",
       "\n",
       "   startID  endID  label  \n",
       "0       49     51      1  \n",
       "1       59     62      1  \n",
       "2       63     65      1  \n",
       "3       66     74      0  \n",
       "4       77     78      1  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (conversations[['SpeakerID1','SpeakerID2']] == conversations[['SpeakerID1','SpeakerID2']].shift())\n",
    "test = test['SpeakerID1'] & test['SpeakerID2']\n",
    "test2 = (conversations['startID'] == conversations['endID'].shift()+1)\n",
    "conversations['label'] = 1-(test & test2)*1\n",
    "conversations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len_ = np.where(conversations.label==1)[0][1:] - np.where(conversations.label==1)[0][:-1]\n",
    "len_ = np.append(len_,conversations.label.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_no = [[x]*y for x,y in zip(np.arange(sum(conversations.label)),len_)]\n",
    "dialogue_no = [item for sublist in dialogue_no for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations['dialogue_no'] = dialogue_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>LineIDs</th>\n",
       "      <th>startID</th>\n",
       "      <th>endID</th>\n",
       "      <th>label</th>\n",
       "      <th>dialogue_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>L59, L60, L61, L62</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L63, L64, L65</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L66, L67, L68, L69, L70, L71, L72, L73, L74</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>L77, L78</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID1 ID2 MovieID                                      LineIDs  startID  \\\n",
       "0  u0  u3      m0                                L49, L50, L51       49   \n",
       "1  u8  u9      m0                           L59, L60, L61, L62       59   \n",
       "2  u2  u7      m0                                L63, L64, L65       63   \n",
       "3  u2  u7      m0  L66, L67, L68, L69, L70, L71, L72, L73, L74       66   \n",
       "4  u2  u7      m0                                     L77, L78       77   \n",
       "\n",
       "   endID  label  dialogue_no  \n",
       "0     51      1            0  \n",
       "1     62      1            1  \n",
       "2     65      1            2  \n",
       "3     74      0            2  \n",
       "4     78      1            3  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L63 You the new guy ?\n",
      "L64 So they tell me ...\n",
      "L65 C'mon . I 'm supposed to give you the tour .\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[2].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L66 So -- which Dakota you from ?\n",
      "L67 North , actually . How 'd you ?\n",
      "L68 I was kidding . People actually live there ?\n",
      "L69 Yeah . A couple . We 're outnumbered by the cows , though .\n",
      "L70 How many people were in your old school ?\n",
      "L71 Thirty-two .\n",
      "L72 Get out !\n",
      "L73 How many people go here ?\n",
      "L74 Couple thousand . Most of them evil\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[3].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L77 That I 'm used to .\n",
      "L78 Yeah , but these guys have never seen a horse . They just jack off to Clint Eastwood .\n"
     ]
    }
   ],
   "source": [
    "for ids in conversations.LineIDs[4].split(', '):\n",
    "    print(ids,' '.join(movie_lines[ids]['Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo = lambda a: ', '.join(a) \n",
    "conv_new = conversations.groupby(['ID1','ID2','dialogue_no']).agg({'LineIDs':foo}).reset_index()\n",
    "conv_new = conv_new.sort_values(by='dialogue_no').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_new['Turn'] = conv_new.LineIDs.str.split(',').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wlen(IDs):\n",
    "    \"\"\"\n",
    "    Return average word counts of each sentence in one dialogue.\n",
    "    \"\"\"\n",
    "    l = 0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for ID in IDs:\n",
    "        l += len(tokenizer.tokenize(' '.join(movie_lines[ID]['Line'])))\n",
    "    return l/len(IDs)\n",
    "\n",
    "conv_new['Word_cnt'] = conv_new.LineIDs.str.split(', ').apply(avg_wlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>dialogue_no</th>\n",
       "      <th>LineIDs</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "      <td>3</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>1</td>\n",
       "      <td>L59, L60, L61, L62</td>\n",
       "      <td>4</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>2</td>\n",
       "      <td>L63, L64, L65, L66, L67, L68, L69, L70, L71, L...</td>\n",
       "      <td>12</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>3</td>\n",
       "      <td>L77, L78</td>\n",
       "      <td>2</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>4</td>\n",
       "      <td>L87, L88, L89, L90, L91, L92</td>\n",
       "      <td>6</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u5</td>\n",
       "      <td>u8</td>\n",
       "      <td>5</td>\n",
       "      <td>L103, L104, L105, L106, L107, L108, L109</td>\n",
       "      <td>7</td>\n",
       "      <td>12.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u5</td>\n",
       "      <td>u6</td>\n",
       "      <td>6</td>\n",
       "      <td>L123, L124, L125, L126, L127, L128, L129, L130...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>7</td>\n",
       "      <td>L139, L140, L141, L142, L143, L144, L145, L146...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u4</td>\n",
       "      <td>u5</td>\n",
       "      <td>8</td>\n",
       "      <td>L148, L149, L150</td>\n",
       "      <td>3</td>\n",
       "      <td>14.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u5</td>\n",
       "      <td>u6</td>\n",
       "      <td>9</td>\n",
       "      <td>L151, L152</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID1 ID2  dialogue_no                                            LineIDs  \\\n",
       "0  u0  u3            0                                      L49, L50, L51   \n",
       "1  u8  u9            1                                 L59, L60, L61, L62   \n",
       "2  u2  u7            2  L63, L64, L65, L66, L67, L68, L69, L70, L71, L...   \n",
       "3  u2  u7            3                                           L77, L78   \n",
       "4  u2  u7            4                       L87, L88, L89, L90, L91, L92   \n",
       "5  u5  u8            5           L103, L104, L105, L106, L107, L108, L109   \n",
       "6  u5  u6            6  L123, L124, L125, L126, L127, L128, L129, L130...   \n",
       "7  u2  u7            7  L139, L140, L141, L142, L143, L144, L145, L146...   \n",
       "8  u4  u5            8                                   L148, L149, L150   \n",
       "9  u5  u6            9                                         L151, L152   \n",
       "\n",
       "   Turn   Word_cnt  \n",
       "0     3   4.333333  \n",
       "1     4   7.250000  \n",
       "2    12   5.666667  \n",
       "3     2  10.500000  \n",
       "4     6   8.666667  \n",
       "5     7  12.714286  \n",
       "6    12  10.250000  \n",
       "7     9  12.888889  \n",
       "8     3  14.333333  \n",
       "9     2  11.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_no</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60699.000000</td>\n",
       "      <td>60699.000000</td>\n",
       "      <td>60699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30349.000000</td>\n",
       "      <td>5.020066</td>\n",
       "      <td>11.023440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17522.436332</td>\n",
       "      <td>5.312256</td>\n",
       "      <td>7.323081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15174.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.281746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30349.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45523.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dialogue_no          Turn      Word_cnt\n",
       "count  60699.000000  60699.000000  60699.000000\n",
       "mean   30349.000000      5.020066     11.023440\n",
       "std    17522.436332      5.312256      7.323081\n",
       "min        0.000000      2.000000      0.000000\n",
       "25%    15174.500000      2.000000      6.281746\n",
       "50%    30349.000000      3.000000      9.500000\n",
       "75%    45523.500000      6.000000     13.857143\n",
       "max    60698.000000    161.000000    196.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_new.to_csv('../datasets/cornell-corpus/cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cornell corpus line by line in .txt\n",
    "# for movie in conversations.MovieID.unique():\n",
    "#     tmp_df = conversations.loc[conversations.MovieID==movie].copy()\n",
    "#     tmp_df = pd.DataFrame(tmp_df.LineIDs.str.split(', ').tolist(),index=tmp_df.MovieID).stack()\n",
    "#     tmp_df = tmp_df.reset_index()\n",
    "#     tmp_df.columns = ['MovieID','label','LineIDs']\n",
    "#     for i in range(len(tmp_df)):\n",
    "#         s = movie_lines[tmp_df.LineIDs.loc[i]]['Line']\n",
    "#         with open('./data/cornell/%s.txt'%movie, 'a') as f:\n",
    "#             f.write(' '.join(s)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word2vec model with virtual sentences\n",
    "\n",
    "improve our own model using google-news\n",
    "\n",
    "https://stackoverflow.com/questions/35117491/is-it-possible-to-re-train-a-word2vec-model-e-g-googlenews-vectors-negative300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from prettytable import PrettyTable\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "ps = PorterStemmer() \n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取单词的词性\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "def lemma_sentence(s):\n",
    "    sentence = s\n",
    "    tokens = tokenizer.tokenize(sentence)  # 分词\n",
    "    tagged_sent = pos_tag(tokens)     # 获取单词词性\n",
    "\n",
    "    lemmas_sent = []\n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmas_sent.append(lemmatizer.lemmatize(tag[0], pos=wordnet_pos)) # 词形还原\n",
    "    return lemmas_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First train word embedding model without virtual sentence.\n",
    "\n",
    "Model 2: not lower case, not virtual sentence\n",
    "\n",
    "Model 3: not lower case, virtual sentence\n",
    "\n",
    "Model 4: not lower, virtual sentence, token\n",
    "\n",
    "Model 5: lower case, not virtual sentence\n",
    "\n",
    "Model 6: lower case, virtual sentence\n",
    "\n",
    "Model 7: lower, virtual sentence, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.split() # not using virtual sentences\n",
    "#                 tmp = line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2745632, 4180181)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model2 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model2.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model2.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model2.train(sentences,total_examples=model2.corpus_count,epochs=model2.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('./word2vec/model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            tmp = []\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield tmp+line.split() # virtual sentences\n",
    "                tmp = line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5553679, 8351942)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model3 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model3.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model3.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model3.train(sentences,total_examples=model3.corpus_count,epochs=model3.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('./word2vec/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#         stop = set(stopwords.words('english'))\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            tmp = []\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                tmp2 = tokenizer.tokenize(line)\n",
    "                yield tmp+tmp2 # virtual sentences\n",
    "                tmp = tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067186, 6942548)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model4 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model4.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model4.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model4.train(sentences,total_examples=model4.corpus_count,epochs=model4.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('./word2vec/model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.lower().split() # not using virtual sentences\n",
    "#                 tmp = line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2619559, 4180181)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model5 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model5.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model5.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model5.train(sentences,total_examples=model5.corpus_count,epochs=model5.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save('./word2vec/model5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            tmp = []\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield tmp+line.lower().split() # virtual sentences\n",
    "                tmp = line.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5290330, 8351942)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model6 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model6.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model6.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model6.train(sentences,total_examples=model6.corpus_count,epochs=model6.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save('./word2vec/model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#         stop = set(stopwords.words('english'))\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            tmp = []\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                tmp2 = tokenizer.tokenize(line.lower())\n",
    "                yield tmp+tmp2 # virtual sentences\n",
    "                tmp = tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4786896, 6942548)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model7 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model7.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model7.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model7.train(sentences,total_examples=model7.corpus_count,epochs=model7.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.save('./word2vec/model7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model from files sentence by sentence\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#         stop = set(stopwords.words('english'))\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            tmp = []\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                tmp2 = tokenizer.tokenize(line.lower())\n",
    "                yield tmp2 # virtual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2371245, 3474699)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = MySentences('./data/cornell/') # a memory-friendly iterator\n",
    "model8 = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model8.build_vocab(sentences)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model8.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model8.train(sentences,total_examples=model8.corpus_count,epochs=model8.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save('./word2vec/model8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38515984360096356"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('Thank','welcome') #not lower, not virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3362176925914835"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.similarity('Thank','welcome') #not lower, virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3993099605938164"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.wv.similarity('Thank','welcome') #not lower, virtual, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42422152702440713"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.wv.similarity('thank','welcome') # lower, not virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4431465429842917"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.wv.similarity('thank','welcome') # lower, virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42022125910372576"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.wv.similarity('thank','welcome') # lower, virtual, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance of virtual sentence training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cos_sim(v1,v2):\n",
    "    return v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "def heuristic_max(s1,s2,model):\n",
    "    if len(s1)*len(s2) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    matrix = np.zeros((len(s1),len(s2)))\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] in model.vocab.keys():\n",
    "            s1_vec = model[s1[i]]\n",
    "        else:\n",
    "            continue # if the source target word is not in vocabulary list then corresponding similiarity row = 0\n",
    "        for j in range(len(s2)):            \n",
    "            if s2[j] in model.vocab.keys():\n",
    "                s2_vec = model[s2[j]]\n",
    "                matrix[i][j] = cos_sim(s1_vec,s2_vec)\n",
    "            else:\n",
    "                continue # for not-found words the similarity is 0\n",
    "    s1_sim =  np.sum(np.max(matrix,1))/len(s1)\n",
    "    s2_sim = np.sum(np.max(matrix,0))/len(s2)\n",
    "    return np.round(s1_sim,5),np.round(s2_sim,5),1/2*(np.round(s1_sim,5)+np.round(s2_sim,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'Thank you so much for your help '\n",
    "s2 = 'You are welcome '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38272, 0.45723, 0.419975)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_max(s1.split(),s2.split(),model=model2.wv)  #not lower, not virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30699, 0.4064, 0.356695)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_max(s1.split(),s2.split(),model=model3.wv) #not lower, virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34948, 0.43785, 0.39366500000000004)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_ = tokenizer.tokenize(s1)\n",
    "s2_ = tokenizer.tokenize(s2)\n",
    "heuristic_max(s1_,s2_,model=model4.wv) #not lower, virtual, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46657, 0.5652, 0.515885)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_max(s1.lower().split(),s2.lower().split(),model=model5.wv) # lower, not virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43626, 0.58689, 0.511575)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_max(s1.lower().split(),s2.lower().split(),model=model6.wv) # lower, virtual, not token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44656, 0.57403, 0.510295)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_ = tokenizer.tokenize(s1.lower())\n",
    "s2_ = tokenizer.tokenize(s2.lower())\n",
    "heuristic_max(s1_,s2_,model=model7.wv) # lower, virtual, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### session segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "# model1 = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = gensim.models.Word2Vec.load('./word2vec/model4')\n",
    "model5 = gensim.models.Word2Vec.load('./word2vec/model5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1,v2):\n",
    "    return v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_max(s1_ID,s2_ID,line_dict,lower_,token_,model):\n",
    "#     s1 = list(set(s1))\n",
    "#     s2 = list(set(s2))\n",
    "    s1 = ' '.join(movie_lines[s1_ID]['Line'])\n",
    "    s2 = ' '.join(movie_lines[s2_ID]['Line'])\n",
    "    if lower_:\n",
    "        s1 = s1.lower()\n",
    "        s2 = s2.lower()\n",
    "    if token_:\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        s1 = ' '.join(tokenizer.tokenize(s1))\n",
    "        s2 = ' '.join(tokenizer.tokenize(s2))\n",
    "    \n",
    "    s1 = s1.split(' ')\n",
    "    s2 = s2.split(' ')\n",
    "    \n",
    "    if len(s1)*len(s2) == 0:\n",
    "        return 0\n",
    "    matrix = np.zeros((len(s1),len(s2)))\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] in model.vocab.keys():\n",
    "            s1_vec = model[s1[i]]\n",
    "        else:\n",
    "            continue # if the source target word is not in vocabulary list then corresponding similiarity row = 0\n",
    "        for j in range(len(s2)):            \n",
    "            if s2[j] in model.vocab.keys():\n",
    "                s2_vec = model[s2[j]]\n",
    "                matrix[i][j] = cos_sim(s1_vec,s2_vec)\n",
    "            else:\n",
    "                continue # for not-found words the similarity is 0\n",
    "    s1_sim =  np.sum(np.max(matrix,1))/len(s1)\n",
    "    s2_sim = np.sum(np.max(matrix,0))/len(s2)\n",
    "    return np.round(s1_sim,5),np.round(s2_sim,5),1/2*(np.round(s1_sim,5)+np.round(s2_sim,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html\n",
    "import numpy\n",
    "\n",
    "def smooth(x,window_len=7,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise(ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise(ValueError, \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise(ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=numpy.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=numpy.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=numpy.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y[window_len//2:-window_len//2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_no</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60699.000000</td>\n",
       "      <td>60699.000000</td>\n",
       "      <td>60699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30349.000000</td>\n",
       "      <td>5.020066</td>\n",
       "      <td>11.023440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17522.436332</td>\n",
       "      <td>5.312256</td>\n",
       "      <td>7.323081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15174.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.281746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30349.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45523.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dialogue_no          Turn      Word_cnt\n",
       "count  60699.000000  60699.000000  60699.000000\n",
       "mean   30349.000000      5.020066     11.023440\n",
       "std    17522.436332      5.312256      7.323081\n",
       "min        0.000000      2.000000      0.000000\n",
       "25%    15174.500000      2.000000      6.281746\n",
       "50%    30349.000000      3.000000      9.500000\n",
       "75%    45523.500000      6.000000     13.857143\n",
       "max    60698.000000    161.000000    196.000000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_new = pd.read_csv('../datasets/cornell-corpus/cleaned.csv')\n",
    "conv_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>dialogue_no</th>\n",
       "      <th>LineIDs</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u3</td>\n",
       "      <td>0</td>\n",
       "      <td>L49, L50, L51</td>\n",
       "      <td>3</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>1</td>\n",
       "      <td>L59, L60, L61, L62</td>\n",
       "      <td>4</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>2</td>\n",
       "      <td>L63, L64, L65, L66, L67, L68, L69, L70, L71, L...</td>\n",
       "      <td>12</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>3</td>\n",
       "      <td>L77, L78</td>\n",
       "      <td>2</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>4</td>\n",
       "      <td>L87, L88, L89, L90, L91, L92</td>\n",
       "      <td>6</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u5</td>\n",
       "      <td>u8</td>\n",
       "      <td>5</td>\n",
       "      <td>L103, L104, L105, L106, L107, L108, L109</td>\n",
       "      <td>7</td>\n",
       "      <td>12.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u5</td>\n",
       "      <td>u6</td>\n",
       "      <td>6</td>\n",
       "      <td>L123, L124, L125, L126, L127, L128, L129, L130...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>7</td>\n",
       "      <td>L139, L140, L141, L142, L143, L144, L145, L146...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u4</td>\n",
       "      <td>u5</td>\n",
       "      <td>8</td>\n",
       "      <td>L148, L149, L150</td>\n",
       "      <td>3</td>\n",
       "      <td>14.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u5</td>\n",
       "      <td>u6</td>\n",
       "      <td>9</td>\n",
       "      <td>L151, L152</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>10</td>\n",
       "      <td>L157, L158, L159</td>\n",
       "      <td>3</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u10</td>\n",
       "      <td>u11</td>\n",
       "      <td>11</td>\n",
       "      <td>L161, L162</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u0</td>\n",
       "      <td>u5</td>\n",
       "      <td>12</td>\n",
       "      <td>L164, L165</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u10</td>\n",
       "      <td>u11</td>\n",
       "      <td>13</td>\n",
       "      <td>L170, L171</td>\n",
       "      <td>2</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u5</td>\n",
       "      <td>u11</td>\n",
       "      <td>14</td>\n",
       "      <td>L172, L173, L174</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>u0</td>\n",
       "      <td>u11</td>\n",
       "      <td>15</td>\n",
       "      <td>L179, L180, L181, L182, L183</td>\n",
       "      <td>5</td>\n",
       "      <td>11.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u5</td>\n",
       "      <td>u11</td>\n",
       "      <td>16</td>\n",
       "      <td>L184, L185</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u0</td>\n",
       "      <td>u11</td>\n",
       "      <td>17</td>\n",
       "      <td>L189, L190</td>\n",
       "      <td>2</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u10</td>\n",
       "      <td>u11</td>\n",
       "      <td>18</td>\n",
       "      <td>L191, L192, L193</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>19</td>\n",
       "      <td>L194, L195, L196, L197, L198, L199, L200, L201...</td>\n",
       "      <td>15</td>\n",
       "      <td>11.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>20</td>\n",
       "      <td>L210, L211, L212, L213</td>\n",
       "      <td>4</td>\n",
       "      <td>11.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>21</td>\n",
       "      <td>L215, L216, L217, L218, L219, L220, L221, L222...</td>\n",
       "      <td>11</td>\n",
       "      <td>12.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u4</td>\n",
       "      <td>u7</td>\n",
       "      <td>22</td>\n",
       "      <td>L231, L232, L233, L234, L235, L236</td>\n",
       "      <td>6</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u4</td>\n",
       "      <td>u7</td>\n",
       "      <td>23</td>\n",
       "      <td>L238, L239, L240</td>\n",
       "      <td>3</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u2</td>\n",
       "      <td>u7</td>\n",
       "      <td>24</td>\n",
       "      <td>L244, L245</td>\n",
       "      <td>2</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>u5</td>\n",
       "      <td>u6</td>\n",
       "      <td>25</td>\n",
       "      <td>L247, L248, L249, L250, L251, L252, L253, L254</td>\n",
       "      <td>8</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>26</td>\n",
       "      <td>L257, L258, L259</td>\n",
       "      <td>3</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u8</td>\n",
       "      <td>u9</td>\n",
       "      <td>27</td>\n",
       "      <td>L261, L262, L263, L264</td>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>28</td>\n",
       "      <td>L271, L272, L273, L274, L275, L276, L277</td>\n",
       "      <td>7</td>\n",
       "      <td>13.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>29</td>\n",
       "      <td>L280, L281</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60669</th>\n",
       "      <td>u9015</td>\n",
       "      <td>u9023</td>\n",
       "      <td>60669</td>\n",
       "      <td>L666116, L666117, L666118, L666119</td>\n",
       "      <td>4</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60670</th>\n",
       "      <td>u9015</td>\n",
       "      <td>u9023</td>\n",
       "      <td>60670</td>\n",
       "      <td>L666123, L666124, L666125</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60671</th>\n",
       "      <td>u9015</td>\n",
       "      <td>u9023</td>\n",
       "      <td>60671</td>\n",
       "      <td>L666127, L666128, L666129, L666130</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60672</th>\n",
       "      <td>u9017</td>\n",
       "      <td>u9019</td>\n",
       "      <td>60672</td>\n",
       "      <td>L666134, L666135, L666136, L666137, L666138</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60673</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>60673</td>\n",
       "      <td>L666149, L666150, L666151, L666152, L666153, L...</td>\n",
       "      <td>8</td>\n",
       "      <td>7.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60674</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>60674</td>\n",
       "      <td>L666158, L666159, L666160, L666161</td>\n",
       "      <td>4</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60675</th>\n",
       "      <td>u9019</td>\n",
       "      <td>u9020</td>\n",
       "      <td>60675</td>\n",
       "      <td>L666166, L666167, L666168, L666169</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60676</th>\n",
       "      <td>u9015</td>\n",
       "      <td>u9023</td>\n",
       "      <td>60676</td>\n",
       "      <td>L666196, L666197, L666198, L666199, L666200, L...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60677</th>\n",
       "      <td>u9017</td>\n",
       "      <td>u9020</td>\n",
       "      <td>60677</td>\n",
       "      <td>L666210, L666211</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60678</th>\n",
       "      <td>u9017</td>\n",
       "      <td>u9020</td>\n",
       "      <td>60678</td>\n",
       "      <td>L666214, L666215, L666216, L666217, L666218, L...</td>\n",
       "      <td>9</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60679</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>60679</td>\n",
       "      <td>L666246, L666247, L666248, L666249, L666250</td>\n",
       "      <td>5</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60680</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>60680</td>\n",
       "      <td>L666251, L666252</td>\n",
       "      <td>2</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60681</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>60681</td>\n",
       "      <td>L666256, L666257</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60682</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>60682</td>\n",
       "      <td>L666262, L666263, L666264</td>\n",
       "      <td>3</td>\n",
       "      <td>16.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60683</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>60683</td>\n",
       "      <td>L666324, L666325, L666326, L666327</td>\n",
       "      <td>4</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60684</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>60684</td>\n",
       "      <td>L666357, L666358</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60685</th>\n",
       "      <td>u9025</td>\n",
       "      <td>u9026</td>\n",
       "      <td>60685</td>\n",
       "      <td>L666361, L666362, L666363, L666364, L666365, L...</td>\n",
       "      <td>8</td>\n",
       "      <td>21.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60686</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>60686</td>\n",
       "      <td>L666369, L666370, L666371, L666372</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60687</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>60687</td>\n",
       "      <td>L666383, L666384, L666385</td>\n",
       "      <td>3</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60688</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9032</td>\n",
       "      <td>60688</td>\n",
       "      <td>L666388, L666389, L666390, L666391, L666392, L...</td>\n",
       "      <td>11</td>\n",
       "      <td>14.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60689</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>60689</td>\n",
       "      <td>L666460, L666461</td>\n",
       "      <td>2</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60690</th>\n",
       "      <td>u9025</td>\n",
       "      <td>u9026</td>\n",
       "      <td>60690</td>\n",
       "      <td>L666462, L666463</td>\n",
       "      <td>2</td>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60691</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>60691</td>\n",
       "      <td>L666480, L666481, L666482, L666483, L666484</td>\n",
       "      <td>5</td>\n",
       "      <td>15.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60692</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>60692</td>\n",
       "      <td>L666485, L666486</td>\n",
       "      <td>2</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60693</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>60693</td>\n",
       "      <td>L666487, L666488</td>\n",
       "      <td>2</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60694</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>60694</td>\n",
       "      <td>L666497, L666498, L666499, L666500, L666501, L...</td>\n",
       "      <td>6</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60695</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9032</td>\n",
       "      <td>60695</td>\n",
       "      <td>L666503, L666504, L666505</td>\n",
       "      <td>3</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60696</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>60696</td>\n",
       "      <td>L666520, L666521, L666522</td>\n",
       "      <td>3</td>\n",
       "      <td>17.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60697</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>60697</td>\n",
       "      <td>L666546, L666547</td>\n",
       "      <td>2</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60698</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>60698</td>\n",
       "      <td>L666575, L666576</td>\n",
       "      <td>2</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60699 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID1    ID2  dialogue_no  \\\n",
       "0         u0     u3            0   \n",
       "1         u8     u9            1   \n",
       "2         u2     u7            2   \n",
       "3         u2     u7            3   \n",
       "4         u2     u7            4   \n",
       "5         u5     u8            5   \n",
       "6         u5     u6            6   \n",
       "7         u2     u7            7   \n",
       "8         u4     u5            8   \n",
       "9         u5     u6            9   \n",
       "10        u2     u7           10   \n",
       "11       u10    u11           11   \n",
       "12        u0     u5           12   \n",
       "13       u10    u11           13   \n",
       "14        u5    u11           14   \n",
       "15        u0    u11           15   \n",
       "16        u5    u11           16   \n",
       "17        u0    u11           17   \n",
       "18       u10    u11           18   \n",
       "19        u0     u2           19   \n",
       "20        u2     u7           20   \n",
       "21        u2     u7           21   \n",
       "22        u4     u7           22   \n",
       "23        u4     u7           23   \n",
       "24        u2     u7           24   \n",
       "25        u5     u6           25   \n",
       "26        u8     u9           26   \n",
       "27        u8     u9           27   \n",
       "28        u0     u2           28   \n",
       "29        u0     u2           29   \n",
       "...      ...    ...          ...   \n",
       "60669  u9015  u9023        60669   \n",
       "60670  u9015  u9023        60670   \n",
       "60671  u9015  u9023        60671   \n",
       "60672  u9017  u9019        60672   \n",
       "60673  u9019  u9020        60673   \n",
       "60674  u9019  u9020        60674   \n",
       "60675  u9019  u9020        60675   \n",
       "60676  u9015  u9023        60676   \n",
       "60677  u9017  u9020        60677   \n",
       "60678  u9017  u9020        60678   \n",
       "60679  u9027  u9030        60679   \n",
       "60680  u9027  u9029        60680   \n",
       "60681  u9030  u9034        60681   \n",
       "60682  u9028  u9031        60682   \n",
       "60683  u9028  u9031        60683   \n",
       "60684  u9027  u9030        60684   \n",
       "60685  u9025  u9026        60685   \n",
       "60686  u9030  u9034        60686   \n",
       "60687  u9027  u9029        60687   \n",
       "60688  u9027  u9032        60688   \n",
       "60689  u9027  u9029        60689   \n",
       "60690  u9025  u9026        60690   \n",
       "60691  u9027  u9030        60691   \n",
       "60692  u9027  u9029        60692   \n",
       "60693  u9027  u9030        60693   \n",
       "60694  u9028  u9033        60694   \n",
       "60695  u9027  u9032        60695   \n",
       "60696  u9030  u9034        60696   \n",
       "60697  u9027  u9029        60697   \n",
       "60698  u9028  u9031        60698   \n",
       "\n",
       "                                                 LineIDs  Turn   Word_cnt  \n",
       "0                                          L49, L50, L51     3   4.333333  \n",
       "1                                     L59, L60, L61, L62     4   7.250000  \n",
       "2      L63, L64, L65, L66, L67, L68, L69, L70, L71, L...    12   5.666667  \n",
       "3                                               L77, L78     2  10.500000  \n",
       "4                           L87, L88, L89, L90, L91, L92     6   8.666667  \n",
       "5               L103, L104, L105, L106, L107, L108, L109     7  12.714286  \n",
       "6      L123, L124, L125, L126, L127, L128, L129, L130...    12  10.250000  \n",
       "7      L139, L140, L141, L142, L143, L144, L145, L146...     9  12.888889  \n",
       "8                                       L148, L149, L150     3  14.333333  \n",
       "9                                             L151, L152     2  11.000000  \n",
       "10                                      L157, L158, L159     3   6.333333  \n",
       "11                                            L161, L162     2   3.500000  \n",
       "12                                            L164, L165     2   3.500000  \n",
       "13                                            L170, L171     2   8.000000  \n",
       "14                                      L172, L173, L174     3   6.000000  \n",
       "15                          L179, L180, L181, L182, L183     5  11.800000  \n",
       "16                                            L184, L185     2   6.000000  \n",
       "17                                            L189, L190     2   5.500000  \n",
       "18                                      L191, L192, L193     3   6.000000  \n",
       "19     L194, L195, L196, L197, L198, L199, L200, L201...    15  11.266667  \n",
       "20                                L210, L211, L212, L213     4  11.750000  \n",
       "21     L215, L216, L217, L218, L219, L220, L221, L222...    11  12.909091  \n",
       "22                    L231, L232, L233, L234, L235, L236     6   6.333333  \n",
       "23                                      L238, L239, L240     3  18.333333  \n",
       "24                                            L244, L245     2  26.000000  \n",
       "25        L247, L248, L249, L250, L251, L252, L253, L254     8  12.000000  \n",
       "26                                      L257, L258, L259     3  13.000000  \n",
       "27                                L261, L262, L263, L264     4  17.000000  \n",
       "28              L271, L272, L273, L274, L275, L276, L277     7  13.142857  \n",
       "29                                            L280, L281     2   1.000000  \n",
       "...                                                  ...   ...        ...  \n",
       "60669                 L666116, L666117, L666118, L666119     4   2.750000  \n",
       "60670                          L666123, L666124, L666125     3   6.000000  \n",
       "60671                 L666127, L666128, L666129, L666130     4   4.000000  \n",
       "60672        L666134, L666135, L666136, L666137, L666138     5   7.000000  \n",
       "60673  L666149, L666150, L666151, L666152, L666153, L...     8   7.625000  \n",
       "60674                 L666158, L666159, L666160, L666161     4  12.750000  \n",
       "60675                 L666166, L666167, L666168, L666169     4   5.000000  \n",
       "60676  L666196, L666197, L666198, L666199, L666200, L...     8   6.375000  \n",
       "60677                                   L666210, L666211     2   5.000000  \n",
       "60678  L666214, L666215, L666216, L666217, L666218, L...     9   5.555556  \n",
       "60679        L666246, L666247, L666248, L666249, L666250     5  12.000000  \n",
       "60680                                   L666251, L666252     2  19.000000  \n",
       "60681                                   L666256, L666257     2  11.000000  \n",
       "60682                          L666262, L666263, L666264     3  16.333333  \n",
       "60683                 L666324, L666325, L666326, L666327     4   8.250000  \n",
       "60684                                   L666357, L666358     2  13.500000  \n",
       "60685  L666361, L666362, L666363, L666364, L666365, L...     8  21.750000  \n",
       "60686                 L666369, L666370, L666371, L666372     4  13.000000  \n",
       "60687                          L666383, L666384, L666385     3  11.000000  \n",
       "60688  L666388, L666389, L666390, L666391, L666392, L...    11  14.090909  \n",
       "60689                                   L666460, L666461     2   9.500000  \n",
       "60690                                   L666462, L666463     2  18.500000  \n",
       "60691        L666480, L666481, L666482, L666483, L666484     5  15.400000  \n",
       "60692                                   L666485, L666486     2  15.000000  \n",
       "60693                                   L666487, L666488     2  21.500000  \n",
       "60694  L666497, L666498, L666499, L666500, L666501, L...     6   7.000000  \n",
       "60695                          L666503, L666504, L666505     3  16.000000  \n",
       "60696                          L666520, L666521, L666522     3  17.666667  \n",
       "60697                                   L666546, L666547     2   6.500000  \n",
       "60698                                   L666575, L666576     2  14.000000  \n",
       "\n",
       "[60699 rows x 6 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_filter = conv_new.loc[(conv_new.Turn>=2) & (conv_new.Turn<=10) &\n",
    "                           (conv_new.Word_cnt>=6) & (conv_new.Word_cnt<=14)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60699"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29244"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>LineIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>L59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>L60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>L61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>L62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>L77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>L78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>L87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>L88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>L89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>L90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  label LineIDs\n",
       "0        1      1     L59\n",
       "1        1      0     L60\n",
       "2        1      0     L61\n",
       "3        1      0     L62\n",
       "4        3      1     L77\n",
       "5        3      0     L78\n",
       "6        4      1     L87\n",
       "7        4      0     L88\n",
       "8        4      0     L89\n",
       "9        4      0     L90"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(conv_filter.LineIDs.str.split(', ').tolist(),index=conv_filter.dialogue_no).stack()\n",
    "new_df = new_df.reset_index()\n",
    "new_df.columns = ['MovieID','label','LineIDs']\n",
    "new_df.label = 1 - new_df.label.clip(upper=1)\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim =  [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                    model=model2.wv,lower_=False,token_=False) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2: not lower, not virtual, not token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                    model=model2.wv,lower_=False,token_=False) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "new_df['model2_sim1'] = [1] + sim1\n",
    "new_df['model2_sim2'] = [1] + sim2\n",
    "new_df['model2_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3: not lower, virtual, not token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model3.wv,\n",
    "                     lower_=False,\n",
    "                     token_=False) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model3_sim1'] = [1] + sim1\n",
    "new_df['model3_sim2'] = [1] + sim2\n",
    "new_df['model3_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4: not lower, virtual, token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model4.wv,\n",
    "                     lower_=False,\n",
    "                     token_=True) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model4_sim1'] = [1] + sim1\n",
    "new_df['model4_sim2'] = [1] + sim2\n",
    "new_df['model4_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 5: lower, not virtual, not token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model5.wv,\n",
    "                     lower_=True,\n",
    "                     token_=False) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model5_sim1'] = [1] + sim1\n",
    "new_df['model5_sim2'] = [1] + sim2\n",
    "new_df['model5_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 6: lower, virtual, not token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model6.wv,\n",
    "                     lower_=True,\n",
    "                     token_=False) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model6_sim1'] = [1] + sim1\n",
    "new_df['model6_sim2'] = [1] + sim2\n",
    "new_df['model6_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 7: lower, virtual, token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model7.wv,\n",
    "                     lower_=True,\n",
    "                     token_=True) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model7_sim1'] = [1] + sim1\n",
    "new_df['model7_sim2'] = [1] + sim2\n",
    "new_df['model7_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 8: lower, not virtual, token\n",
    "sim = [heuristic_max(new_df.LineIDs[i],\n",
    "                     new_df.LineIDs[i+1],\n",
    "                     line_dict = movie_lines,\n",
    "                     model=model8.wv,\n",
    "                     lower_=True,\n",
    "                     token_=True) for i in range(len(new_df)-1)]\n",
    "sim1 = [x[0] for x in sim]\n",
    "sim2 = [x[1] for x in sim]\n",
    "simavg = [x[2] for x in sim]\n",
    "\n",
    "new_df['model8_sim1'] = [1] + sim1\n",
    "new_df['model8_sim2'] = [1] + sim2\n",
    "new_df['model8_simavg'] = [1] + simavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('TextSimilarity.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('TextSimilarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>model2_sim1</th>\n",
       "      <th>model2_sim2</th>\n",
       "      <th>model2_simavg</th>\n",
       "      <th>model3_sim1</th>\n",
       "      <th>model3_sim2</th>\n",
       "      <th>model3_simavg</th>\n",
       "      <th>model4_sim1</th>\n",
       "      <th>model4_sim2</th>\n",
       "      <th>model4_simavg</th>\n",
       "      <th>model5_sim1</th>\n",
       "      <th>model5_sim2</th>\n",
       "      <th>model5_simavg</th>\n",
       "      <th>model6_sim1</th>\n",
       "      <th>model6_sim2</th>\n",
       "      <th>model6_simavg</th>\n",
       "      <th>model7_sim1</th>\n",
       "      <th>model7_sim2</th>\n",
       "      <th>model7_simavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30241.910266</td>\n",
       "      <td>0.258948</td>\n",
       "      <td>0.489173</td>\n",
       "      <td>0.489499</td>\n",
       "      <td>0.489336</td>\n",
       "      <td>0.455521</td>\n",
       "      <td>0.455877</td>\n",
       "      <td>0.455699</td>\n",
       "      <td>0.367625</td>\n",
       "      <td>0.368238</td>\n",
       "      <td>0.367931</td>\n",
       "      <td>0.510997</td>\n",
       "      <td>0.511581</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>0.473556</td>\n",
       "      <td>0.473207</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.390578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17513.272867</td>\n",
       "      <td>0.438059</td>\n",
       "      <td>0.132533</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.108391</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.107585</td>\n",
       "      <td>0.165727</td>\n",
       "      <td>0.165830</td>\n",
       "      <td>0.145023</td>\n",
       "      <td>0.131772</td>\n",
       "      <td>0.133234</td>\n",
       "      <td>0.106857</td>\n",
       "      <td>0.137125</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.110441</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>0.166606</td>\n",
       "      <td>0.140670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058190</td>\n",
       "      <td>-0.075800</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.100010</td>\n",
       "      <td>-0.096010</td>\n",
       "      <td>-0.077365</td>\n",
       "      <td>-0.065490</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.145090</td>\n",
       "      <td>-0.184300</td>\n",
       "      <td>-0.130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15124.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.400340</td>\n",
       "      <td>0.419485</td>\n",
       "      <td>0.362640</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.267860</td>\n",
       "      <td>0.267990</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.421563</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.441802</td>\n",
       "      <td>0.376940</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.399367</td>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.286910</td>\n",
       "      <td>0.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30440.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.481110</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>0.442590</td>\n",
       "      <td>0.442970</td>\n",
       "      <td>0.451547</td>\n",
       "      <td>0.361110</td>\n",
       "      <td>0.361940</td>\n",
       "      <td>0.368402</td>\n",
       "      <td>0.501110</td>\n",
       "      <td>0.502085</td>\n",
       "      <td>0.511350</td>\n",
       "      <td>0.459725</td>\n",
       "      <td>0.459870</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.376555</td>\n",
       "      <td>0.378140</td>\n",
       "      <td>0.386350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45289.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569590</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.556934</td>\n",
       "      <td>0.534447</td>\n",
       "      <td>0.534567</td>\n",
       "      <td>0.520814</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.461097</td>\n",
       "      <td>0.457985</td>\n",
       "      <td>0.590037</td>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.577615</td>\n",
       "      <td>0.553625</td>\n",
       "      <td>0.554608</td>\n",
       "      <td>0.540645</td>\n",
       "      <td>0.478330</td>\n",
       "      <td>0.480167</td>\n",
       "      <td>0.476315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MovieID          label    model2_sim1    model2_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean    30241.910266       0.258948       0.489173       0.489499   \n",
       "std     17513.272867       0.438059       0.132533       0.132979   \n",
       "min         1.000000       0.000000      -0.058190      -0.075800   \n",
       "25%     15124.250000       0.000000       0.400020       0.400340   \n",
       "50%     30440.500000       0.000000       0.480600       0.481110   \n",
       "75%     45289.000000       1.000000       0.569590       0.570000   \n",
       "max     60698.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model2_simavg    model3_sim1    model3_sim2  model3_simavg  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.489336       0.455521       0.455877       0.455699   \n",
       "std         0.108391       0.134610       0.135085       0.107585   \n",
       "min        -0.037415      -0.056780      -0.041250      -0.005710   \n",
       "25%         0.419485       0.362640       0.362510       0.383170   \n",
       "50%         0.489415       0.442590       0.442970       0.451547   \n",
       "75%         0.556934       0.534447       0.534567       0.520814   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model4_sim1    model4_sim2  model4_simavg    model5_sim1  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.367625       0.368238       0.367931       0.510997   \n",
       "std         0.165727       0.165830       0.145023       0.131772   \n",
       "min        -0.225060      -0.225060      -0.225060      -0.100010   \n",
       "25%         0.267860       0.267990       0.279186       0.421563   \n",
       "50%         0.361110       0.361940       0.368402       0.501110   \n",
       "75%         0.459800       0.461097       0.457985       0.590037   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model5_sim2  model5_simavg    model6_sim1    model6_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.511581       0.511289       0.472858       0.473556   \n",
       "std         0.133234       0.106857       0.137125       0.138584   \n",
       "min        -0.096010      -0.077365      -0.065490      -0.059140   \n",
       "25%         0.421650       0.441802       0.376940       0.377500   \n",
       "50%         0.502085       0.511350       0.459725       0.459870   \n",
       "75%         0.590880       0.577615       0.553625       0.554608   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model6_simavg    model7_sim1    model7_sim2  model7_simavg  \n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000  \n",
       "mean        0.473207       0.389916       0.391240       0.390578  \n",
       "std         0.110441       0.164293       0.166606       0.140670  \n",
       "min        -0.025970      -0.145090      -0.184300      -0.130730  \n",
       "25%         0.399367       0.287120       0.286910       0.298611  \n",
       "50%         0.471070       0.376555       0.378140       0.386350  \n",
       "75%         0.540645       0.478330       0.480167       0.476315  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>model2_sim1</th>\n",
       "      <th>model2_sim2</th>\n",
       "      <th>model2_simavg</th>\n",
       "      <th>model3_sim1</th>\n",
       "      <th>model3_sim2</th>\n",
       "      <th>model3_simavg</th>\n",
       "      <th>model4_sim1</th>\n",
       "      <th>model4_sim2</th>\n",
       "      <th>model4_simavg</th>\n",
       "      <th>model5_sim1</th>\n",
       "      <th>model5_sim2</th>\n",
       "      <th>model5_simavg</th>\n",
       "      <th>model6_sim1</th>\n",
       "      <th>model6_sim2</th>\n",
       "      <th>model6_simavg</th>\n",
       "      <th>model7_sim1</th>\n",
       "      <th>model7_sim2</th>\n",
       "      <th>model7_simavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30241.910266</td>\n",
       "      <td>0.258948</td>\n",
       "      <td>0.489173</td>\n",
       "      <td>0.489499</td>\n",
       "      <td>0.489336</td>\n",
       "      <td>0.455521</td>\n",
       "      <td>0.455877</td>\n",
       "      <td>0.455699</td>\n",
       "      <td>0.367625</td>\n",
       "      <td>0.368238</td>\n",
       "      <td>0.367931</td>\n",
       "      <td>0.510997</td>\n",
       "      <td>0.511581</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>0.473556</td>\n",
       "      <td>0.473207</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.390578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17513.272867</td>\n",
       "      <td>0.438059</td>\n",
       "      <td>0.132533</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.108391</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.107585</td>\n",
       "      <td>0.165727</td>\n",
       "      <td>0.165830</td>\n",
       "      <td>0.145023</td>\n",
       "      <td>0.131772</td>\n",
       "      <td>0.133234</td>\n",
       "      <td>0.106857</td>\n",
       "      <td>0.137125</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.110441</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>0.166606</td>\n",
       "      <td>0.140670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058190</td>\n",
       "      <td>-0.075800</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.100010</td>\n",
       "      <td>-0.096010</td>\n",
       "      <td>-0.077365</td>\n",
       "      <td>-0.065490</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.145090</td>\n",
       "      <td>-0.184300</td>\n",
       "      <td>-0.130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15124.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.400340</td>\n",
       "      <td>0.419485</td>\n",
       "      <td>0.362640</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.267860</td>\n",
       "      <td>0.267990</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.421563</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.441802</td>\n",
       "      <td>0.376940</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.399367</td>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.286910</td>\n",
       "      <td>0.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30440.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.481110</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>0.442590</td>\n",
       "      <td>0.442970</td>\n",
       "      <td>0.451547</td>\n",
       "      <td>0.361110</td>\n",
       "      <td>0.361940</td>\n",
       "      <td>0.368402</td>\n",
       "      <td>0.501110</td>\n",
       "      <td>0.502085</td>\n",
       "      <td>0.511350</td>\n",
       "      <td>0.459725</td>\n",
       "      <td>0.459870</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.376555</td>\n",
       "      <td>0.378140</td>\n",
       "      <td>0.386350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45289.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569590</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.556934</td>\n",
       "      <td>0.534447</td>\n",
       "      <td>0.534567</td>\n",
       "      <td>0.520814</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.461097</td>\n",
       "      <td>0.457985</td>\n",
       "      <td>0.590037</td>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.577615</td>\n",
       "      <td>0.553625</td>\n",
       "      <td>0.554608</td>\n",
       "      <td>0.540645</td>\n",
       "      <td>0.478330</td>\n",
       "      <td>0.480167</td>\n",
       "      <td>0.476315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MovieID          label    model2_sim1    model2_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean    30241.910266       0.258948       0.489173       0.489499   \n",
       "std     17513.272867       0.438059       0.132533       0.132979   \n",
       "min         1.000000       0.000000      -0.058190      -0.075800   \n",
       "25%     15124.250000       0.000000       0.400020       0.400340   \n",
       "50%     30440.500000       0.000000       0.480600       0.481110   \n",
       "75%     45289.000000       1.000000       0.569590       0.570000   \n",
       "max     60698.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model2_simavg    model3_sim1    model3_sim2  model3_simavg  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.489336       0.455521       0.455877       0.455699   \n",
       "std         0.108391       0.134610       0.135085       0.107585   \n",
       "min        -0.037415      -0.056780      -0.041250      -0.005710   \n",
       "25%         0.419485       0.362640       0.362510       0.383170   \n",
       "50%         0.489415       0.442590       0.442970       0.451547   \n",
       "75%         0.556934       0.534447       0.534567       0.520814   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model4_sim1    model4_sim2  model4_simavg    model5_sim1  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.367625       0.368238       0.367931       0.510997   \n",
       "std         0.165727       0.165830       0.145023       0.131772   \n",
       "min        -0.225060      -0.225060      -0.225060      -0.100010   \n",
       "25%         0.267860       0.267990       0.279186       0.421563   \n",
       "50%         0.361110       0.361940       0.368402       0.501110   \n",
       "75%         0.459800       0.461097       0.457985       0.590037   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model5_sim2  model5_simavg    model6_sim1    model6_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.511581       0.511289       0.472858       0.473556   \n",
       "std         0.133234       0.106857       0.137125       0.138584   \n",
       "min        -0.096010      -0.077365      -0.065490      -0.059140   \n",
       "25%         0.421650       0.441802       0.376940       0.377500   \n",
       "50%         0.502085       0.511350       0.459725       0.459870   \n",
       "75%         0.590880       0.577615       0.553625       0.554608   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model6_simavg    model7_sim1    model7_sim2  model7_simavg  \n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000  \n",
       "mean        0.473207       0.389916       0.391240       0.390578  \n",
       "std         0.110441       0.164293       0.166606       0.140670  \n",
       "min        -0.025970      -0.145090      -0.184300      -0.130730  \n",
       "25%         0.399367       0.287120       0.286910       0.298611  \n",
       "50%         0.471070       0.376555       0.378140       0.386350  \n",
       "75%         0.540645       0.478330       0.480167       0.476315  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>model2_sim1</th>\n",
       "      <th>model2_sim2</th>\n",
       "      <th>model2_simavg</th>\n",
       "      <th>model3_sim1</th>\n",
       "      <th>model3_sim2</th>\n",
       "      <th>model3_simavg</th>\n",
       "      <th>model4_sim1</th>\n",
       "      <th>model4_sim2</th>\n",
       "      <th>model4_simavg</th>\n",
       "      <th>model5_sim1</th>\n",
       "      <th>model5_sim2</th>\n",
       "      <th>model5_simavg</th>\n",
       "      <th>model6_sim1</th>\n",
       "      <th>model6_sim2</th>\n",
       "      <th>model6_simavg</th>\n",
       "      <th>model7_sim1</th>\n",
       "      <th>model7_sim2</th>\n",
       "      <th>model7_simavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.0</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "      <td>29244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30312.297018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474380</td>\n",
       "      <td>0.477701</td>\n",
       "      <td>0.476040</td>\n",
       "      <td>0.438987</td>\n",
       "      <td>0.442324</td>\n",
       "      <td>0.440656</td>\n",
       "      <td>0.344694</td>\n",
       "      <td>0.350557</td>\n",
       "      <td>0.347626</td>\n",
       "      <td>0.495458</td>\n",
       "      <td>0.498239</td>\n",
       "      <td>0.496848</td>\n",
       "      <td>0.455622</td>\n",
       "      <td>0.458753</td>\n",
       "      <td>0.457187</td>\n",
       "      <td>0.364157</td>\n",
       "      <td>0.370604</td>\n",
       "      <td>0.367381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17575.726429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120847</td>\n",
       "      <td>0.118997</td>\n",
       "      <td>0.099764</td>\n",
       "      <td>0.120723</td>\n",
       "      <td>0.119133</td>\n",
       "      <td>0.097516</td>\n",
       "      <td>0.145876</td>\n",
       "      <td>0.149421</td>\n",
       "      <td>0.132387</td>\n",
       "      <td>0.119081</td>\n",
       "      <td>0.116761</td>\n",
       "      <td>0.096830</td>\n",
       "      <td>0.122583</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>0.099009</td>\n",
       "      <td>0.141587</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.125951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.058190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016670</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.225060</td>\n",
       "      <td>-0.032520</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016280</td>\n",
       "      <td>-0.136980</td>\n",
       "      <td>-0.151980</td>\n",
       "      <td>-0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15165.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394380</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.413136</td>\n",
       "      <td>0.356168</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.375478</td>\n",
       "      <td>0.260687</td>\n",
       "      <td>0.262428</td>\n",
       "      <td>0.269959</td>\n",
       "      <td>0.415430</td>\n",
       "      <td>0.420690</td>\n",
       "      <td>0.434954</td>\n",
       "      <td>0.369977</td>\n",
       "      <td>0.376548</td>\n",
       "      <td>0.391376</td>\n",
       "      <td>0.279517</td>\n",
       "      <td>0.279830</td>\n",
       "      <td>0.288303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30426.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469960</td>\n",
       "      <td>0.472920</td>\n",
       "      <td>0.478897</td>\n",
       "      <td>0.430925</td>\n",
       "      <td>0.433450</td>\n",
       "      <td>0.439585</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.351070</td>\n",
       "      <td>0.354258</td>\n",
       "      <td>0.491325</td>\n",
       "      <td>0.492120</td>\n",
       "      <td>0.499135</td>\n",
       "      <td>0.448740</td>\n",
       "      <td>0.449830</td>\n",
       "      <td>0.457445</td>\n",
       "      <td>0.359530</td>\n",
       "      <td>0.365270</td>\n",
       "      <td>0.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45622.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.551475</td>\n",
       "      <td>0.540448</td>\n",
       "      <td>0.512583</td>\n",
       "      <td>0.513830</td>\n",
       "      <td>0.503080</td>\n",
       "      <td>0.432825</td>\n",
       "      <td>0.440292</td>\n",
       "      <td>0.433307</td>\n",
       "      <td>0.570290</td>\n",
       "      <td>0.569723</td>\n",
       "      <td>0.559225</td>\n",
       "      <td>0.531432</td>\n",
       "      <td>0.531223</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.447115</td>\n",
       "      <td>0.456325</td>\n",
       "      <td>0.448140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MovieID    label   model2_sim1   model2_sim2  model2_simavg  \\\n",
       "count  29244.000000  29244.0  29244.000000  29244.000000   29244.000000   \n",
       "mean   30312.297018      1.0      0.474380      0.477701       0.476040   \n",
       "std    17575.726429      0.0      0.120847      0.118997       0.099764   \n",
       "min        1.000000      1.0     -0.058190      0.000000      -0.016670   \n",
       "25%    15165.750000      1.0      0.394380      0.399498       0.413136   \n",
       "50%    30426.500000      1.0      0.469960      0.472920       0.478897   \n",
       "75%    45622.250000      1.0      0.551083      0.551475       0.540448   \n",
       "max    60698.000000      1.0      1.000000      1.000000       1.000000   \n",
       "\n",
       "        model3_sim1   model3_sim2  model3_simavg   model4_sim1   model4_sim2  \\\n",
       "count  29244.000000  29244.000000   29244.000000  29244.000000  29244.000000   \n",
       "mean       0.438987      0.442324       0.440656      0.344694      0.350557   \n",
       "std        0.120723      0.119133       0.097516      0.145876      0.149421   \n",
       "min       -0.043660      0.000000       0.000000     -0.225060     -0.225060   \n",
       "25%        0.356168      0.360930       0.375478      0.260687      0.262428   \n",
       "50%        0.430925      0.433450       0.439585      0.345205      0.351070   \n",
       "75%        0.512583      0.513830       0.503080      0.432825      0.440292   \n",
       "max        1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "       model4_simavg   model5_sim1   model5_sim2  model5_simavg   model6_sim1  \\\n",
       "count   29244.000000  29244.000000  29244.000000   29244.000000  29244.000000   \n",
       "mean        0.347626      0.495458      0.498239       0.496848      0.455622   \n",
       "std         0.132387      0.119081      0.116761       0.096830      0.122583   \n",
       "min        -0.225060     -0.032520     -0.003900       0.000000     -0.065490   \n",
       "25%         0.269959      0.415430      0.420690       0.434954      0.369977   \n",
       "50%         0.354258      0.491325      0.492120       0.499135      0.448740   \n",
       "75%         0.433307      0.570290      0.569723       0.559225      0.531432   \n",
       "max         1.000000      1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "        model6_sim2  model6_simavg   model7_sim1   model7_sim2  model7_simavg  \n",
       "count  29244.000000   29244.000000  29244.000000  29244.000000   29244.000000  \n",
       "mean       0.458753       0.457187      0.364157      0.370604       0.367381  \n",
       "std        0.120493       0.099009      0.141587      0.146100       0.125951  \n",
       "min        0.000000      -0.016280     -0.136980     -0.151980      -0.122200  \n",
       "25%        0.376548       0.391376      0.279517      0.279830       0.288303  \n",
       "50%        0.449830       0.457445      0.359530      0.365270       0.368600  \n",
       "75%        0.531223       0.520750      0.447115      0.456325       0.448140  \n",
       "max        1.000000       1.000000      1.000000      1.000000       1.000000  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[new_df.label==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>model2_sim1</th>\n",
       "      <th>model2_sim2</th>\n",
       "      <th>model2_simavg</th>\n",
       "      <th>model3_sim1</th>\n",
       "      <th>model3_sim2</th>\n",
       "      <th>model3_simavg</th>\n",
       "      <th>model4_sim1</th>\n",
       "      <th>model4_sim2</th>\n",
       "      <th>model4_simavg</th>\n",
       "      <th>model5_sim1</th>\n",
       "      <th>model5_sim2</th>\n",
       "      <th>model5_simavg</th>\n",
       "      <th>model6_sim1</th>\n",
       "      <th>model6_sim2</th>\n",
       "      <th>model6_simavg</th>\n",
       "      <th>model7_sim1</th>\n",
       "      <th>model7_sim2</th>\n",
       "      <th>model7_simavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.0</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "      <td>83690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30217.314852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494342</td>\n",
       "      <td>0.493622</td>\n",
       "      <td>0.493982</td>\n",
       "      <td>0.461299</td>\n",
       "      <td>0.460613</td>\n",
       "      <td>0.460956</td>\n",
       "      <td>0.375637</td>\n",
       "      <td>0.374416</td>\n",
       "      <td>0.375027</td>\n",
       "      <td>0.516427</td>\n",
       "      <td>0.516243</td>\n",
       "      <td>0.516335</td>\n",
       "      <td>0.478880</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.478804</td>\n",
       "      <td>0.398917</td>\n",
       "      <td>0.398451</td>\n",
       "      <td>0.398684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17491.435463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.110873</td>\n",
       "      <td>0.138673</td>\n",
       "      <td>0.139923</td>\n",
       "      <td>0.110406</td>\n",
       "      <td>0.171404</td>\n",
       "      <td>0.170763</td>\n",
       "      <td>0.148534</td>\n",
       "      <td>0.135509</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.109699</td>\n",
       "      <td>0.141361</td>\n",
       "      <td>0.144015</td>\n",
       "      <td>0.113635</td>\n",
       "      <td>0.170607</td>\n",
       "      <td>0.172620</td>\n",
       "      <td>0.144589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055290</td>\n",
       "      <td>-0.075800</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.168250</td>\n",
       "      <td>-0.168450</td>\n",
       "      <td>-0.168250</td>\n",
       "      <td>-0.100010</td>\n",
       "      <td>-0.096010</td>\n",
       "      <td>-0.077365</td>\n",
       "      <td>-0.047080</td>\n",
       "      <td>-0.059140</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.145090</td>\n",
       "      <td>-0.184300</td>\n",
       "      <td>-0.130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15110.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402090</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>0.421950</td>\n",
       "      <td>0.364903</td>\n",
       "      <td>0.363015</td>\n",
       "      <td>0.386131</td>\n",
       "      <td>0.270640</td>\n",
       "      <td>0.270153</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.424220</td>\n",
       "      <td>0.421990</td>\n",
       "      <td>0.444727</td>\n",
       "      <td>0.379970</td>\n",
       "      <td>0.377892</td>\n",
       "      <td>0.402471</td>\n",
       "      <td>0.290342</td>\n",
       "      <td>0.289810</td>\n",
       "      <td>0.302310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30446.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484670</td>\n",
       "      <td>0.484275</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.447065</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.456342</td>\n",
       "      <td>0.366970</td>\n",
       "      <td>0.366135</td>\n",
       "      <td>0.374335</td>\n",
       "      <td>0.505060</td>\n",
       "      <td>0.505750</td>\n",
       "      <td>0.515825</td>\n",
       "      <td>0.463890</td>\n",
       "      <td>0.464280</td>\n",
       "      <td>0.476330</td>\n",
       "      <td>0.383595</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.393515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45187.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576908</td>\n",
       "      <td>0.577117</td>\n",
       "      <td>0.562875</td>\n",
       "      <td>0.542797</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.527405</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>0.469210</td>\n",
       "      <td>0.467580</td>\n",
       "      <td>0.597930</td>\n",
       "      <td>0.599230</td>\n",
       "      <td>0.584336</td>\n",
       "      <td>0.562615</td>\n",
       "      <td>0.563430</td>\n",
       "      <td>0.547889</td>\n",
       "      <td>0.490920</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.487405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MovieID    label   model2_sim1   model2_sim2  model2_simavg  \\\n",
       "count  83690.000000  83690.0  83690.000000  83690.000000   83690.000000   \n",
       "mean   30217.314852      0.0      0.494342      0.493622       0.493982   \n",
       "std    17491.435463      0.0      0.136002      0.137292       0.110873   \n",
       "min        1.000000      0.0     -0.055290     -0.075800      -0.037415   \n",
       "25%    15110.250000      0.0      0.402090      0.400770       0.421950   \n",
       "50%    30446.500000      0.0      0.484670      0.484275       0.493822   \n",
       "75%    45187.000000      0.0      0.576908      0.577117       0.562875   \n",
       "max    60698.000000      0.0      1.000000      1.000000       1.000000   \n",
       "\n",
       "        model3_sim1   model3_sim2  model3_simavg   model4_sim1   model4_sim2  \\\n",
       "count  83690.000000  83690.000000   83690.000000  83690.000000  83690.000000   \n",
       "mean       0.461299      0.460613       0.460956      0.375637      0.374416   \n",
       "std        0.138673      0.139923       0.110406      0.171404      0.170763   \n",
       "min       -0.056780     -0.041250      -0.005710     -0.168250     -0.168450   \n",
       "25%        0.364903      0.363015       0.386131      0.270640      0.270153   \n",
       "50%        0.447065      0.446700       0.456342      0.366970      0.366135   \n",
       "75%        0.542797      0.542857       0.527405      0.470870      0.469210   \n",
       "max        1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "       model4_simavg   model5_sim1   model5_sim2  model5_simavg   model6_sim1  \\\n",
       "count   83690.000000  83690.000000  83690.000000   83690.000000  83690.000000   \n",
       "mean        0.375027      0.516427      0.516243       0.516335      0.478880   \n",
       "std         0.148534      0.135509      0.138226       0.109699      0.141361   \n",
       "min        -0.168250     -0.100010     -0.096010      -0.077365     -0.047080   \n",
       "25%         0.282500      0.424220      0.421990       0.444727      0.379970   \n",
       "50%         0.374335      0.505060      0.505750       0.515825      0.463890   \n",
       "75%         0.467580      0.597930      0.599230       0.584336      0.562615   \n",
       "max         1.000000      1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "        model6_sim2  model6_simavg   model7_sim1   model7_sim2  model7_simavg  \n",
       "count  83690.000000   83690.000000  83690.000000  83690.000000   83690.000000  \n",
       "mean       0.478728       0.478804      0.398917      0.398451       0.398684  \n",
       "std        0.144015       0.113635      0.170607      0.172620       0.144589  \n",
       "min       -0.059140      -0.025970     -0.145090     -0.184300      -0.130730  \n",
       "25%        0.377892       0.402471      0.290342      0.289810       0.302310  \n",
       "50%        0.464280       0.476330      0.383595      0.383245       0.393515  \n",
       "75%        0.563430       0.547889      0.490920      0.489378       0.487405  \n",
       "max        1.000000       1.000000      1.000000      1.000000       1.000000  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[new_df.label==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每个label=1起始的句子，在后续s size句子中找到合适的threshold进行切割。\n",
    "s size越大该方法对比random split的差异越明显。\n",
    "\n",
    "s size too small: not obvious changes in std\n",
    "s size too large: th too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_df.label.get_values()\n",
    "LineIDs = new_df.LineIDs.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_pred(x,alpha):\n",
    "    x_ = x[x!=0]\n",
    "    if len(x_)==0:\n",
    "        th = 0\n",
    "        label = [0]\n",
    "    else:\n",
    "        th = np.mean(x_)-alpha*np.std(x_)\n",
    "        label = np.where(x<=th)[0]\n",
    "        label = label if len(label)>0 else [0] # if th is too low, then the predicted label is the whole session\n",
    "    return label[0]\n",
    "\n",
    "def deriv_pred(x):\n",
    "    tmp = np.where((x[1:]-x[:-1])>0)[0]\n",
    "    if len(tmp)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def calculate_p_k(p,r,s_size):\n",
    "    P = np.ones(s_size)\n",
    "    P[p:] = 2\n",
    "\n",
    "    R = np.ones(s_size)\n",
    "    R[r:] = 2\n",
    "    \n",
    "    k = int(s_size/2)\n",
    "\n",
    "    delta_R = np.array([int(R[i]==R[i+k]) for i in range(len(R)-k)])\n",
    "    delta_P = np.array([int(P[i]==P[i+k]) for i in range(len(P)-k)])\n",
    "\n",
    "    P_k = sum(~(delta_R==delta_P)*1)/(len(R)-k)\n",
    "    return P_k\n",
    "\n",
    "def calculate_MAE(x,s_size):\n",
    "    x[x<0] = s_size\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texttiling_embedding(labels,smooth_score):\n",
    "    s_dict = {}\n",
    "    start_idx = np.where(labels==1)[0]\n",
    "\n",
    "    s_size = 10\n",
    "\n",
    "    for i in start_idx:\n",
    "        s = smooth_score[i:i+s_size]\n",
    "        block_label = np.where(labels[i:i+s_size])[0]\n",
    "        if len(block_label) < 2:\n",
    "            continue\n",
    "        depth_score = [0]\n",
    "        lpeak = s[0]\n",
    "        for k in range(1,len(s)):\n",
    "    #         idx = max(0,k-block_size)\n",
    "            lpeak = max(s[0:k+1])\n",
    "            depth_score.append(s[k]-lpeak)\n",
    "        s_dict[i] = {}\n",
    "        s_dict[i]['depth score'] = np.round(np.array(depth_score),5)\n",
    "        s_dict[i]['smooth score'] = s\n",
    "        s_dict[i]['depth mean'] = np.mean(depth_score)\n",
    "        s_dict[i]['depth std'] = np.std(depth_score)\n",
    "        s_dict[i]['block label'] = block_label\n",
    "        s_dict[i]['LineIDs'] = LineIDs[i:i+s_size]\n",
    "    s_df = pd.DataFrame.from_dict(s_dict).T  \n",
    "\n",
    "    # block_labels = s_df['block label'].apply(lambda x:x[1])\n",
    "#     length = s_df['length'].get_values()\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['alpha','ACC','MAE','P_k','Random ACC','Random MAE','Random P_k']\n",
    "\n",
    "    # nltk.texttiling: mean - std/2\n",
    "    alphas = [0.1,0.2,0.3,0.4,0.5]\n",
    "    for alpha in alphas:\n",
    "        block_labels = []\n",
    "        pred = s_df['depth score'].apply(lambda x: th_pred(x,alpha))\n",
    "#         delta = s_df['depth score'].apply(lambda x: deriv_pred(x))\n",
    "        delta = s_df['depth score'].apply(lambda x: next(iter(np.where((x[1:]-x[:-1])>0)[0]), 0))\n",
    "    #     max_index = delta.loc[delta==s_size-1].index.get_values()\n",
    "    #     for i in max_index:\n",
    "    #         delta.loc[i] = pred.loc[i]\n",
    "        s_df['pred'] = np.max((pred.get_values(),delta.get_values()),axis=0) \n",
    "        # pred is the starting sentence of next dialogue\n",
    "        s_df.pred.replace(0,s_size-1,inplace=True) # predict = 0 means not found and set label to len of session\n",
    "    #     s_df['pred'] = delta\n",
    "        for i in range(len(pred)): # find the nearest label to prediction\n",
    "            block_labels.append(min(s_df['block label'].iloc[i][1:], key=lambda x:abs(x-s_df['pred'].iloc[i])))\n",
    "        diff = block_labels - pred # diff>0 when the prediction before ground truth\n",
    "\n",
    "        random_pred = np.random.randint(low=1,high=s_size+1,size=len(block_labels))\n",
    "        random_diff = block_labels - random_pred\n",
    "\n",
    "        acc = sum(block_labels==pred)/len(pred)\n",
    "        random_acc = sum(block_labels==random_pred)/len(random_pred)\n",
    "        \n",
    "        p_k = np.mean([calculate_p_k(p,r,s_size) for (p,r) in zip(block_labels,pred)])\n",
    "        random_p_k = np.mean([calculate_p_k(p,r,s_size) for (p,r) in zip(block_labels,random_pred)])\n",
    "        \n",
    "        table.add_row([alpha,\n",
    "                       round(acc,3),\n",
    "                      round(abs(calculate_MAE(diff,s_size)).mean(),3), # MAE\n",
    "                       round(p_k,3),\n",
    "                       round(random_acc,3),\n",
    "                      round(abs(calculate_MAE(random_diff,s_size)).mean(),3), # random MAE\n",
    "                       round(random_p_k,3)]\n",
    "                     )\n",
    "    print(table)\n",
    "    return s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random的accuracy并没有特殊意义，总体来说与我选择的session长度有关，最终random acc会收敛到1/s_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>label</th>\n",
       "      <th>model2_sim1</th>\n",
       "      <th>model2_sim2</th>\n",
       "      <th>model2_simavg</th>\n",
       "      <th>model3_sim1</th>\n",
       "      <th>model3_sim2</th>\n",
       "      <th>model3_simavg</th>\n",
       "      <th>model4_sim1</th>\n",
       "      <th>model4_sim2</th>\n",
       "      <th>model4_simavg</th>\n",
       "      <th>model5_sim1</th>\n",
       "      <th>model5_sim2</th>\n",
       "      <th>model5_simavg</th>\n",
       "      <th>model6_sim1</th>\n",
       "      <th>model6_sim2</th>\n",
       "      <th>model6_simavg</th>\n",
       "      <th>model7_sim1</th>\n",
       "      <th>model7_sim2</th>\n",
       "      <th>model7_simavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "      <td>112934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30241.910266</td>\n",
       "      <td>0.258948</td>\n",
       "      <td>0.489173</td>\n",
       "      <td>0.489499</td>\n",
       "      <td>0.489336</td>\n",
       "      <td>0.455521</td>\n",
       "      <td>0.455877</td>\n",
       "      <td>0.455699</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>0.345764</td>\n",
       "      <td>0.457979</td>\n",
       "      <td>0.458770</td>\n",
       "      <td>0.458374</td>\n",
       "      <td>0.457979</td>\n",
       "      <td>0.458770</td>\n",
       "      <td>0.458374</td>\n",
       "      <td>0.352804</td>\n",
       "      <td>0.354307</td>\n",
       "      <td>0.353555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17513.272867</td>\n",
       "      <td>0.438059</td>\n",
       "      <td>0.132533</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.108391</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.107585</td>\n",
       "      <td>0.164726</td>\n",
       "      <td>0.164639</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.136693</td>\n",
       "      <td>0.138177</td>\n",
       "      <td>0.108420</td>\n",
       "      <td>0.136693</td>\n",
       "      <td>0.138177</td>\n",
       "      <td>0.108420</td>\n",
       "      <td>0.172137</td>\n",
       "      <td>0.174252</td>\n",
       "      <td>0.149104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058190</td>\n",
       "      <td>-0.075800</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.234260</td>\n",
       "      <td>-0.234260</td>\n",
       "      <td>-0.234260</td>\n",
       "      <td>-0.022820</td>\n",
       "      <td>-0.060240</td>\n",
       "      <td>-0.040825</td>\n",
       "      <td>-0.022820</td>\n",
       "      <td>-0.060240</td>\n",
       "      <td>-0.040825</td>\n",
       "      <td>-0.116630</td>\n",
       "      <td>-0.112590</td>\n",
       "      <td>-0.087345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15124.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.400340</td>\n",
       "      <td>0.419485</td>\n",
       "      <td>0.362640</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.241492</td>\n",
       "      <td>0.241140</td>\n",
       "      <td>0.250280</td>\n",
       "      <td>0.363240</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.363240</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.244325</td>\n",
       "      <td>0.257306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30440.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.481110</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>0.442590</td>\n",
       "      <td>0.442970</td>\n",
       "      <td>0.451547</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.335025</td>\n",
       "      <td>0.342905</td>\n",
       "      <td>0.443950</td>\n",
       "      <td>0.444820</td>\n",
       "      <td>0.453750</td>\n",
       "      <td>0.443950</td>\n",
       "      <td>0.444820</td>\n",
       "      <td>0.453750</td>\n",
       "      <td>0.341505</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>0.352637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45289.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569590</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.556934</td>\n",
       "      <td>0.534447</td>\n",
       "      <td>0.534567</td>\n",
       "      <td>0.520814</td>\n",
       "      <td>0.436968</td>\n",
       "      <td>0.438107</td>\n",
       "      <td>0.434338</td>\n",
       "      <td>0.537007</td>\n",
       "      <td>0.538250</td>\n",
       "      <td>0.524129</td>\n",
       "      <td>0.537007</td>\n",
       "      <td>0.538250</td>\n",
       "      <td>0.524129</td>\n",
       "      <td>0.449350</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.447399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60698.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MovieID          label    model2_sim1    model2_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean    30241.910266       0.258948       0.489173       0.489499   \n",
       "std     17513.272867       0.438059       0.132533       0.132979   \n",
       "min         1.000000       0.000000      -0.058190      -0.075800   \n",
       "25%     15124.250000       0.000000       0.400020       0.400340   \n",
       "50%     30440.500000       0.000000       0.480600       0.481110   \n",
       "75%     45289.000000       1.000000       0.569590       0.570000   \n",
       "max     60698.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model2_simavg    model3_sim1    model3_sim2  model3_simavg  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.489336       0.455521       0.455877       0.455699   \n",
       "std         0.108391       0.134610       0.135085       0.107585   \n",
       "min        -0.037415      -0.056780      -0.041250      -0.005710   \n",
       "25%         0.419485       0.362640       0.362510       0.383170   \n",
       "50%         0.489415       0.442590       0.442970       0.451547   \n",
       "75%         0.556934       0.534447       0.534567       0.520814   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model4_sim1    model4_sim2  model4_simavg    model5_sim1  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.345485       0.346042       0.345764       0.457979   \n",
       "std         0.164726       0.164639       0.142298       0.136693   \n",
       "min        -0.234260      -0.234260      -0.234260      -0.022820   \n",
       "25%         0.241492       0.241140       0.250280       0.363240   \n",
       "50%         0.334280       0.335025       0.342905       0.443950   \n",
       "75%         0.436968       0.438107       0.434338       0.537007   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         model5_sim2  model5_simavg    model6_sim1    model6_sim2  \\\n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000   \n",
       "mean        0.458770       0.458374       0.457979       0.458770   \n",
       "std         0.138177       0.108420       0.136693       0.138177   \n",
       "min        -0.060240      -0.040825      -0.022820      -0.060240   \n",
       "25%         0.363422       0.384351       0.363240       0.363422   \n",
       "50%         0.444820       0.453750       0.443950       0.444820   \n",
       "75%         0.538250       0.524129       0.537007       0.538250   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       model6_simavg    model7_sim1    model7_sim2  model7_simavg  \n",
       "count  112934.000000  112934.000000  112934.000000  112934.000000  \n",
       "mean        0.458374       0.352804       0.354307       0.353555  \n",
       "std         0.108420       0.172137       0.174252       0.149104  \n",
       "min        -0.040825      -0.116630      -0.112590      -0.087345  \n",
       "25%         0.384351       0.243582       0.244325       0.257306  \n",
       "50%         0.453750       0.341505       0.343100       0.352637  \n",
       "75%         0.524129       0.449350       0.451900       0.447399  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  | 0.26020819459535244 | 1.535 |  0.2865795100066595 | 0.10059233815849426 |   2.924    |  0.4982229855245172 |\n",
      "|  0.2  | 0.26602642739476356 | 1.515 |  0.2834530861168554 | 0.09985629665977358 |   2.931    |  0.4982370053625881 |\n",
      "|  0.3  |  0.2701973292208475 | 1.501 | 0.28101363429252396 |  0.0962111387613473 |   2.954    |  0.5047211804703656 |\n",
      "|  0.4  | 0.27223020574112367 | 1.492 | 0.27935228348112584 | 0.10325610739195962 |   2.923    | 0.49774631103010764 |\n",
      "|  0.5  | 0.27517437173600645 |  1.48 | 0.27750166485577094 | 0.10108303249097472 |   2.955    |  0.4994146717605412 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model2_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |     Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n",
      "|  0.1  | 0.29893799726613157 | 3.817 | 0.27637306789106586 | 0.10006659423083664 |    6.39    | 0.5026252146787704 |\n",
      "|  0.2  |  0.3034243454488101 | 3.909 | 0.27314850513476574 | 0.10252006589323893 |   6.346    | 0.5008587150818408 |\n",
      "|  0.3  |  0.3056324699449721 | 4.009 |  0.2710735691002769 | 0.10024184220672251 |   6.308    | 0.5014896077950299 |\n",
      "|  0.4  |  0.3060881146822754 | 4.116 |  0.2694052083698434 | 0.09933055273211594 |   6.269    | 0.500346990992254  |\n",
      "|  0.5  |  0.3066839578002874 | 4.229 |  0.2682135221338193 | 0.09992639585012793 |   6.204    |  0.5011671515194   |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model2_simavg.get_values()\n",
    "\n",
    "s_df2 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2609792856892503 | 1.535 |  0.2869720654726438 | 0.10094283411026603 |   2.947    |  0.5003119413970769 |\n",
      "|  0.2  |  0.2629420630191721 | 1.517 | 0.28409098874907995 | 0.09666678349865059 |   2.932    |  0.499428691598612  |\n",
      "|  0.3  |  0.2674284112018506 | 1.501 |  0.2814412393536855 | 0.10164382601380954 |   2.928    | 0.49894500718516693 |\n",
      "|  0.4  | 0.27261575128807264 | 1.485 | 0.27865830149661774 | 0.10073253653920297 |   2.921    | 0.49740282499737126 |\n",
      "|  0.5  |  0.2768217027093337 | 1.474 |  0.2766254249763415 | 0.09645648592758754 |   2.953    |  0.5024429567838491 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model3_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.3052819739932004 | 3.789 |  0.2736251796291753 | 0.10129333006203778 |   6.365    |  0.5003329711541832 |\n",
      "|  0.2  | 0.30791069363148854 | 3.889 | 0.27082121201500126 | 0.09873470961410395 |   6.356    |  0.5018330938277663 |\n",
      "|  0.3  |  0.3098734709614104 | 3.981 | 0.26815043286250045 | 0.10052223896813992 |   6.264    |  0.4995128106270373 |\n",
      "|  0.4  | 0.31169604991062355 | 4.085 | 0.26609652658511795 | 0.09985629665977358 |   6.258    | 0.49930251305597423 |\n",
      "|  0.5  | 0.31138060355402897 | 4.209 |  0.2650730784059444 | 0.10108303249097472 |   6.198    | 0.49910623532298204 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model3_simavg.get_values()\n",
    "\n",
    "s_df3 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2550208545091304 | 1.529 |  0.285766359398549  | 0.09989134625495076 |   2.932    | 0.49917633451333643 |\n",
      "|  0.2  | 0.25982264904840346 | 1.511 | 0.28233850899022117 | 0.09761312256843434 |   2.938    |  0.5011180820861519 |\n",
      "|  0.3  |  0.2636080053275385 | 1.493 |  0.2792611545336651 | 0.09684203147453647 |   2.957    |  0.5016227962567033 |\n",
      "|  0.4  |  0.2658862290140549 | 1.484 | 0.27742455574638114 | 0.09915530475623006 |    2.91    |  0.4978304300585329 |\n",
      "|  0.5  | 0.26795415512950826 | 1.474 |  0.2756440363113806 | 0.10045213977778557 |   2.937    | 0.49910623532298204 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model4_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2976061126493989 | 3.762 |  0.2732115944060846 | 0.10122323087168343 |   6.323    | 0.49734674564508785 |\n",
      "|  0.2  |  0.2994637411937892 | 3.866 | 0.27074410290561146 | 0.09890995758998984 |   6.312    |  0.5012022011145771 |\n",
      "|  0.3  | 0.30069047702499035 | 3.965 |  0.2678910658581894 | 0.10108303249097472 |    6.27    |  0.4990781956468403 |\n",
      "|  0.4  | 0.30387999018611334 | 4.045 | 0.26594230836633836 | 0.09936560232729312 |   6.192    |  0.5008376853247346 |\n",
      "|  0.5  |  0.305211874802846  | 4.144 | 0.26477165188742074 | 0.10174897479934107 |   6.167    |  0.4980337177105605 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model4_simavg.get_values()\n",
    "\n",
    "s_df4 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2633626581612982 |  1.53 |  0.2861939644597105 | 0.10273036346430199 |   2.927    |  0.4968280116364656 |\n",
      "|  0.2  | 0.26942623812694966 | 1.509 |  0.2825908660754968 | 0.10136342925239214 |   2.949    |  0.5019803021275104 |\n",
      "|  0.3  |  0.2723704041218324 | 1.494 |  0.2800462654656339 | 0.09950580070800183 |   2.962    |  0.5017840243945183 |\n",
      "|  0.4  |  0.2749991237601206 | 1.483 | 0.27810451789281837 | 0.09666678349865059 |   2.954    |  0.5029827205495777 |\n",
      "|  0.5  | 0.27664645473344784 | 1.474 |  0.2766114051382707 |  0.1011180820861519 |   2.937    | 0.49841225333847394 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model5_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |     Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n",
      "|  0.1  |  0.3088570327012723 | 3.797 | 0.27387052679541557 | 0.09624618835652449 |   6.436    | 0.505001577231783  |\n",
      "|  0.2  |  0.3104342644842452 | 3.885 |  0.2714871543233676 |  0.0983842136623322 |   6.397    | 0.5002768918018996 |\n",
      "|  0.3  | 0.31306298412253336 | 3.973 |  0.269012652903859  | 0.09803371771056044 |   6.322    | 0.502246679050857  |\n",
      "|  0.4  |  0.3144649679296204 | 4.076 | 0.26675545897444886 | 0.09908520556587572 |   6.233    | 0.5030107602257194 |\n",
      "|  0.5  | 0.31565665416564437 | 4.188 |  0.2651922470295468 |  0.0994006519224703 |    6.19    | 0.4981598962531983 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model5_simavg.get_values()\n",
    "\n",
    "s_df5 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2618555255686797 | 1.534 | 0.28648838105919877 | 0.09876975920928113 |   2.937    |  0.5000035049595178 |\n",
      "|  0.2  | 0.26648207213206687 | 1.511 |  0.282899302513056  | 0.10294066103536505 |   2.915    | 0.49755003329711545 |\n",
      "|  0.3  |  0.2710385195050997 | 1.494 |  0.2797518488661456 | 0.10167887560898671 |   2.931    |  0.5002698818828643 |\n",
      "|  0.4  | 0.27261575128807264 | 1.483 |  0.2781676071641373 | 0.10122323087168343 |   2.943    |  0.5015737268234551 |\n",
      "|  0.5  | 0.27555991728295537 | 1.473 | 0.27633100837685326 | 0.09684203147453647 |   2.961    |  0.5035084644772353 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model6_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  | 0.30805089201219726 | 3.783 | 0.27373032841470685 | 0.10318600820160527 |   6.375    | 0.49930952297500963 |\n",
      "|  0.2  |  0.3102940661035365 | 3.885 |  0.2713048964284463 | 0.09841926325750938 |   6.344    |  0.4993515824892223 |\n",
      "|  0.3  |  0.3125021905996986 | 3.985 |  0.2691949107987803 | 0.10069748694402579 |   6.273    |  0.4995688899793207 |\n",
      "|  0.4  |  0.3146752655006835 | 4.089 |  0.2670989450071852 | 0.09898005678034419 |   6.265    |  0.5016438260138095 |\n",
      "|  0.5  | 0.31383407521643125 |  4.2  |  0.2662016753706495 |  0.0983842136623322 |   6.202    |  0.4983561739861905 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model6_simavg.get_values()\n",
    "s_df6 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "| alpha |  ACC  |  MAE  |  P_k  | Random ACC | Random MAE | Random P_k |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "|  0.1  |  0.26 | 3.852 | 0.284 |   0.101    |   6.005    |   0.499    |\n",
      "|  0.2  | 0.261 | 3.971 | 0.281 |   0.102    |    6.02    |   0.501    |\n",
      "|  0.3  | 0.266 | 4.063 | 0.278 |   0.097    |   5.994    |   0.501    |\n",
      "|  0.4  |  0.27 |  4.18 | 0.275 |   0.099    |   5.943    |    0.5     |\n",
      "|  0.5  | 0.272 | 4.314 | 0.274 |   0.101    |   5.919    |   0.499    |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model7_simavg.get_values()\n",
    "smooth_score = np.round(smooth(scores),5)\n",
    "\n",
    "s_df = texttiling_embedding(labels,smooth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "| alpha |  ACC  |  MAE  |  P_k  | Random ACC | Random MAE | Random P_k |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "|  0.1  | 0.305 | 3.723 | 0.271 |   0.101    |   6.349    |   0.503    |\n",
      "|  0.2  | 0.309 | 3.804 | 0.267 |   0.098    |   6.344    |   0.503    |\n",
      "|  0.3  |  0.31 | 3.918 | 0.266 |   0.099    |   6.293    |   0.501    |\n",
      "|  0.4  | 0.311 | 4.013 | 0.264 |   0.096    |   6.253    |   0.501    |\n",
      "|  0.5  | 0.314 | 4.105 | 0.262 |   0.102    |   6.143    |   0.499    |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model7_simavg.get_values()\n",
    "s_df7 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  | 0.28642529178787984 | 3.897 |  0.2763450282149241 |  0.099540850303179  |   6.401    |  0.500297921559006  |\n",
      "|  0.2  |  0.2875118292383723 | 3.988 |  0.273555080438821  | 0.09943570151764747 |   6.358    |  0.5014966177140654 |\n",
      "|  0.3  |  0.2881777715467386 | 4.103 | 0.27183064035610394 | 0.09999649504048229 |   6.288    | 0.49785145981563916 |\n",
      "|  0.4  | 0.28933440818758543 | 4.219 |  0.2696084960218709 | 0.10076758613438015 |   6.246    |  0.4974589043496548 |\n",
      "|  0.5  | 0.28898391223581366 |  4.34 |  0.2686200974378746 | 0.10315095860642809 |   6.178    |  0.5001927727734745 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model7_sim1.get_values()\n",
    "s_df = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "| alpha |         ACC         |  MAE  |         P_k         |      Random ACC     | Random MAE |      Random P_k     |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n",
      "|  0.1  |  0.2896849041393572 | 3.718 | 0.27872840068697213 | 0.10230976832217588 |   6.339    |  0.4991132452420174 |\n",
      "|  0.2  | 0.29301461568118886 | 3.799 |  0.2756790859065578 | 0.09929550313693877 |   6.329    |  0.502407907188672  |\n",
      "|  0.3  |  0.2962041288423119 |  3.88 |  0.2730293365111633 | 0.09936560232729312 |   6.328    |  0.5014685780379237 |\n",
      "|  0.4  | 0.29893799726613157 | 3.962 |  0.2709754302337809 | 0.10076758613438015 |   6.257    | 0.49985629665977355 |\n",
      "|  0.5  |  0.2994637411937892 | 4.074 |  0.2687042164662999 |  0.0994006519224703 |   6.194    | 0.49684904139357194 |\n",
      "+-------+---------------------+-------+---------------------+---------------------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model7_sim2.get_values()\n",
    "s_df = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "| alpha |  ACC  |  MAE  |  P_k  | Random ACC | Random MAE | Random P_k |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n",
      "|  0.1  | 0.301 | 3.756 | 0.273 |   0.098    |   6.376    |   0.504    |\n",
      "|  0.2  | 0.306 | 3.829 | 0.269 |    0.1     |   6.314    |   0.502    |\n",
      "|  0.3  | 0.306 |  3.93 | 0.267 |    0.1     |   6.277    |   0.501    |\n",
      "|  0.4  | 0.308 | 4.025 | 0.265 |   0.101    |    6.2     |    0.5     |\n",
      "|  0.5  |  0.31 | 4.119 | 0.264 |   0.096    |    6.2     |   0.503    |\n",
      "+-------+-------+-------+-------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "scores = new_df.model8_simavg.get_values()\n",
    "s_df8 = texttiling_embedding(labels,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "加上human作为对比。\n",
    "\n",
    "加上even segmented作为对比。\n",
    "\n",
    "Accuracy并不适合这种情况，同样是完全预测不中准确label，完全瞎猜和只差一句的acc都是0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5]\n",
      "0 L58878 I 'm sorry . I did n't know .\n",
      "1 L58879 I did n't know either .\n",
      "2 L58881 I told him to leave me alone .\n",
      "3 L58882 Landon --\n",
      "4 L58883 It was the only thing I 've ever asked him !\n",
      "5 L58897 I 'm so sorry . I 'm a coward --\n",
      "6 L58898 I should have told you sooner --\n",
      "7 L58899 I made you do too many things , kept you up all night --\n",
      "8 L58900 No . The drugs just stopped working . If anything , doing things I love kept me healthy longer .\n",
      "9 L58901 Are you frightened ?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = s_df7.reset_index().copy()\n",
    "i = test_df.index[np.random.randint(10000)]\n",
    "block_label = min(test_df['block label'].iloc[i][1:], key=lambda x:abs(x-test_df['pred'].iloc[i]))\n",
    "depth_score = test_df['depth score'].iloc[i]\n",
    "IDs = test_df['LineIDs'].iloc[i]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.axvline(0,alpha=1,lw=4,c='r')\n",
    "plt.axvline(block_label,alpha=1,lw=4,c='r',label='Ground Truth')\n",
    "    \n",
    "    \n",
    "smooth_score = np.round(smooth(depth_score,window_len=5),5)\n",
    "\n",
    "# plt.axvline(np.random.randint(s_size),label='random pred')\n",
    "# plt.axvline(s_df['pred1'].iloc[i],c='b',label='pred1',linestyle='-.',lw=3)\n",
    "# plt.axvline(s_df['pred2'].iloc[i],c='g',label='pred2',linestyle='--')\n",
    "plt.plot(np.arange(len(depth_score)),depth_score,label='Depth score')\n",
    "# plt.plot(np.arange(len(depth_score)),smooth_score,label='Smooth score')\n",
    "plt.axvline(test_df['pred'].iloc[i],c='k',label='Prediction',linestyle='-.',lw=2)\n",
    "# plt.scatter(y=s,x=np.arange(len(depth_score)),label='smooth score')\n",
    "plt.xlabel('Index of sentences')\n",
    "plt.legend()\n",
    "\n",
    "print(test_df['block label'].iloc[i][1:])\n",
    "\n",
    "j = 0\n",
    "for ids in IDs:\n",
    "    print(j,ids,' '.join(movie_lines[ids]['Line']))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 L46262 I mean , I 've got the whole package , right ? A great life , a beautiful wife , and a few kids .\n",
      "1 L46263 A < u > few < /u > ?\n",
      "2 L46420 Please , Sylvia ! It 's a quarter to nine !\n",
      "3 L46421 First you ca n't wait to get me up here , and now -- rush , rush , rush ! Makes a person feel cheap .\n",
      "4 L46422 Sylvia -- sweetie -- it 's not that -- but I promised the guy I 'd be out of here by eight o'clock , positively .\n",
      "5 L46423 What guy ? Whose apartment is this , anyway ?\n",
      "6 L46424 What 's the difference ? Some schnook that works in the office .\n",
      "7 L46425 Good evening , Mr. Baxter .\n",
      "8 L46426 Good evening , Mrs. Lieberman .\n",
      "9 L46427 Some weather we 're having . Must be from all the meshugass at Cape Canaveral . You locked out of your apartment ?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = s_df2.reset_index().copy()\n",
    "depth_score = test_df['depth score'].iloc[i]\n",
    "IDs = test_df['LineIDs'].iloc[i]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.axvline(0,alpha=1,lw=4,c='r')\n",
    "plt.axvline(block_label,alpha=1,lw=4,c='r',label='Ground Truth')\n",
    "    \n",
    "plt.plot(np.arange(len(depth_score)),depth_score,label='Depth score')\n",
    "plt.axvline(test_df['pred'].iloc[i],c='k',label='Prediction',linestyle='-.',lw=2)\n",
    "# plt.scatter(y=s,x=np.arange(len(depth_score)),label='smooth score')\n",
    "plt.xlabel('Index of sentences')\n",
    "plt.legend()\n",
    "\n",
    "j = 0\n",
    "for ids in IDs:\n",
    "    print(j,ids,' '.join(movie_lines[ids]['Line']))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on OpenSubtitle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,gensim,os,chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# ps.stem(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_extract(line):\n",
    "    encode_type = chardet.detect(line)  \n",
    "    try:\n",
    "        line = line.decode(encode_type['encoding']) #进行相应解码，赋给原标识符（变量）\n",
    "#         line = multiple_replace(dict_, line)\n",
    "        line = line.replace('<GO>','').replace('<EOS>','')\n",
    "        line = [line.split('|')[1]]\n",
    "    except:\n",
    "        line = []\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import smart_open\n",
    "class MyCorpus(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname)[:500]: # take 500 files for test\n",
    "            for line in smart_open(os.path.join(self.dirname, fname), 'rb'):\n",
    "                yield from sentence_extract(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_clean(s):\n",
    "    s = s.replace('\\'','')\n",
    "    s = tokenizer.tokenize(s.lower())\n",
    "#     s = ' '.join([ps.stem(x) for x in s])\n",
    "    s = ' '.join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/Users/yan/Documents/document/EPFL/MA2/semesterprj/code/processed_data/OpenSubtitle/'\n",
    "sentences = MyCorpus(file_dir)\n",
    "sentences = [x.lstrip().rstrip() for x in sentences]\n",
    "sentences = list(filter(None,sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257863"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_stem = [corpus_clean(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61261"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_question = [i for i,x in enumerate(sentences) if '?' in x] # return index where exits '?'\n",
    "len(idx_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_idx = np.array(idx_question[1:]) - np.array(idx_question[:-1])\n",
    "diff_idx = np.append(diff_idx,[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61261"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_before = idx_question[0]\n",
    "for i in idx_question:\n",
    "    if (len(sentences[i]) > 20) | (len(sentences[i]) < 4):\n",
    "        idx_question.remove(i)\n",
    "    if i-idx_before==1:\n",
    "        idx_question.remove(idx_before)\n",
    "    idx_before = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34925"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_size = 10\n",
    "corpus = []\n",
    "for i in idx_question:\n",
    "    s_tmp = [tokenizer.tokenize(x) for x in sentences_stem[i:i+s_size]]\n",
    "    word_cnt = sum([len(x) for x in s_tmp])/len(s_tmp)\n",
    "    if (word_cnt > 4) & (word_cnt< 20): # the average words number should be between 7-15 words\n",
    "        corpus.extend(s_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323090"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for i in range(len(corpus)-1):\n",
    "    lines.append(corpus[i]+corpus[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163755, 4546819)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opst = gensim.models.Word2Vec(iter=1,size=300)  # an empty model, no training yet\n",
    "model_opst.build_vocab(lines)  # can be a non-repeatable, 1-pass generator\n",
    "\n",
    "model_opst.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                lockf=1.0, # allow further training updates of merged vectors\n",
    "                                binary=True)\n",
    "\n",
    "model_opst.train(lines,total_examples=model_opst.corpus_count,epochs=model_opst.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1,v2):\n",
    "    return v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "def heuristic_max(s1,s2,flag=False,model=model_opst.wv):\n",
    "    if len(s1)*len(s2) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    matrix = np.zeros((len(s1),len(s2)))\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] in model.vocab.keys():\n",
    "            s1_vec = model[s1[i]]\n",
    "        else:\n",
    "            continue # if the source target word is not in vocabulary list then corresponding similiarity row = 0\n",
    "        for j in range(len(s2)):            \n",
    "            if s2[j] in model.vocab.keys():\n",
    "                s2_vec = model[s2[j]]\n",
    "                matrix[i][j] = cos_sim(s1_vec,s2_vec)\n",
    "            else:\n",
    "                continue # for not-found words the similarity is 0\n",
    "    s1_sim =  np.sum(np.max(matrix,1))/len(s1)\n",
    "    s2_sim = np.sum(np.max(matrix,0))/len(s2)\n",
    "    return 1/2*(np.round(s1_sim,5)+np.round(s2_sim,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a37f1bb00>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### heuristic max using model 4 (upper case; puncuation)\n",
    "idx = np.random.randint(100) * s_size\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "sim = [heuristic_max(corpus[idx],corpus[idx+i],flag=True) for i in range(s_size)]\n",
    "sim = [1] + sim\n",
    "# smooth_score = smooth(np.array(sim))\n",
    "\n",
    "s = np.array(sim)\n",
    "depth_score = [0]\n",
    "lpeak = s[0]\n",
    "for k in range(1,len(s)):\n",
    "    lpeak = max(s[0:k+1])\n",
    "    depth_score.append(s[k]-lpeak)\n",
    "\n",
    "\n",
    "pred = th_pred(np.array(depth_score),alpha)\n",
    "delta = np.array(depth_score[1:]) - np.array(depth_score[:-1])\n",
    "delta = np.where(delta>0)[0]\n",
    "delta = delta[0] if len(delta>0) else s_size-1\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.axvline(pred,c='b',label='th_pred')\n",
    "plt.axvline(pred1,c='g',label='derivative pred')\n",
    "plt.legend()\n",
    "plt.plot(depth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_stem = sentences_stem[idx_question[idx]:idx_question[idx]+s_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "53\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "56\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "70\n",
      "71\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "75\n",
      "76\n",
      "77\n",
      "77\n",
      "78\n",
      "79\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "82\n",
      "82\n",
      "82\n",
      "82\n",
      "83\n",
      "83\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "86\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "99\n",
      "100\n",
      "101\n",
      "101\n",
      "101\n",
      "102\n",
      "103\n",
      "103\n",
      "104\n",
      "104\n",
      "105\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "108\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "110\n",
      "110\n",
      "111\n",
      "112\n",
      "112\n",
      "113\n",
      "113\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "115\n",
      "116\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "119\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "131\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "133\n",
      "133\n",
      "133\n",
      "134\n",
      "134\n",
      "135\n",
      "136\n",
      "136\n",
      "136\n",
      "136\n",
      "137\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "150\n",
      "151\n",
      "151\n",
      "151\n",
      "152\n",
      "152\n",
      "152\n",
      "153\n",
      "153\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "156\n",
      "157\n",
      "157\n",
      "158\n",
      "158\n",
      "159\n",
      "159\n",
      "160\n",
      "160\n",
      "161\n",
      "162\n",
      "162\n",
      "163\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "173\n",
      "173\n",
      "174\n",
      "174\n",
      "174\n",
      "174\n",
      "175\n",
      "175\n",
      "175\n",
      "176\n",
      "176\n",
      "177\n",
      "177\n",
      "178\n",
      "179\n",
      "179\n",
      "179\n",
      "180\n",
      "181\n",
      "181\n",
      "182\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "186\n",
      "186\n",
      "186\n",
      "186\n",
      "187\n",
      "188\n",
      "188\n",
      "188\n",
      "189\n",
      "189\n",
      "190\n",
      "191\n",
      "191\n",
      "191\n",
      "192\n",
      "192\n",
      "193\n",
      "194\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "205\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "207\n",
      "207\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "221\n",
      "222\n",
      "223\n",
      "223\n",
      "224\n",
      "225\n",
      "225\n",
      "226\n",
      "226\n",
      "226\n",
      "226\n",
      "227\n",
      "228\n",
      "228\n",
      "229\n",
      "230\n",
      "230\n",
      "230\n",
      "231\n",
      "232\n",
      "232\n",
      "232\n",
      "233\n",
      "233\n",
      "234\n",
      "234\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "240\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "245\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "249\n",
      "250\n",
      "251\n",
      "251\n",
      "251\n",
      "252\n",
      "253\n",
      "253\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "255\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "257\n",
      "258\n",
      "258\n",
      "259\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "265\n",
      "265\n",
      "265\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "267\n",
      "268\n",
      "268\n",
      "269\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "273\n",
      "274\n",
      "275\n",
      "275\n",
      "275\n",
      "276\n",
      "277\n",
      "277\n",
      "278\n",
      "279\n",
      "279\n",
      "279\n",
      "280\n",
      "280\n",
      "281\n",
      "281\n",
      "282\n",
      "283\n",
      "283\n",
      "284\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "294\n",
      "294\n",
      "295\n",
      "295\n",
      "295\n",
      "296\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "305\n",
      "305\n",
      "306\n",
      "306\n",
      "307\n",
      "308\n",
      "308\n",
      "309\n",
      "310\n",
      "310\n",
      "310\n",
      "310\n",
      "310\n",
      "310\n",
      "310\n",
      "311\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "313\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "317\n",
      "317\n",
      "318\n",
      "319\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "325\n",
      "326\n",
      "326\n",
      "326\n",
      "327\n",
      "327\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "333\n",
      "334\n",
      "334\n",
      "335\n",
      "335\n",
      "335\n",
      "335\n",
      "335\n",
      "335\n",
      "336\n",
      "336\n",
      "336\n",
      "337\n",
      "337\n",
      "337\n",
      "337\n",
      "338\n",
      "338\n",
      "338\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "341\n",
      "342\n",
      "342\n",
      "342\n",
      "342\n",
      "343\n",
      "343\n",
      "344\n",
      "344\n",
      "344\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "347\n",
      "348\n",
      "349\n",
      "349\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "351\n",
      "352\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "356\n",
      "356\n",
      "357\n",
      "357\n",
      "358\n",
      "359\n",
      "359\n",
      "359\n",
      "360\n",
      "361\n",
      "361\n",
      "361\n",
      "361\n",
      "361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/semester/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in less_equal\n",
      "  \n",
      "/anaconda3/envs/semester/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "362\n",
      "363\n",
      "364\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "373\n",
      "374\n",
      "375\n",
      "375\n",
      "376\n",
      "377\n",
      "377\n",
      "377\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "382\n",
      "383\n",
      "383\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "386\n",
      "387\n",
      "388\n",
      "388\n",
      "389\n",
      "390\n",
      "390\n",
      "391\n",
      "391\n",
      "391\n",
      "392\n",
      "392\n",
      "392\n",
      "393\n",
      "394\n",
      "394\n",
      "395\n",
      "395\n",
      "396\n",
      "396\n",
      "396\n",
      "396\n",
      "396\n",
      "397\n",
      "397\n",
      "398\n",
      "399\n",
      "399\n",
      "399\n",
      "400\n",
      "401\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "405\n",
      "405\n",
      "405\n",
      "405\n",
      "405\n",
      "406\n",
      "406\n",
      "407\n",
      "408\n",
      "408\n",
      "408\n",
      "409\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "420\n",
      "420\n",
      "421\n",
      "422\n",
      "422\n",
      "422\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "430\n",
      "430\n",
      "431\n",
      "432\n",
      "432\n",
      "433\n",
      "433\n",
      "433\n",
      "434\n",
      "434\n",
      "435\n",
      "436\n",
      "436\n",
      "437\n",
      "438\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "446\n",
      "447\n",
      "447\n",
      "447\n",
      "447\n",
      "448\n",
      "449\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "454\n",
      "454\n",
      "454\n",
      "455\n",
      "455\n",
      "456\n",
      "456\n",
      "457\n",
      "457\n",
      "458\n",
      "459\n",
      "459\n",
      "459\n",
      "459\n",
      "460\n",
      "461\n",
      "461\n",
      "462\n",
      "462\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "469\n",
      "470\n",
      "470\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "474\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "479\n",
      "479\n",
      "479\n",
      "479\n",
      "479\n",
      "479\n",
      "480\n",
      "480\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "484\n",
      "484\n",
      "485\n",
      "485\n",
      "485\n",
      "486\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "488\n",
      "489\n",
      "489\n",
      "489\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "495\n",
      "496\n",
      "496\n",
      "497\n",
      "497\n",
      "498\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "wordcnt_ = []\n",
    "len_ = []\n",
    "i = 0\n",
    "while(i<500):\n",
    "    print(i)\n",
    "    idx = np.random.randint(5000)\n",
    "    org = sentences[idx_question[idx]:idx_question[idx]+s_size]\n",
    "    org_stem = sentences_stem[idx_question[idx]:idx_question[idx]+s_size]\n",
    "\n",
    "    alpha = 0.5\n",
    "    s_size = 10\n",
    "\n",
    "    sim = [heuristic_max(org_stem[i],org_stem[i+1]) for i in range(s_size-1)]\n",
    "    sim = [1] + sim\n",
    "#     smooth_score = smooth(np.array(sim))\n",
    "\n",
    "    s = np.array(sim)\n",
    "    depth_score = [0]\n",
    "    lpeak = s[0]\n",
    "    for k in range(1,len(s)):\n",
    "        lpeak = max(s[0:k+1])\n",
    "        depth_score.append(s[k]-lpeak)\n",
    "\n",
    "    pred = th_pred(np.array(depth_score),alpha)\n",
    "    delta = np.array(depth_score[1:]) - np.array(depth_score[:-1])\n",
    "    delta = np.where(delta>0)[0]\n",
    "    delta = delta[0] if len(delta>0) else s_size-1\n",
    "    \n",
    "    pred = max(pred,delta)\n",
    "\n",
    "    pred_text = org[:pred]\n",
    "    if '?' in pred_text[-1]:\n",
    "        continue\n",
    "    len_.append(pred)\n",
    "    wordcnt_.append(np.mean([len(tokenizer.tokenize(x)) for x in pred_text]))\n",
    "    \n",
    "    with open('session_segmentation.txt', 'a') as f:\n",
    "        \n",
    "        f.write(\"==========Starting of Session %s.==========\\n\" % str(i))\n",
    "        f.write(\"==========Starting of Dialogue %s.==========\\n\" % str(i))\n",
    "        for j in range(len(org)):\n",
    "            if j<pred:\n",
    "                f.write('Turn %s: '% str(j+1))\n",
    "            f.write(\"%s\\n\" % org[j])\n",
    "            if j == pred-1:\n",
    "                f.write(\"==========Predicted ending of Dialogue %s.==========\\n\" % str(i))\n",
    "        f.write(\"==========End of this session==========\\n\\n\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semester)",
   "language": "python",
   "name": "semester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
